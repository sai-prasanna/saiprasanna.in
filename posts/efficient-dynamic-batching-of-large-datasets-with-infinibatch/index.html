<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Efficient Dynamic Batching of Large Datasets with Infinibatch | λf.(λg.f (g g)) (λg.f (g g)) Sai</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Efficient Dynamic Batching of Large Datasets with Infinibatch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Learn how to efficiently batch large datasets with varied sequence length for training using infinibatch." />
<meta property="og:description" content="Learn how to efficiently batch large datasets with varied sequence length for training using infinibatch." />
<link rel="canonical" href="https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" />
<meta property="og:url" content="https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" />
<meta property="og:site_name" content="λf.(λg.f (g g)) (λg.f (g g)) Sai" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-13T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/","@type":"BlogPosting","headline":"Efficient Dynamic Batching of Large Datasets with Infinibatch","dateModified":"2020-09-13T00:00:00-05:00","datePublished":"2020-09-13T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/"},"description":"Learn how to efficiently batch large datasets with varied sequence length for training using infinibatch.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://saiprasanna.in/feed.xml" title="λf.(λg.f (g g)) (λg.f (g g)) Sai" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css">

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">λf.(λg.f (g g)) (λg.f (g g)) Sai</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Efficient Dynamic Batching of Large Datasets with Infinibatch</h1><p class="page-description">Learn how to efficiently batch large datasets with varied sequence length for training using <a href='https://github.com/microsoft/infinibatch/'>infinibatch</a>.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-13T00:00:00-05:00" itemprop="datePublished">
        Sep 13, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      32 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#deep learning">deep learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/sai-prasanna/saiprasanna.in/tree/master/_notebooks/2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/sai-prasanna/saiprasanna.in/master?filepath=_notebooks%2F2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/sai-prasanna/saiprasanna.in/blob/master/_notebooks/2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Challenges-in-efficiently-processing-large-datasets">Challenges in efficiently processing large datasets </a>
<ul>
<li class="toc-entry toc-h2"><a href="#1.-Loading-and-shuffling-large-datasets">1. Loading and shuffling large datasets </a></li>
<li class="toc-entry toc-h2"><a href="#2.-Dynamic-Batching">2. Dynamic Batching </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Tokenization-and-length-distribution">Tokenization and length distribution </a></li>
<li class="toc-entry toc-h3"><a href="#Dynamic-Padding">Dynamic Padding </a></li>
<li class="toc-entry toc-h3"><a href="#General-approach-to-dynamic-batching">General approach to dynamic batching </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#3.-Checkpointing">3. Checkpointing </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Infinibatch-to-the-rescue">Infinibatch to the rescue </a>
<ul>
<li class="toc-entry toc-h2"><a href="#1.-Loading-and-shuffling-large-datasets">1. Loading and shuffling large datasets </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Tensorize-our-dataset-with-a-map-iterator">Tensorize our dataset with a map iterator </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#2.-Dynamic-Batching">2. Dynamic Batching </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Example">Example </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#3.-Checkpointing">3. Checkpointing </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Making-Infinibatch-work-with-Pytorch-Dataloaders">Making Infinibatch work with Pytorch Dataloaders </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will explore how to efficiently batch large datasets with varied sequence length for training using <a href="https://github.com/microsoft/infinibatch/">infinibatch</a>. The focus will be on solving multiple challenges associated with this and making it work with <code>dataloader</code> abstraction in pytorch library. Though our focus is on pytorch, Infinibatch is a pure python library agnostic of the deep learning library.</p>
<p>This post was inspired by this thread on twitter.

</p>
<center>
    <div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Late, but I think exactly what you are asking for: <a href="https://t.co/gIyBzf5yoE">https://t.co/gIyBzf5yoE</a><br><br>By colleagues from my team in MS.</p>— Marcin Junczys-Dowmunt (Marian NMT) (@marian_nmt) <a href="https://twitter.com/marian_nmt/status/1292850875715604480?ref_src=twsrc%5Etfw">August 10, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</center>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>We will use <a href="https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/">wikitext-103</a> dataset as an example. It’s a dataset with sentences from wikipedia. It has 103,227,021 word level tokens in it’s training split. It is used only for illustration, the techniques discussed here are can work for far larger dataset sizes.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip
<span class="o">!</span>unzip wikitext-103-raw-v1.zip
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-09-14 11:31:28--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip
Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.88.158
Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.88.158|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 191984949 (183M) [application/zip]
Saving to: ‘wikitext-103-raw-v1.zip’

wikitext-103-raw-v1 100%[===================&gt;] 183.09M  58.0MB/s    in 3.2s    

2020-09-14 11:31:31 (58.0 MB/s) - ‘wikitext-103-raw-v1.zip’ saved [191984949/191984949]

Archive:  wikitext-103-raw-v1.zip
   creating: wikitext-103-raw/
  inflating: wikitext-103-raw/wiki.test.raw  
  inflating: wikitext-103-raw/wiki.valid.raw  
  inflating: wikitext-103-raw/wiki.train.raw  
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Challenges-in-efficiently-processing-large-datasets">
<a class="anchor" href="#Challenges-in-efficiently-processing-large-datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Challenges in efficiently processing large datasets<a class="anchor-link" href="#Challenges-in-efficiently-processing-large-datasets"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Loading-and-shuffling-large-datasets">
<a class="anchor" href="#1.-Loading-and-shuffling-large-datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Loading and shuffling large datasets<a class="anchor-link" href="#1.-Loading-and-shuffling-large-datasets"> </a>
</h2>
<p>For large datasets, loading the entire data into memory might not be possible. If we were to sample fully random batches we need to do random access on huge dataset. Depending on the disk latency this might be unfeasible.</p>
<p>To solve this we can do the following.</p>
<ol>
<li>Shard the data into chunks larger than single instances so that it reduces the disk access.</li>
<li>Shuffle the chunks and load few of them and shuffle the data loaded from the chunks.</li>
</ol>
<p>If we shard the pieces into too big chunks we might end up loosing statistical power in our training updates as we are essentially reducing the randomness of our samples used for training. But we can't shard them too small either as that wouldn't solve our disk access problem.</p>
<p>We need a flexible approach would make it easy to control how much data is to be loaded into memory for shuffling. To address this challenge in isolation, you can refer dataset sharding logic in NVIDIA's <a href="https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/data/indexed_dataset.py">MEGATRON language model training code</a>. But infinibatch solves it in a more generalized manner along with our other challenges.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Dynamic-Batching">
<a class="anchor" href="#2.-Dynamic-Batching" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Dynamic Batching<a class="anchor-link" href="#2.-Dynamic-Batching"> </a>
</h2>
<p>NLP datasets generally have samples which are of varied lengths. When we batch the data for training on devices like GPU, we are forced to make them into n-dimensional tensors with fixed dimension. The most common type of input for NLP models is of the shape <strong>Mini-batch size x Sequence length</strong>. The sequence length is either a fixed value or is the length of longest sequence in that batch. The shorter sequences in the minii-batch are generally padded with a <em>padding token</em>. These padding tokens are wasteful in terms of computation as they don't do anything useful.</p>
<p>Some tutorials and examples you would find for pre-processing data would pad batches to a pre-determined sequence length independent of the elements in each batch. This is fully wasteful as many batches would have all the members less than the pre-determined length.</p>
<p>A better option would be to pad the elements of each batch to the sequence length which is maximum in that batch. This <strong>dynamic padding</strong> can improve efficiency but it doesn't solve the entire problem. Let's see why with an example.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tokenization-and-length-distribution">
<a class="anchor" href="#Tokenization-and-length-distribution" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tokenization and length distribution<a class="anchor-link" href="#Tokenization-and-length-distribution"> </a>
</h3>
<p>Let's implement a typical dynamic padding workflow with pytorch dataloader and a subword level tokenizer. We use BERT-base-cased tokenizer from huggingface's transformers library. This tokenizes words to subwords. The BERT model was pre-trained with maximum subword length of 512. We can theoretically use sequence lengths larger than that but for our purposes we will leave it as such at 512.</p>
<p>We will use torch's <a href="https://pytorch.org/docs/stable/data.html">dataset and dataloader</a> abstraction for this. It will as both an illustration of real world usage and is convinent as it helps avoid having to entire tokenized dataset in memory. We still have to load the sentences into memory once. This is not a problem for small datasets, but for very large corpuses it's a big problem as mentioned before.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hide_output</span>
<span class="o">!</span>pip install git+https://github.com/microsoft/infinibatch.git transformers torch
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">PreTrainedTokenizerFast</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Wiki103</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizerFast</span><span class="p">,</span> <span class="n">data_path</span><span class="o">=</span><span class="s2">"wikitext-103-raw/wiki.train.raw"</span><span class="p">,</span> <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">dp</span><span class="p">:</span>
            <span class="c1"># We are </span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">dp</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sentences</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-cased"</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">wiki_dataset</span> <span class="o">=</span> <span class="n">Wiki103</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">sequence_lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">wiki_dataset</span><span class="p">)):</span>
    <span class="n">sequence_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>1164464it [04:51, 4000.17it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By plotting the truncated <code>Subword sequence length vs Frequency</code> we see a distribution with a large variance.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">'fivethirtyeight'</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#0504aa'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'y'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Subword Sequence Length'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Sequence Length Distribution'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dynamic-Padding">
<a class="anchor" href="#Dynamic-Padding" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dynamic Padding<a class="anchor-link" href="#Dynamic-Padding"> </a>
</h3>
<p>From the above graph we can intuit that if we draw random samples from the data to form a mini-batch, we would have few examples which are significantly longer than the rest. This would mean that we would add a lot of padding tokens. This holds even if we clean the very short length instances as noise.</p>
<p>Let's implement dynamic padding and measure how much. We can use torch's <code>DataLoader</code> abstraction to do efficient batching with multi-processing. Since our tokenized outputs are of different lengths we have to implement a collate function to pad them dynamically together. We can pass the <code>tokenizer.pad</code> function implemented in huggingface's tokenizer as the collate function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">examples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="c1"># Since huggingface has already implemented this, this function is just to illustrate what a collator does.</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>

<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">wiki_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's assume that we can use maximum a batch size of 32 for max sequence length of 512 for our model in our training hardware without out-of-memory errors. The tokens per batch would be <code>512 * 32 = 16384</code>. We can now compute how much of it is padding tokens and what is the distribution of the batch's sequence length(which depends on the maximum element in the batch).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">padding_tokens</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">batch_lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)):</span>
    <span class="n">batched_input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
    <span class="n">batch_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batched_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">batched_input_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="n">padding_tokens</span> <span class="o">+=</span> <span class="n">batched_input_ids</span><span class="p">[</span><span class="n">batched_input_ids</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 36390/36390 [06:35&lt;00:00, 91.92it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Batches    : </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Padding Tokens   : </span><span class="si">{</span><span class="n">padding_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Input Tokens     : </span><span class="si">{</span><span class="n">total_tokens</span> <span class="o">-</span> <span class="n">padding_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Tokens     : </span><span class="si">{</span><span class="n">total_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Padding Tokens % : </span><span class="si">{</span><span class="p">(</span><span class="n">padding_tokens</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">/</span><span class="n">total_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total Batches    : 36390
Padding Tokens   : 244072396
Input Tokens     : 119699332
Total Tokens     : 363771728
Padding Tokens % : 67.09493267712108
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Surprise, surprise, <strong>67% of our net tokens are padding tokens</strong>. This would imply that of all the computations that we do, only 33% of is done for useful work. This starkly highlights the problem with static batch lengths even when accounting for dynamic padding.</p>
<p>Let's also plot the distribution of batch lengths.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">'fivethirtyeight'</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">batch_lengths</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#0504aa'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'y'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Batch Sequence Length'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Static Batch - Dynamic Padding Length Distribution'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As batches are randomly sampled, we see a normal distribution as we can should expect by the Central Limit Theorem. The frequency in the final bin is deviant because we have a significant number of sentences which we had truncated, hence batches with them will have the maximum sequence length.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="General-approach-to-dynamic-batching">
<a class="anchor" href="#General-approach-to-dynamic-batching" aria-hidden="true"><span class="octicon octicon-link"></span></a>General approach to dynamic batching<a class="anchor-link" href="#General-approach-to-dynamic-batching"> </a>
</h3>
<p>Instead of drawing samples in random, had we sorted our dataset by length, then we can form batches by packing similar length sequences together into a batch till we reach the maximum number of tokens that we can fit. The maximum number of tokens that can be packed can be derived approximately from our previous memory limit <em>static_batch x max_sequence_length</em>. This allows us to pack more instances in one batch without much padding because the sequences would be of similar lengths after sorting.</p>
<p>We can't sort the entire dataset because machine learning training is based on the assumption that our instances are drawn independently from an identical distribution (IID). If we were to sort the entire dataset this breaks the assumption as our samples are no longer drawn independently from each other. If sentence length were a confounding factor then the model might fit on this spurious correlation.</p>
<p>We have a trade-off here between statistical power derived from randomization of our samples and lesser error in gradient updates derived from larger batch sizes if we batch dynamically.</p>
<p>Generally, we can have a positive trade off by sampling a window of instances and sorting withing the window and forming batches.</p>
<p>The <code>Dataset</code> we implemented above is a <a href="https://pytorch.org/docs/stable/data.html#map-style-datasets">map-style</a> dataset. It implements length and random access to each individual data sample with index (<code>__getitem__</code>). The sampling into batches is taken care of a sampler passed to <code>DataLoader</code>.</p>
<p>I don't think there is a clean way to implement a map-style dataset and a collate function such that we get batches with dynamic batch sizes but same number of tokens per batch. This comes from the basic mismatch of number of dynamic batches which you can form keeps changing based on the larger window you sample.</p>
<p>So it turns out that we have to do all the shuffling, windowing, sorting and batching inside a <a href="https://pytorch.org/docs/stable/data.html#iterable-style-datasets">iterable-style</a> <code>IterableDataset</code> dataset abstraction. These features are implemented by infinibatch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Checkpointing">
<a class="anchor" href="#3.-Checkpointing" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Checkpointing<a class="anchor-link" href="#3.-Checkpointing"> </a>
</h2>
<p>In large datasets, it's typical not to wait for an entire epoch to checkpoint your model to recover from failures. So to be able to recover and continue training in a deterministic manner, such that it converges to same state if the failure hadn't occured, we have to checkpoint the random state that controls the order in which our samples are generated.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Infinibatch-to-the-rescue">
<a class="anchor" href="#Infinibatch-to-the-rescue" aria-hidden="true"><span class="octicon octicon-link"></span></a>Infinibatch to the rescue<a class="anchor-link" href="#Infinibatch-to-the-rescue"> </a>
</h1>
<blockquote>
<p>Infinibatch is a library of checkpointable iterators for randomized data loading of massive data sets in deep neural network training.</p>
</blockquote>
<p>It is aimed at simplify the processing of large datasets. It is a collection of pure python classes that implement <code>__iter__</code> interface. They can be composed inside one another easily and the final composed iterator can be checkpointed as a single entity.You can checkout it's basic tutorial <a href="https://github.com/microsoft/infinibatch">here</a>. We will use it to address the listed challenges piece by piece and then finally make it work inside <code>IterableDataset</code> and <code>DataLoader</code> abstractions. We will also see the tricks needed to make it work distributed data parallel training.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Loading-and-shuffling-large-datasets">
<a class="anchor" href="#1.-Loading-and-shuffling-large-datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Loading and shuffling large datasets<a class="anchor-link" href="#1.-Loading-and-shuffling-large-datasets"> </a>
</h2>
<p>Following the infinibatch tutorial, we divide our dataset into multiple gzip chunks of 10000 sentences each.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>mkdir -p wikitext-103-chunks
<span class="o">!</span>split  -a <span class="m">4</span> --lines <span class="m">10000</span>  --numeric-suffixes --filter <span class="s1">'gzip &gt; wikitext-103-chunks/$FILE.txt.gz'</span> wikitext-103-raw/wiki.train.raw  train.
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now create an iterator using infinibatch with a function that can deserialize a shard. Infinibatch takes care of loading multiple in a shuffled order. We can control the amount of deserialized individual examples from the shards be buffered using <code>buffer_size</code> parameter. The library returns a python iterable. We can call <code>next(iterable)</code> or iterate with a <code>for</code> to get the examples.</p>
<p>Note: Passing <code>train=True</code> creates an infinite iterator that cycles after a full run on the dataset. The <code>chunked_dataset_iterator</code> method returns a composition of iterators, you can refer the source code <a href="https://github.com/microsoft/infinibatch/blob/master/infinibatch/iterators.py">here</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gzip</span><span class="o">,</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">from</span> <span class="nn">infinibatch</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">iterators</span>

<span class="k">def</span> <span class="nf">read_chunk</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">read</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">lines</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>

<span class="n">sentence_it</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">chunked_dataset_iterator</span><span class="p">(</span>
    <span class="n">chunk_refs</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">),</span>
    <span class="n">read_chunk_fn</span> <span class="o">=</span> <span class="n">read_chunk</span><span class="p">,</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">1337</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">sentence_it</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>= = = Oxides and hydroxides = = =
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tensorize-our-dataset-with-a-map-iterator">
<a class="anchor" href="#Tensorize-our-dataset-with-a-map-iterator" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tensorize our dataset with a map iterator<a class="anchor-link" href="#Tensorize-our-dataset-with-a-map-iterator"> </a>
</h3>
<p>We can now compose our tokenizer upon our sentence iterator. Infinibatch has two ways of doing this,</p>
<ol>
<li><code>MapIterator</code></li>
<li><code>ParallelMapIterator</code></li>
</ol>
<p>If you use pytorch and need multiprocessing to do costly transformations over your data on the fly, use the <code>ParallelMap</code> and set the <code>num_processes</code> with what you would have with <code>num_workers</code>. And set <code>num_workers=0</code> in your dataloader.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenize_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">features_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">ParallelMapIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">sentence_it</span><span class="p">,</span>
    <span class="n">num_processes</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_items_per_process</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">tokenize_fn</span>
<span class="p">)</span>
<span class="nb">next</span><span class="p">(</span><span class="n">features_it</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'input_ids': [101, 134, 134, 134, 152, 8745, 4704, 1105, 177, 19694, 8745, 4704, 134, 134, 134, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Dynamic-Batching">
<a class="anchor" href="#2.-Dynamic-Batching" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Dynamic Batching<a class="anchor-link" href="#2.-Dynamic-Batching"> </a>
</h2>
<p>Now comes the magic of dynamic batching with <code>BucketedReadaheadBatchIterator</code>. Let's fix the maximum tokens per batch to  <code>32 * 512 = 16384</code>. This iterator allows you to compute dynamic batch size by iteratively applying a user given function over the current longest example (with length computed by user function) in a sorted <code>read_ahead</code> window. This window is sorted and batches are formed by using the user provided <code>batch_size</code> function iteratively.</p>
<h3 id="Example">
<a class="anchor" href="#Example" aria-hidden="true"><span class="octicon octicon-link"></span></a>Example<a class="anchor-link" href="#Example"> </a>
</h3>
<p>Say we want 50 tokens per batch. If we set a read ahead window of 6. Assume we fetch six items [a, b, c, d, e, f] in the first read ahead window.</p>
<table>
<thead>
<tr>
<th>Sequence id</th>
<th>Length</th>
</tr>
</thead>
<tbody>
<tr>
<td>a</td>
<td>50</td>
</tr>
<tr>
<td>b</td>
<td>30</td>
</tr>
<tr>
<td>c</td>
<td>20</td>
</tr>
<tr>
<td>d</td>
<td>20</td>
</tr>
<tr>
<td>e</td>
<td>30</td>
</tr>
<tr>
<td>f</td>
<td>20</td>
</tr>
</tbody>
</table>
<p>First we sort this window with lengths in decreasing order. The sort order is stable. This preserves the shuffling of equal sized elements from previous iterator. So for our example it would be [a, b, e, c, d, f]</p>
<p>Now we can Compute the dynamic batch sizes by applying the function <code>batch_size</code> iteratively till the window is exhausted. Assume our function is <code>lambda longest_instance: 60 // len(longest_instance)</code>. Then applying it once we get first longest item <code>a</code>, current batch size will be <code>60 //50 = 1</code>. The next longest item remaining can be used to calculate the size of the next batch and so on. So we will end up with [a], [b, e], [c, d, f]. Each of them will have 60 tokens.</p>
<p>You can take a look at the code that does this computation <a href="https://github.com/microsoft/infinibatch/blob/master/infinibatch/iterators.py#L1080">here</a>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens_per_batch</span> <span class="o">=</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">512</span>
<span class="n">batches_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">BucketedReadaheadBatchIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">features_it</span><span class="p">,</span>
    <span class="c1"># read_ahead is the number of items to be read from previous iterator,</span>
    <span class="c1"># these are sorted and over which dynamic batches are formed.</span>
    <span class="n">read_ahead</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> 
    <span class="c1"># key determines the length used to sort and choose the longest remaining record.</span>
    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">example</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span> 
     <span class="c1"># Determines the dynamic batch size</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="k">lambda</span> <span class="n">longest_example</span><span class="p">:</span> <span class="n">tokens_per_batch</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest_example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span> 
<span class="p">)</span>
<span class="n">dynamic_batch_wo_padding</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches_it</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Dynamic batch size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dynamic_batch_wo_padding</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">dynamic_batch_wo_padding</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches_it</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Dynamic batch size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dynamic_batch_wo_padding</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dynamic_batch_wo_padding</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dynamic batch size: 133
Dynamic batch size: 99
[{'input_ids': [101, 1109, 10437, 10745, 1159, 1108, 1103, 1211, 10543, 7631, 1121, 19475, 119, 23364, 1276, 1103, 10745, 1551, 107, 1119, 27944, 107, 1105, 6315, 1115, 1103, 1591, 1329, 1160, 10437, 9307, 1939, 1104, 1141, 117, 1112, 4836, 10437, 24295, 2624, 1108, 2320, 1107, 1103, 1342, 119, 5512, 5912, 1116, 9279, 1276, 1103, 24295, 2624, 1104, 107, 1544, 170, 5955, 107, 22593, 27643, 27725, 170, 107, 12178, 107, 1113, 1103, 20694, 23676, 119, 26835, 3798, 1276, 1103, 107, 3321, 107, 2971, 1104, 10437, 24295, 2624, 1106, 1129, 1103, 1342, 112, 188, 2026, 3282, 4197, 117, 1112, 1218, 1112, 1103, 1263, 10745, 1551, 1115, 4977, 1122, 119, 8746, 2202, 1115, 21105, 1158, 1551, 1127, 107, 17562, 3345, 107, 1496, 1106, 1103, 12177, 10437, 2469, 1158, 119, 2061, 2202, 1115, 1103, 1342, 1125, 170, 10437, 2469, 9285, 107, 1177, 2213, 107, 1115, 1122, 1108, 1593, 4763, 1106, 2469, 22493, 1219, 11716, 117, 1112, 1103, 16408, 1733, 1766, 2230, 1108, 1579, 170, 1248, 1481, 4315, 10322, 5172, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [101, 2651, 4385, 1127, 1211, 1510, 1276, 8910, 15364, 1158, 12354, 2928, 1105, 1103, 15553, 1104, 5400, 15246, 117, 1105, 11561, 1317, 3050, 131, 172, 16717, 3848, 6126, 117, 16358, 2881, 5018, 117, 23639, 11239, 5326, 6126, 117, 1105, 7812, 21212, 119, 140, 16717, 3848, 2116, 1110, 1103, 7764, 1271, 1111, 16307, 172, 16717, 3447, 1105, 1143, 17670, 4199, 131, 18249, 1105, 4600, 5511, 1113, 1499, 1104, 170, 2095, 119, 9800, 2881, 5018, 1127, 4122, 9417, 1116, 1115, 11479, 2894, 1103, 2095, 117, 3525, 15024, 1106, 5211, 1120, 117, 1137, 3968, 4546, 1113, 117, 19450, 1120, 1103, 2259, 1104, 1103, 2095, 1443, 1515, 1106, 8290, 1679, 24755, 1361, 1193, 1166, 1103, 172, 16717, 3848, 6126, 117, 8267, 15952, 2310, 1106, 1231, 6163, 26264, 1183, 1783, 119, 6603, 11239, 5326, 6126, 1127, 2576, 25344, 1113, 1499, 1104, 170, 2095, 1114, 18199, 1115, 2148, 4546, 1106, 1129, 2434, 1113, 1126, 3437, 1120, 1103, 2259, 1104, 1103, 2095, 1107, 170, 1861, 4633, 1106, 16358, 2881, 5018, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can collate our examples and see how much  this scheme has saved us. Since a training iterator is infinite, we will recreate our iterators with a non-infinite iterator.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence_it_finite</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">chunked_dataset_iterator</span><span class="p">(</span>
    <span class="n">chunk_refs</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">),</span>
    <span class="n">read_chunk_fn</span> <span class="o">=</span> <span class="n">read_chunk</span><span class="p">,</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> 
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">1337</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">features_it_finite</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">ParallelMapIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">sentence_it_finite</span><span class="p">,</span>
    <span class="n">num_processes</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_items_per_process</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">tokenize_fn</span>
<span class="p">)</span>
<span class="n">batches_it_finite</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">BucketedReadaheadBatchIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">features_it_finite</span><span class="p">,</span>
    <span class="n">read_ahead</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="c1"># Determines the window for the bucket which</span>
    <span class="c1"># will be sorted and  converted to batches.</span>
    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">example</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span> <span class="c1"># Determines the length used</span>
    <span class="c1"># to sort and choose the longest remaining record.</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="k">lambda</span> <span class="n">longest</span><span class="p">:</span> <span class="n">tokens_per_batch</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
    <span class="c1"># Determines the dynamic batch size</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span> 
<span class="p">)</span>
<span class="n">collate_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>
<span class="n">tensors_it_finite</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MapIterator</span><span class="p">(</span>
    <span class="n">batches_it_finite</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">collate_fn</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">total_batches_dynamic</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="n">total_tokens_dynamic</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">padding_tokens_dynamic</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">batch_lengths_dynamic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">tensors_it_finite</span><span class="p">):</span>
    <span class="n">total_batches_dynamic</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">batched_input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
    <span class="n">batch_lengths_dynamic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batched_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">total_tokens_dynamic</span> <span class="o">+=</span> <span class="n">batched_input_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="n">padding_tokens_dynamic</span> <span class="o">+=</span> <span class="n">batched_input_ids</span><span class="p">[</span><span class="n">batched_input_ids</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>7645it [08:45, 14.54it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Batches    : </span><span class="si">{</span><span class="n">total_batches_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span> <span class="c1"># Seeing the tqdm stats.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Padding Tokens   : </span><span class="si">{</span><span class="n">padding_tokens_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Input Tokens     : </span><span class="si">{</span><span class="n">total_tokens_dynamic</span> <span class="o">-</span> <span class="n">padding_tokens_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Tokens     : </span><span class="si">{</span><span class="n">total_tokens_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Padding Tokens % : </span><span class="si">{</span><span class="p">(</span><span class="n">padding_tokens_dynamic</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">/</span><span class="n">total_tokens_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total Batches    : 7645
Padding Tokens   : 3848626
Input Tokens     : 119699332
Total Tokens     : 123547958
Padding Tokens % : 3.1150866937031854
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have <strong>reduced</strong> the % of <strong>padding tokens</strong> per epoch from <strong>67% to just around 3%</strong>.The total batches needed to process it in the same max tokens per batch limitation hence got reduced nearly five times from 36390 to 7642.</p>
<p>The processing time is just one minute extra. I guess that might be due to IO, but you could try benchmarking that with more rigour.</p>
<p>Now, plotting the length distribution for dynamic batches.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">'fivethirtyeight'</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">batch_lengths_dynamic</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#0504aa'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'y'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Batch Sequence Length'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Dynamic Batch - Dynamic Padding Length Distribution'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now see that the expected per batch sequence length has reduced from 300 to 200.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Checkpointing">
<a class="anchor" href="#3.-Checkpointing" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Checkpointing<a class="anchor-link" href="#3.-Checkpointing"> </a>
</h2>
<p>One cool feature of <code>infinibatch</code> is that you can checkpoint a particular state in which the composed iterators is at and restore (rewind?) it back to that state. This is very cool considering it works recursively on the composed iterators and even on infinite iterator. Let's recreate our iterators and check this out.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence_it</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">chunked_dataset_iterator</span><span class="p">(</span>
    <span class="n">chunk_refs</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">),</span>
    <span class="n">read_chunk_fn</span> <span class="o">=</span> <span class="n">read_chunk</span><span class="p">,</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> 
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">1337</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">features_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">ParallelMapIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">sentence_it</span><span class="p">,</span>
    <span class="n">num_processes</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_items_per_process</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">tokenize_fn</span>
<span class="p">)</span>
<span class="n">batches_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">BucketedReadaheadBatchIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">features_it</span><span class="p">,</span>
    <span class="n">read_ahead</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="c1"># Determines the window for the bucket which</span>
    <span class="c1"># will be sorted and  converted to batches.</span>
    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">example</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span> <span class="c1"># Determines the length used</span>
    <span class="c1"># to sort and choose the longest remaining record.</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="k">lambda</span> <span class="n">longest</span><span class="p">:</span> <span class="n">tokens_per_batch</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
    <span class="c1"># Determines the dynamic batch size</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span> 
<span class="p">)</span>
<span class="n">collate_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>
<span class="n">tensors_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MapIterator</span><span class="p">(</span>
    <span class="n">batches_it</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">collate_fn</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">tensors_it</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span> 
<span class="nb">print</span><span class="p">(</span><span class="s2">"Initial State of composed iterators"</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">)</span>
<span class="c1"># Draw 5 batches</span>
<span class="n">batches</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">tensors_it</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Current State after sampling 5 batches: </span><span class="si">{</span><span class="n">tensors_it</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Reset the Iterator</span>
<span class="n">tensors_it</span><span class="o">.</span><span class="n">setstate</span><span class="p">(</span><span class="n">initial_state</span><span class="p">)</span>
<span class="c1"># Redraw 5 batches</span>
<span class="n">redraw_batches</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">tensors_it</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"State after resampling 5 batches: </span><span class="si">{</span><span class="n">tensors_it</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="c1"># Check equal</span>
<span class="n">all_equal</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">for</span> <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batches</span><span class="p">,</span> <span class="n">redraw_batches</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">b1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">b1</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">b2</span><span class="p">[</span><span class="n">k</span><span class="p">])):</span>
            <span class="k">continue</span>
        <span class="n">all_equal</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">break</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">all_equal</span><span class="p">:</span>
        <span class="k">break</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All items drawn after resetting are equal: </span><span class="si">{</span><span class="n">all_equal</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Initial State of composed iterators {'source_state': None, 'random_state': None, 'num_served': 0}
Current State after sampling 5 batches: {'source_state': {'source_state': None, 'flattened_items_yielded': 0}, 'random_state': (3, (2147483648, 766982754, 497961170, 3952298588, 2331775348, 1811986599, 3100132149, 3188119873, 3937547222, 215718963, 3315684082, 2978012849, 2428261856, 1298227695, 1704729580, 54668373, 3285201915, 3285178464, 1552935063, 988471319, 3135387943, 1691402966, 2757551880, 416056905, 907387413, 1072924981, 33903495, 2168419592, 2429050353, 831159753, 430343641, 3315943586, 1761671042, 864453023, 334804929, 1627478028, 2596811275, 3468733638, 3994375553, 1457139722, 3139722021, 1334790738, 2656639915, 3535811098, 1464315470, 2397423927, 885719490, 1140895889, 3284299483, 2854516462, 2734973817, 147484763, 792049954, 114360641, 3345458839, 1159898878, 1410498733, 2242989638, 453922141, 1344019764, 413870456, 3089405849, 1494382840, 470157779, 4266372830, 2831181573, 1361928602, 1589253513, 1381373062, 753045124, 987032420, 781978839, 2953638767, 3258570111, 3006718191, 1675218601, 1854232715, 3655829819, 1731242722, 2192104666, 1736665161, 740150002, 1195833394, 1610203160, 159492766, 4041488705, 3128952632, 2867295744, 3272632449, 886824304, 1791482600, 221114776, 3867175393, 4020804062, 1077871826, 1298953503, 996366221, 4149754679, 2483052703, 2615558283, 274318093, 1716359450, 4099129961, 1026774175, 288240973, 1459347562, 2365566296, 3690105224, 3065780221, 2050634722, 2652606621, 3185241207, 3026457375, 3456165734, 1880121515, 3398461093, 1795638629, 2379692076, 608668379, 1261955525, 84456522, 1913485156, 106878280, 757183891, 2913957588, 160418091, 2025664758, 141497907, 1657818026, 3053760160, 672193054, 4157546743, 223046484, 1623470498, 1201972930, 675008814, 684162366, 1738776330, 3025656654, 159760723, 1908867305, 3933381342, 2545706671, 467196949, 1427819885, 842150314, 4032903454, 2140851898, 3269883445, 975813755, 4177392955, 1556690684, 2535611513, 462962732, 67591358, 1729610528, 2025206740, 3153739740, 3255032049, 4186226368, 1070144624, 3107867195, 1621006038, 63742485, 835629717, 3189842019, 3950227584, 3184714559, 841836938, 1685394870, 657939920, 766156242, 1412314179, 1048281639, 4037161120, 2044490307, 1923947830, 3900790422, 907554295, 276417304, 860658646, 3574201134, 3508771399, 2110232300, 1636296241, 1405006077, 1093408401, 3243057343, 1519791182, 1994660136, 3829840937, 2644974199, 957955566, 3487641161, 1646922510, 1907939989, 3836029453, 3429168778, 201307778, 72550089, 2464394982, 1695794191, 3344785682, 996786130, 3589457196, 1241754792, 1291082245, 4224603667, 1194379475, 2693491244, 881186965, 2705535111, 445306946, 440274268, 1980827733, 2482488861, 3205215943, 2119332222, 2928713046, 1418736938, 652581136, 2474070665, 2208621536, 4171251876, 2303664214, 443762656, 2981912989, 2199228311, 2652261633, 3166738494, 3443009210, 3498764432, 424010848, 4065487566, 2262993542, 1756076712, 1477098233, 2742171915, 306185806, 3610666541, 923091830, 1034267993, 2336668648, 1880719718, 676878038, 3788797208, 3763351494, 3985428106, 1101865631, 1130501258, 3672967388, 3432003530, 4124438011, 1660392285, 4025484827, 2108074566, 3815409682, 42955331, 3248965569, 1643835718, 1246665668, 1071162194, 3814069229, 115491158, 985096811, 3311029186, 2990827378, 3101633320, 1648574497, 1470117052, 174145027, 2019894819, 2035501481, 459104123, 3507464599, 2093352659, 3369174406, 618767835, 4009895756, 935587447, 3956987426, 33753995, 307782427, 2473424805, 1440371818, 2382619594, 2138695812, 3164510238, 1318650933, 2910086616, 3886677510, 566832801, 3718063320, 1559818704, 183047272, 1142362855, 26306548, 645536402, 3875596208, 2272778168, 3512733409, 1897046338, 38248886, 2570759766, 1806313150, 860304898, 2433450338, 4124013408, 1216634590, 1275388896, 1169566669, 652504502, 761221427, 1448403764, 3129135949, 2513214949, 1269533687, 2413509541, 1226750363, 2450740925, 4094137910, 945759293, 3636927736, 3178020081, 2509964157, 3878869300, 1848504895, 2018369720, 1579755740, 1023627943, 924838836, 2653160914, 1812804174, 1521323076, 4012390528, 1338763317, 2608655937, 16022784, 1672945066, 2177189646, 2944458483, 2213810972, 1369873847, 1224017670, 130901785, 3595066712, 2259115284, 3316038259, 455873927, 2917250465, 3599550610, 1502173758, 684943436, 3079863840, 3144992244, 942855823, 1771140188, 2118780653, 3411494225, 2711180217, 4239611184, 1371891067, 3398566397, 3105518599, 1310665701, 3345178451, 2959821156, 242241789, 2148966880, 3192740583, 404401893, 3605380577, 1446464038, 3920522056, 2577523013, 1079274576, 286634372, 1752710796, 2351075979, 981312309, 3410516352, 3468455736, 1938779182, 1592494371, 1533303080, 88045436, 438252489, 1220512168, 3487004938, 3724852871, 1073434882, 3728218947, 2977555283, 4105408406, 3553772656, 1462006821, 3917158017, 119003006, 3470530198, 3439192457, 2829375771, 3555715155, 32324691, 588735808, 1459221702, 803072782, 2699519868, 1530797005, 79738580, 671990400, 4289511388, 3207115447, 2584684068, 832698998, 760958416, 1217440464, 2517898131, 2418819938, 3629956222, 3445024962, 206619378, 365007395, 522114139, 1707954431, 540423623, 1786750801, 369253262, 4239016754, 147889201, 1637777773, 236798285, 2806120188, 586972608, 2201782716, 1323327827, 819485723, 406078680, 3407345698, 1537169369, 1821691865, 527271655, 3751827102, 1465426495, 3321682429, 2179672664, 401355478, 1068871880, 24609462, 1403522408, 2311580015, 1532058170, 3877815340, 1768430711, 1619755157, 2832904331, 475102697, 354987331, 3295386430, 2816873951, 1039415736, 363972779, 1499307670, 2895506264, 3746345349, 2678027234, 3251899088, 955392878, 2329157295, 1343358773, 309573887, 2410178377, 2843173466, 361132917, 1755816798, 1319204283, 609284796, 1998842567, 1892325921, 223190385, 1483015769, 2876023365, 3876009312, 3199738344, 491524099, 160383137, 1219178873, 3870310498, 1114580266, 4279604166, 855339774, 1983818547, 2297848784, 4118592947, 4084409863, 2225095054, 4215601993, 946447434, 4205503762, 146088676, 778046685, 1876936928, 3157333726, 2173097090, 3215738813, 4135448234, 1219619643, 1936128689, 2897130162, 3336043946, 3779039524, 4200886837, 1359380925, 3402593091, 3140713935, 50855190, 3122065768, 1501584468, 2512255124, 687125154, 2666013386, 837819715, 3057258172, 3653455791, 2868624990, 322131992, 42534870, 4036564806, 798099710, 3533853670, 190914037, 3726947981, 2601169403, 602059656, 1365668439, 1918780004, 394790500, 277566007, 3891847777, 3365421094, 3139612253, 1380519090, 1183088424, 4203794803, 3049949521, 4214159484, 3446206962, 1875544460, 3207220027, 3288287026, 913535288, 178159620, 1410694581, 4190575040, 880731713, 1427805121, 404869072, 3413191414, 2865934056, 2899472677, 4239222733, 688404529, 3923323887, 933651074, 1199453686, 642723732, 2850614853, 3104368451, 3054041024, 3129913503, 2805843726, 1829781129, 3479062313, 650272704, 4224852052, 4085038685, 2616580676, 1793860711, 585126334, 2995262791, 520446536, 3855655015, 1571815563, 2240778227, 2051010344, 1694977983, 788402852, 1988089041, 2035558649, 1800063056, 1234412692, 2490862867, 417320514, 2415019489, 3374117797, 136034611, 898704236, 1247106941, 3923519397, 3563607190, 2454738671, 3522360389, 2672645476, 146828884, 3985140042, 4233949333, 1184742586, 860278824, 2815489967, 983483427, 3190081845, 3288865305, 3575181235, 1292151129, 4007823805, 4049420597, 3499391972, 1611182906, 1721268432, 2944249577, 2487212557, 789127738, 4027610014, 1057334138, 2902720905, 624), None), 'num_served': 5}
State after resampling 5 batches: {'source_state': {'source_state': None, 'flattened_items_yielded': 0}, 'random_state': (3, (2147483648, 766982754, 497961170, 3952298588, 2331775348, 1811986599, 3100132149, 3188119873, 3937547222, 215718963, 3315684082, 2978012849, 2428261856, 1298227695, 1704729580, 54668373, 3285201915, 3285178464, 1552935063, 988471319, 3135387943, 1691402966, 2757551880, 416056905, 907387413, 1072924981, 33903495, 2168419592, 2429050353, 831159753, 430343641, 3315943586, 1761671042, 864453023, 334804929, 1627478028, 2596811275, 3468733638, 3994375553, 1457139722, 3139722021, 1334790738, 2656639915, 3535811098, 1464315470, 2397423927, 885719490, 1140895889, 3284299483, 2854516462, 2734973817, 147484763, 792049954, 114360641, 3345458839, 1159898878, 1410498733, 2242989638, 453922141, 1344019764, 413870456, 3089405849, 1494382840, 470157779, 4266372830, 2831181573, 1361928602, 1589253513, 1381373062, 753045124, 987032420, 781978839, 2953638767, 3258570111, 3006718191, 1675218601, 1854232715, 3655829819, 1731242722, 2192104666, 1736665161, 740150002, 1195833394, 1610203160, 159492766, 4041488705, 3128952632, 2867295744, 3272632449, 886824304, 1791482600, 221114776, 3867175393, 4020804062, 1077871826, 1298953503, 996366221, 4149754679, 2483052703, 2615558283, 274318093, 1716359450, 4099129961, 1026774175, 288240973, 1459347562, 2365566296, 3690105224, 3065780221, 2050634722, 2652606621, 3185241207, 3026457375, 3456165734, 1880121515, 3398461093, 1795638629, 2379692076, 608668379, 1261955525, 84456522, 1913485156, 106878280, 757183891, 2913957588, 160418091, 2025664758, 141497907, 1657818026, 3053760160, 672193054, 4157546743, 223046484, 1623470498, 1201972930, 675008814, 684162366, 1738776330, 3025656654, 159760723, 1908867305, 3933381342, 2545706671, 467196949, 1427819885, 842150314, 4032903454, 2140851898, 3269883445, 975813755, 4177392955, 1556690684, 2535611513, 462962732, 67591358, 1729610528, 2025206740, 3153739740, 3255032049, 4186226368, 1070144624, 3107867195, 1621006038, 63742485, 835629717, 3189842019, 3950227584, 3184714559, 841836938, 1685394870, 657939920, 766156242, 1412314179, 1048281639, 4037161120, 2044490307, 1923947830, 3900790422, 907554295, 276417304, 860658646, 3574201134, 3508771399, 2110232300, 1636296241, 1405006077, 1093408401, 3243057343, 1519791182, 1994660136, 3829840937, 2644974199, 957955566, 3487641161, 1646922510, 1907939989, 3836029453, 3429168778, 201307778, 72550089, 2464394982, 1695794191, 3344785682, 996786130, 3589457196, 1241754792, 1291082245, 4224603667, 1194379475, 2693491244, 881186965, 2705535111, 445306946, 440274268, 1980827733, 2482488861, 3205215943, 2119332222, 2928713046, 1418736938, 652581136, 2474070665, 2208621536, 4171251876, 2303664214, 443762656, 2981912989, 2199228311, 2652261633, 3166738494, 3443009210, 3498764432, 424010848, 4065487566, 2262993542, 1756076712, 1477098233, 2742171915, 306185806, 3610666541, 923091830, 1034267993, 2336668648, 1880719718, 676878038, 3788797208, 3763351494, 3985428106, 1101865631, 1130501258, 3672967388, 3432003530, 4124438011, 1660392285, 4025484827, 2108074566, 3815409682, 42955331, 3248965569, 1643835718, 1246665668, 1071162194, 3814069229, 115491158, 985096811, 3311029186, 2990827378, 3101633320, 1648574497, 1470117052, 174145027, 2019894819, 2035501481, 459104123, 3507464599, 2093352659, 3369174406, 618767835, 4009895756, 935587447, 3956987426, 33753995, 307782427, 2473424805, 1440371818, 2382619594, 2138695812, 3164510238, 1318650933, 2910086616, 3886677510, 566832801, 3718063320, 1559818704, 183047272, 1142362855, 26306548, 645536402, 3875596208, 2272778168, 3512733409, 1897046338, 38248886, 2570759766, 1806313150, 860304898, 2433450338, 4124013408, 1216634590, 1275388896, 1169566669, 652504502, 761221427, 1448403764, 3129135949, 2513214949, 1269533687, 2413509541, 1226750363, 2450740925, 4094137910, 945759293, 3636927736, 3178020081, 2509964157, 3878869300, 1848504895, 2018369720, 1579755740, 1023627943, 924838836, 2653160914, 1812804174, 1521323076, 4012390528, 1338763317, 2608655937, 16022784, 1672945066, 2177189646, 2944458483, 2213810972, 1369873847, 1224017670, 130901785, 3595066712, 2259115284, 3316038259, 455873927, 2917250465, 3599550610, 1502173758, 684943436, 3079863840, 3144992244, 942855823, 1771140188, 2118780653, 3411494225, 2711180217, 4239611184, 1371891067, 3398566397, 3105518599, 1310665701, 3345178451, 2959821156, 242241789, 2148966880, 3192740583, 404401893, 3605380577, 1446464038, 3920522056, 2577523013, 1079274576, 286634372, 1752710796, 2351075979, 981312309, 3410516352, 3468455736, 1938779182, 1592494371, 1533303080, 88045436, 438252489, 1220512168, 3487004938, 3724852871, 1073434882, 3728218947, 2977555283, 4105408406, 3553772656, 1462006821, 3917158017, 119003006, 3470530198, 3439192457, 2829375771, 3555715155, 32324691, 588735808, 1459221702, 803072782, 2699519868, 1530797005, 79738580, 671990400, 4289511388, 3207115447, 2584684068, 832698998, 760958416, 1217440464, 2517898131, 2418819938, 3629956222, 3445024962, 206619378, 365007395, 522114139, 1707954431, 540423623, 1786750801, 369253262, 4239016754, 147889201, 1637777773, 236798285, 2806120188, 586972608, 2201782716, 1323327827, 819485723, 406078680, 3407345698, 1537169369, 1821691865, 527271655, 3751827102, 1465426495, 3321682429, 2179672664, 401355478, 1068871880, 24609462, 1403522408, 2311580015, 1532058170, 3877815340, 1768430711, 1619755157, 2832904331, 475102697, 354987331, 3295386430, 2816873951, 1039415736, 363972779, 1499307670, 2895506264, 3746345349, 2678027234, 3251899088, 955392878, 2329157295, 1343358773, 309573887, 2410178377, 2843173466, 361132917, 1755816798, 1319204283, 609284796, 1998842567, 1892325921, 223190385, 1483015769, 2876023365, 3876009312, 3199738344, 491524099, 160383137, 1219178873, 3870310498, 1114580266, 4279604166, 855339774, 1983818547, 2297848784, 4118592947, 4084409863, 2225095054, 4215601993, 946447434, 4205503762, 146088676, 778046685, 1876936928, 3157333726, 2173097090, 3215738813, 4135448234, 1219619643, 1936128689, 2897130162, 3336043946, 3779039524, 4200886837, 1359380925, 3402593091, 3140713935, 50855190, 3122065768, 1501584468, 2512255124, 687125154, 2666013386, 837819715, 3057258172, 3653455791, 2868624990, 322131992, 42534870, 4036564806, 798099710, 3533853670, 190914037, 3726947981, 2601169403, 602059656, 1365668439, 1918780004, 394790500, 277566007, 3891847777, 3365421094, 3139612253, 1380519090, 1183088424, 4203794803, 3049949521, 4214159484, 3446206962, 1875544460, 3207220027, 3288287026, 913535288, 178159620, 1410694581, 4190575040, 880731713, 1427805121, 404869072, 3413191414, 2865934056, 2899472677, 4239222733, 688404529, 3923323887, 933651074, 1199453686, 642723732, 2850614853, 3104368451, 3054041024, 3129913503, 2805843726, 1829781129, 3479062313, 650272704, 4224852052, 4085038685, 2616580676, 1793860711, 585126334, 2995262791, 520446536, 3855655015, 1571815563, 2240778227, 2051010344, 1694977983, 788402852, 1988089041, 2035558649, 1800063056, 1234412692, 2490862867, 417320514, 2415019489, 3374117797, 136034611, 898704236, 1247106941, 3923519397, 3563607190, 2454738671, 3522360389, 2672645476, 146828884, 3985140042, 4233949333, 1184742586, 860278824, 2815489967, 983483427, 3190081845, 3288865305, 3575181235, 1292151129, 4007823805, 4049420597, 3499391972, 1611182906, 1721268432, 2944249577, 2487212557, 789127738, 4027610014, 1057334138, 2902720905, 624), None), 'num_served': 5}
All items drawn after resetting are equal: True
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since the <code>state</code> of the iterator is just a dictionary, you can serialize it along with your model weights and restore them to continue training from exact point where you have checkpointed it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Making-Infinibatch-work-with-Pytorch-Dataloaders">
<a class="anchor" href="#Making-Infinibatch-work-with-Pytorch-Dataloaders" aria-hidden="true"><span class="octicon octicon-link"></span></a>Making Infinibatch work with Pytorch Dataloaders<a class="anchor-link" href="#Making-Infinibatch-work-with-Pytorch-Dataloaders"> </a>
</h1>
<p>Infinibatch by its very nature can be used only with <code>IterableDataset</code>. The training iterator with shuffling is infinite, so you must limit the training batches to some <code>n</code> steps if you want to maintain the notion of "epochs" to start validation. Or you can eschew whole notion of epochs by validating every <code>nth</code> step or both.
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>The multi processing workers of <code>DataLoader</code> should be set to zero, with <code>num_workers=0</code>. Rather use <code>ParallelMapIterator</code> to parallelize your pre-processing.
</div>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>While using <code>IterableDataset</code> in the typical multi-gpu <code>DistributedDataParallel</code> (ddp) setup, you should pass <code>instance_rank</code> and <code>num_instances</code> to have different slices of data distributed to different training devices.
</div>
<div class="flash flash-error">
    <svg class="octicon octicon-alert" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path></svg>
    <strong>Warning: </strong>When using finite iterators with <code>ddp</code> for validation set, if you split the data using <code>instance_rank</code> option, the validation can get stuck.This can happen either when your dataset is not divisible by number of <code>ddp</code> processes or doing dynamic batching caused an uneven number of batches produced for each instance. So it’s better to do the validation in one GPU setting <code>instance_rank=0</code>. This is a quick hack, if you find a better option please let me know in the comments.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">IterableDataset</span>


<span class="k">class</span> <span class="nc">IterableCheckpointedDataset</span><span class="p">(</span><span class="n">IterableDataset</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Wraps a CheckpointableIterator into a PyTorch IterableDataset, which is </span>
<span class="sd">    recognized by its type by PyTorch's DataLoader class.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="n">iterators</span><span class="o">.</span><span class="n">CheckpointableIterator</span><span class="p">,</span> 
                 <span class="n">should_reset</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="n">source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source_state</span> <span class="o">=</span> <span class="n">source</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_should_reset</span> <span class="o">=</span> <span class="n">should_reset</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># this is called in the forked clone</span>
        <span class="n">worker_info</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get_worker_info</span><span class="p">()</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">worker_info</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">worker_info</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># not supported since we can't get at the checkpoint for each worker</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_reset</span><span class="p">:</span>
            <span class="c1"># For training, since it's infinite iterator, if we train for </span>
            <span class="c1"># `n` batches with total instances less than dataset size</span>
            <span class="c1"># it's better not to reset the iterator by itself will cycle back</span>
            <span class="c1"># with a new shuffle order when all the instances are iterated once.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">setstate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_source_state</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span>



<span class="k">def</span> <span class="nf">create_wiki_dataloader</span><span class="p">(</span><span class="n">chunks_glob</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                           <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizerFast</span><span class="p">,</span>
                           <span class="n">is_train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
                           <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
                           <span class="n">tokens_per_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">16</span><span class="p">,</span> 
                           <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
                           <span class="n">buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> 
                           <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1337</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
    <span class="n">sentence_it</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">chunked_dataset_iterator</span><span class="p">(</span>
        <span class="n">chunk_refs</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">chunks_glob</span><span class="p">),</span>
        <span class="n">read_chunk_fn</span> <span class="o">=</span> <span class="n">read_chunk</span><span class="p">,</span>
        <span class="n">buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span><span class="p">,</span> 
        <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> 
        <span class="n">train</span><span class="o">=</span><span class="n">is_train</span><span class="p">,</span> 
        <span class="n">shuffle</span><span class="o">=</span><span class="n">is_train</span> <span class="c1"># Shuffle Only on Train</span>
    <span class="p">)</span>
    <span class="n">tokenize_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">features_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">ParallelMapIterator</span><span class="p">(</span>
        <span class="n">source_iterator</span><span class="o">=</span><span class="n">sentence_it</span><span class="p">,</span>
        <span class="n">num_processes</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">num_items_per_process</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">tokenize_fn</span>
    <span class="p">)</span>
    <span class="n">batches_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">BucketedReadaheadBatchIterator</span><span class="p">(</span>
        <span class="n">source_iterator</span><span class="o">=</span><span class="n">features_it</span><span class="p">,</span>
        <span class="n">read_ahead</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> 
        <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">example</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="k">lambda</span> <span class="n">longest</span><span class="p">:</span> <span class="n">tokens_per_batch</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span>
    <span class="p">)</span>
    <span class="n">collate_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>
    <span class="n">tensors_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MapIterator</span><span class="p">(</span>
        <span class="n">batches_it</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">collate_fn</span>
    <span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">IterableCheckpointedDataset</span><span class="p">(</span>
        <span class="n">source</span><span class="o">=</span><span class="n">tensors_it</span><span class="p">,</span>
        <span class="n">should_reset</span><span class="o">=</span><span class="ow">not</span> <span class="n">is_train</span> <span class="c1">#Reset only for validation</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                      <span class="c1"># Very important to set this to 0.</span>
                      <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                      <span class="c1"># Important as we have already batched. </span>
                      <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="c1"># Since batch has only one member which has all the </span>
                      <span class="c1">#tensors already collated, we just return it.</span>
                      <span class="n">collate_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 
                      <span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-cased"</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">create_wiki_dataloader</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">,</span>
                                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                                      <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">val_loader</span> <span class="o">=</span>  <span class="n">create_wiki_dataloader</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">,</span>
                                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                                      <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#print(next(iter(train_loader)))</span>
<span class="c1">#print(next(iter(val_loader)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>

<script type="application/vnd.jupyter.widget-state+json">
{"4ac9de7d40914f9ca3ac2e32b1c83300": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_view_name": "HBoxView", "_dom_classes": [], "_model_name": "HBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_beeaea6b1bfd4d00aa6503086fc58b5c", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_2fbceb9ebded411293cddc95f9ecba35", "IPY_MODEL_4241770e5d5e4cd2b46ef61e553af9cf"]}}, "dcdb7dc95f0846a7a4c1e2fc9c7bd7ea": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_view_name": "HBoxView", "_dom_classes": [], "_model_name": "HBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_8c2b21fcc8324b719144b1cb0bfd0233", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_84848cf9d52541e9866a48172ee108dd", "IPY_MODEL_d043b16a119b48a88757d48f87ab4a2f"]}}}
</script>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="sai-prasanna/saiprasanna.in"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Blog on machine learning, NLP, Computer Science, philosophy, economics, animal rights, music, programming languages and endless other things that pique my curiosity.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/sai-prasanna" title="sai-prasanna"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/sai_prasanna" title="sai_prasanna"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
