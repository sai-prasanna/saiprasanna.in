<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Efficient Dynamic Batching of Large Datasets with Infinibatch | λf.(λg.f (g g)) (λg.f (g g)) Sai</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Efficient Dynamic Batching of Large Datasets with Infinibatch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We will explore how to efficiently batch large datasets with varied sequence length for training using infinibatch." />
<meta property="og:description" content="We will explore how to efficiently batch large datasets with varied sequence length for training using infinibatch." />
<link rel="canonical" href="https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" />
<meta property="og:url" content="https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" />
<meta property="og:site_name" content="λf.(λg.f (g g)) (λg.f (g g)) Sai" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-13T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"We will explore how to efficiently batch large datasets with varied sequence length for training using infinibatch.","@type":"BlogPosting","headline":"Efficient Dynamic Batching of Large Datasets with Infinibatch","dateModified":"2020-09-13T00:00:00-05:00","datePublished":"2020-09-13T00:00:00-05:00","url":"https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/","mainEntityOfPage":{"@type":"WebPage","@id":"https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://saiprasanna.in/feed.xml" title="λf.(λg.f (g g)) (λg.f (g g)) Sai" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Efficient Dynamic Batching of Large Datasets with Infinibatch | λf.(λg.f (g g)) (λg.f (g g)) Sai</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Efficient Dynamic Batching of Large Datasets with Infinibatch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We will explore how to efficiently batch large datasets with varied sequence length for training using infinibatch." />
<meta property="og:description" content="We will explore how to efficiently batch large datasets with varied sequence length for training using infinibatch." />
<link rel="canonical" href="https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" />
<meta property="og:url" content="https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" />
<meta property="og:site_name" content="λf.(λg.f (g g)) (λg.f (g g)) Sai" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-13T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"We will explore how to efficiently batch large datasets with varied sequence length for training using infinibatch.","@type":"BlogPosting","headline":"Efficient Dynamic Batching of Large Datasets with Infinibatch","dateModified":"2020-09-13T00:00:00-05:00","datePublished":"2020-09-13T00:00:00-05:00","url":"https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/","mainEntityOfPage":{"@type":"WebPage","@id":"https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://saiprasanna.in/feed.xml" title="λf.(λg.f (g g)) (λg.f (g g)) Sai" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">λf.(λg.f (g g)) (λg.f (g g)) Sai</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Efficient Dynamic Batching of Large Datasets with Infinibatch</h1><p class="page-description">We will explore how to efficiently batch large datasets with varied sequence length for training using <a href='https://github.com/microsoft/infinibatch/'>infinibatch</a>.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-13T00:00:00-05:00" itemprop="datePublished">
        Sep 13, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      31 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#deep learning">deep learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/sai-prasanna/saiprasanna.in/tree/master/_notebooks/2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/sai-prasanna/saiprasanna.in/master?filepath=_notebooks%2F2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/sai-prasanna/saiprasanna.in/blob/master/_notebooks/2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Challenges-in-efficiently-processing-large-datasets">Challenges in efficiently processing large datasets </a>
<ul>
<li class="toc-entry toc-h2"><a href="#1.-Loading-and-shuffling-large-datasets">1. Loading and shuffling large datasets </a></li>
<li class="toc-entry toc-h2"><a href="#2.-Dynamic-Batching">2. Dynamic Batching </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Tokenization-and-length-distribution">Tokenization and length distribution </a></li>
<li class="toc-entry toc-h3"><a href="#Dynamic-Padding">Dynamic Padding </a></li>
<li class="toc-entry toc-h3"><a href="#General-approach-to-dynamic-batching-and-it's-challenges.">General approach to dynamic batching and it&#39;s challenges. </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Checkpointing-Data-Iteration">Checkpointing Data Iteration </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Infinibatch-to-the-rescue">Infinibatch to the rescue </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Sharding-Dataset-and-shuffling-iterator">Sharding Dataset and shuffling iterator </a></li>
<li class="toc-entry toc-h2"><a href="#Tensorize-our-dataset-with-a-map-iterator">Tensorize our dataset with a map iterator </a></li>
<li class="toc-entry toc-h2"><a href="#Dynamic-Batching">Dynamic Batching </a></li>
<li class="toc-entry toc-h2"><a href="#Checkpointing">Checkpointing </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Making-Infinibatch-work-with-Pytorch-Dataloaders">Making Infinibatch work with Pytorch Dataloaders </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will explore how to efficiently batch large datasets with varied sequence length for training using <a href="https://github.com/microsoft/infinibatch/">infinibatch</a>.</p>
<p>We will focus on solving multiple challenges associated with this together and make it work with dataloaders in pytorch library.Infinibatch is a pure python library which is agnostic of the deep learning library used.
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>We will use <a href="https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/">wikitext-103</a> dataset as an example. It’s a dataset with sentences from wikipedia. It has 103,227,021 word level tokens in it’s training split. It is just for illustration, the techniques we discuss are for scaling for far larger dataset sizes.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="o">!</span>wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip
<span class="o">!</span>unzip wikitext-103-raw-v1.zip
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2020-09-13 16:56:29--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip
Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.43.102
Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.43.102|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 191984949 (183M) [application/zip]
Saving to: ‘wikitext-103-raw-v1.zip’

wikitext-103-raw-v1 100%[===================&gt;] 183.09M  16.5MB/s    in 12s     

2020-09-13 16:56:43 (14.9 MB/s) - ‘wikitext-103-raw-v1.zip’ saved [191984949/191984949]

Archive:  wikitext-103-raw-v1.zip
   creating: wikitext-103-raw/
  inflating: wikitext-103-raw/wiki.test.raw  
  inflating: wikitext-103-raw/wiki.valid.raw  
  inflating: wikitext-103-raw/wiki.train.raw  
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Challenges-in-efficiently-processing-large-datasets">
<a class="anchor" href="#Challenges-in-efficiently-processing-large-datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Challenges in efficiently processing large datasets<a class="anchor-link" href="#Challenges-in-efficiently-processing-large-datasets"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Loading-and-shuffling-large-datasets">
<a class="anchor" href="#1.-Loading-and-shuffling-large-datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Loading and shuffling large datasets<a class="anchor-link" href="#1.-Loading-and-shuffling-large-datasets"> </a>
</h2>
<p>For large datasets, loading the entire data into memory might not be possible. If we are to sample fully random batches, we would need to do random access on huge dataset. Depending on the disk latency this might be unfeasible.</p>
<p>To solve this, we need to</p>
<ol>
<li>Shard the data into chunks larger than single instances so that it reduces the disk access.</li>
<li>We can then shuffle the chunks and load few of them and shuffle the data loaded from the chunks.</li>
</ol>
<p>If we shard the pieces into too big chunks we might end up loosing statistical power in our training updates as we are essentially reducing the randomness of our samples used for training. But we can't shard them too small either as that wouldn't solve our disk access problem.</p>
<p>So a flexible approach would make it easy to control how much data is to be loaded into memory for shuffling. To address this challenge in isolation, you can refer dataset sharding logic in NVIDIA's <a href="https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/data/indexed_dataset.py">MEGATRON language model training code</a> as an example.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Dynamic-Batching">
<a class="anchor" href="#2.-Dynamic-Batching" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Dynamic Batching<a class="anchor-link" href="#2.-Dynamic-Batching"> </a>
</h2>
<p>NLP datasets generally have samples which are of varied lengths. When we batch the data for training on devices like GPU generally we are forced to make them into n-dimensional tensors with fixed dimension. The most common type of input for NLP models is of the shape <strong>Batch size x Sequence length</strong>, where the sequence length is either a fixed value or is the length of longest sequence in that batch. The shorter sequences are generally padded with a <em>padding token</em>.</p>
<p>These padding tokens are wasteful in terms of computation as they are not used to do anything useful other than to overcome the hardware architecture which allows only fixed size tensor computation to be done fast.</p>
<p>Some tutorials and examples you would find for pre-processing data would pad batches to a pre-determined sequence length independent of the elements in each batch. This is completely wasteful as many batches would have all the members less than the pre-deterimend length.</p>
<p>A better option is to pad the elements of each batch to the sequence length which is maximum in that batch. This <strong>dynamic padding</strong> can improve efficiency but it doesn't solve the entire problem. Let's see why with an example.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tokenization-and-length-distribution">
<a class="anchor" href="#Tokenization-and-length-distribution" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tokenization and length distribution<a class="anchor-link" href="#Tokenization-and-length-distribution"> </a>
</h3>
<p>Let's implement a typical dynamic batching workflow with pytorch dataloader and a subword level tokenizer. We use BERT-base-cased tokenizer from huggingface's transformers library. This  tokenizes words to subwords. The BERT model was pre-trained with maximum subword length of 512. We can theoretically use sequence lengths larger than that but for our purposes  we will leave it as such at 512.</p>
<p>We will use torch's <a href="https://pytorch.org/docs/stable/data.html">dataset and dataloader</a> abstraction for this. It will as both an illustration of real world usage and is convinent as it helps avoid having to entire tokenized dataset in memory We still have to load the sentences into memory once. This is not a problem for small datasets, but for very large corpuses it's a big problem. We will see soon that infinibatch solves also this problem elegantly.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="o">!</span>pip install git+https://github.com/microsoft/infinibatch.git transformers torch
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">PreTrainedTokenizerFast</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Wiki103</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizerFast</span><span class="p">,</span> <span class="n">data_path</span><span class="o">=</span><span class="s2">"wikitext-103-raw/wiki.train.raw"</span><span class="p">,</span> <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">dp</span><span class="p">:</span>
            <span class="c1"># We are </span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">dp</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sentences</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-cased"</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">wiki_dataset</span> <span class="o">=</span> <span class="n">Wiki103</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">sequence_lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">wiki_dataset</span><span class="p">)):</span>
    <span class="n">sequence_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>1164464it [04:14, 4568.74it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Plotting the truncated subword token length distribution we see that the distribution is wide with a large variance.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">'fivethirtyeight'</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#0504aa'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'y'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Subword Sequence Length'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Sequence Length Distribution'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAhQAAAFpCAYAAADELrFnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVxU9f4/8BegiEBwAGVREFwGcENByVwQDfGCluCWKIFKXrtkImQgqGmuoIRoSaampgjaVwvQXBLTvIZretN+uTBmLmiuOIIOiwK/P7yc6zgszgyr83o+Hjyu8zmf8zmfeTPdeXHOZ87oyGSyMhARERFpQLe+J0BERESNHwMFERERaYyBgoiIiDTGQEFEREQaY6AgIiIijTFQEBERkcYYKIiek5KSAk9PT9ja2sLe3h4eHh6YOXNmfU+rwYuNjUW7du3qexqi4uJixMbG4uzZswrtV69ehSAI2Lt3r8pjhoaGQhAECIIACwsLtG3bFj4+PkhMTMTDhw8V+h4+fBiCIODcuXMvNfbdu3cRGxuLq1evvvR8BEHAmjVrxMdDhw5FcHDwS+9flbS0NKSkpCi11+Qx6NXDQEH0X8uWLUNYWBi8vLyQnJyMr776CkOGDMGePXvqe2qkouLiYixZsgS///57jY7r6OiIzMxM7NmzB1999RX69euHL774Av3791cIA926dUNmZibatm37UuPevXsXS5YswbVr1156LpmZmfD391f5ObyMtLQ0pKamKrUnJCRg7ty5tXJMavya1PcEiBqKtWvXYuLEiZgzZ47Y5uvri+jo6HqcFTUkhoaGcHd3Fx//4x//wMSJE+Hl5YUpU6bghx9+AACYmJgo9KtJBQUFaN68ea2NXxVnZ+c6PyY1HjxDQfRfDx8+hKWlpVK7jo6OwuPCwkLMmTMHnTt3hqWlJfr27Yt9+/Yp9CkqKkJkZCTatGkDBwcHxMTEICkpCYIgiH1SUlIgCAIePXqksG/Xrl0xe/ZshbZdu3ZhwIABsLKygqOjI+bMmYMnT56I28svOZw5cwaDBg2CjY0NPDw8cOTIEaXns3HjRvTp0wdWVlaQSCQIDg5WOGV/5MgRDBkyBDY2Nmjbti3CwsKQn5//EhWs2rlz5/DOO+/A1tYWtra2GD9+PG7fvi1uL79McPjwYYwfPx6tW7dGt27d8PXXXyuNtWbNGnTu3BmtWrXCuHHjcOjQIXFfALC1tQUATJkyRbxM8fwZhIKCAoSHh6NNmzbo1KkTFi9ejNLSUrWeV+vWrREVFYVffvkF2dnZCs/l+UsemzZtQq9evWBtbY127dphyJAhOH/+PK5evYo+ffoAAN5++21xvs+P89NPPyEgIACtW7dGZGQkAOVLHuW++eYbdO3aFdbW1njnnXdw8+ZNpRq/eCnm+UsZoaGh2LFjB7KyssS5xMbGKvUrd+jQIXh5eYmvp+nTpyu8plX5vVLjxkBB9F/dunXDmjVrkJqaitzc3Er7jR8/Hqmpqfjoo4+wdetWuLm5YezYsQrX6z/99FNs2rQJkZGRWLt2La5fv46kpCS15pWWloagoCD06NEDW7ZswYwZM/DNN99g3rx5Cv0KCgoQGhqKCRMmYNOmTWjWrBmCgoIgl8vFPvHx8QgPD0ffvn2RkpKChIQEmJiY4PHjxwCAY8eOwd/fH1ZWVti4cSNiY2ORmZmJKVOmqDX3cpcvX4aPjw8KCwuxevVqJCUl4cKFCwgICEBZmeLd/6dNm4YuXbpg8+bN6NevHz7++GOcOnVK3L5z505ERUXB19cXmzdvRufOnfHhhx8qjLFjxw4AwMcff4zMzExkZmbC2tpa3D5nzhwYGRlh48aNeOedd7B06VJkZGSo/fwGDhwIADh58mSF27OysvDRRx9hzJgx2LZtG1auXIlevXohLy8P1tbWWLt2LQDgs88+E+f7vKlTp6JLly5ITU1FUFBQpfM4efIk1qxZg0WLFuGLL77AH3/8gcDAQJWeS1RUFDw8PODi4iLOpbJ1E+fPn8eoUaNgYWGBTZs2ISYmBtu2bcP48eOV+lb3e6XGj5c8iP4rPj4egYGB+OCDD6CjowMnJye8/fbbmDp1KkxMTAA8+2vsxx9/xA8//IB+/foBAN58801cunQJCQkJ2LhxI3Jzc7FhwwbExMRg6tSpAAAvLy/06tVL5TmVlZXhk08+QUBAABISEsR2fX19REZG4qOPPoK5uTmAZ4EiNjYWnp6eAAArKyv0798fR44cwaBBgyCTybBs2TKEhoZi8eLF4ljDhg0T/z1v3jy8/vrr2LBhg9hmY2MDPz8/nDt3Dp06dVL5OQBAXFwcLC0tsX37dujr6wMAunTpAnd3d+zbtw//+Mc/xL4jR44U/wrv168f9u7di507d6JHjx4Anq11GTx4MD777DMAz+qfm5uLdevWiWO4ubkBANq2bVvhpYE+ffpg0aJFAJ6Fgf3792Pnzp0YPny4Ws+vVatWAJ6thajI6dOn0blzZ3z00Udi25AhQ8R/d+7cGQDg5ORU4Xz9/PyUzlpV5O7du9i3bx/s7OwAAHZ2dvDx8cH+/fsxaNCgl3oubdu2hZmZGUpLS6u9rBIfHw87Ozts2bIFenp6AAAzMzNMnDgRJ06cwOuvvy72re73So0fz1AQ/VeXLl1w4sQJbNmyBZMmTUJZWRni4+MxcOBA8RTuzz//DCsrK7zxxht4+vSp+OPp6Yn//Oc/AIA//vgDhYWFCm8Yurq6Co9f1qVLl5CTk4Phw4crHK9///4oLCxUOHWtr68PDw8P8XH59e7yU94nT55EQUFBpX+xyuVynDhxQulYvXv3RtOmTfHbb7+pPP9yhw4dwltvvQVdXV1xXHt7e7Rp00asW7k333xT/HfTpk3Rvn178Tk8ffoUZ8+eha+vr8I+Lz6uzvPHAJ7V6vlLA6p68SzLi7p27YqzZ88iJiYGWVlZKC4uVmn85wNXVbp16yaGCQB444030LJly1o7E3Dq1Cm89dZbYpgAngXUJk2a4NixYwp9q/q90quBZyiIntOsWTP4+vqKb1CbNm1CWFgYkpOTERoaivv37+P27dto0aKF0r7l/6d6584dAEDLli0Vtle0T3Xu378PABg9enSF22/cuCH+29jYGLq6//sbofxMQGFhIQCIl3GeP/X/PJlMhpKSEkyfPh3Tp0+v8liqun//PpYvX47ly5dXO66pqanC46ZNm4rP4f79+ygpKYGFhYVCH1VrW9Ux1PH3338DUP6dlxswYACSkpKwevVqfPXVVzA2NsaYMWMwb948GBkZVTt+ZeO+qKI6tGzZUmGtSk26ffu20tz09PRgbm6OBw8eKLTXdM2p4WGgIKpCcHAw5s6dC6lUCuDZ6dxWrVpV+Bn9cuULO+/evQszMzOx/d69ewr9DAwMAEBhcSUAhQWS5fuvWLECLi4uSseyt7d/6edSfmnk1q1bSm/IwLP/w9fR0UF0dDQGDx6stL2yIPIyzMzM8NZbb1V4Lb58Xi/DwsICenp6YtAq92Jt69qBAwcAQOEU/4vGjRuHcePG4d69e9i5cydmzpwJY2NjfPrpp9WO/+LC4MpUVIe7d+/CysoKwP9ecy+eIZHJZBW+JqpjZWWldMySkhLk5uYqvPZJOzBQEP3X3bt3lf7aunfvHvLy8sR2T09PrFy5EkZGRnB0dKxwnM6dO8PAwAC7d+8W+5SWlmL37t0K/cqvu1+8eBFvvPEGAODXX39FXl6e2EcikaBVq1a4du1ahQvdVOHu7o7mzZtjy5YtWLhwodJ2IyMjuLu749KlS5gxY4ZGx3qRp6cnLly4gO7du7/0m2NFmjRpAhcXF+zevRsTJ04U21+8V0j52ZmioiK1j/Wybty4gfj4eHh4eEAikVTbv0WLFpg4cSJ27tyJCxcuAKi5+Z45cwbXr18XL3scO3YMd+/eFdcplL/msrOz0b17dwBATk4OpFIp2rdvL46jr6//UnPp2bMnfvjhB8yZM0c8Q7dz5048ffpUfE2T9mCgIPqvPn36YMiQIXjzzTfRokULXL9+HV988QUMDQ0xduxYAM8W8Hl5eWH48OGYNm0anJ2dkZ+fj99//x1FRUWYO3cuzM3NMX78eMTGxkJPTw8dO3bExo0bxU9SlOvRowdatWqFGTNmYNasWXjw4AFWrFghLgAFnq29WLhwId5//33k5eXB29sb+vr6uHLlCnbt2oWNGzfC0NDwpZ6fIAiIjIzEggULUFxcjMGDB6OoqAj79u3DjBkz0KpVK8ybNw9+fn7Q0dGBn58fjI2NkZOTg3379uGTTz5Bhw4dKh3/yZMnFX5Som/fvoiOjsabb76Jd955B++++y7Mzc3x999/4+DBgxg3bpzC2o/qREREIDg4GJGRkfD19cWxY8fw448/ivUCnr0h2tvbIy0tDR07doSBgYG48FETcrkcJ0+eRFlZGR4+fIjjx49jw4YNMDY2rvJTPIsXL8aDBw/Qr18/WFhY4OzZs8jKyhJvEmVrayuGPRMTEzRt2hSurq4qz69FixYYM2YMoqOjUVRUhE8//RTdunUTF2S2bt0arq6uWLRoEZo3b47S0lIsW7ZM6WyCRCLB7t278cMPP6B169awtraGjY2N0vE+/vhj9O/fH+PGjcN7772HmzdvYu7cufDy8qrybA29mhgoiP4rKioKu3fvxowZM/DgwQNYWlqiV69e2LBhAxwcHAA8O/WcnJyMhIQErFq1Cjk5OTAzM0PXrl0xefJkcaz58+fj6dOniI+Ph46ODt555x188MEHCiv19fX1sXnzZkyfPh3jx49Hhw4dsGzZMvzzn/9UmNeIESPw2muvYdmyZUhJSYGenh7s7e3h4+Mj/mX7sj766COYmZnhq6++wjfffANBENCnTx8YGxsDAHr37o3du3cjNjYW//rXv1BSUgI7Ozt4eXlVex0/Pz+/wrMoO3fuhIeHB/bv34+FCxdi2rRpKCwshI2NDTw9PVW+ZfewYcOwZMkSrFixQvwI4sKFCzFhwgS89tprYr/ExETMnj0b/v7+KCoqwpkzZ1Q6TkWys7Ph7e0NXV1dmJiYwMnJCR9++CFCQkKU1gg8z83NDV9++SW+//57PHr0CHZ2doiOjkZoaCiAZ5ciVqxYgSVLlmDo0KF48uQJZDKZyvN7/fXXMWDAAMycORP37t1Dv379lNatrFu3DlOnTsX7778vhsgvv/xSoc+kSZNw9uxZfPjhh5DJZJgxYwZiYmKUjtexY0ds374d8+fPR1BQEF577TWMGjVK6SPNpB10ZDJZ1cuTiahGrFmzBlFRUWq9UVDV4uPjkZCQgL/++gvNmzev7+kQaSWeoSCiRuXevXtYtmwZPDw8YGhoiCNHjmDFihUICgpimCCqRwwURNSoNG3aFFKpFFu3bhXvNPmvf/0Ls2bNqu+pEWk1XvIgIiIijfFOmURERKQxBgoiIiLSGAMFERERaYyBgoiIiDTGQNHAlX+HBKmGdVMfa6ce1k19rJ36GlLtGCiIiIhIYwwUREREpDEGCiIiItIYAwURERFpjIGCiIiINMZAQURERBpjoCAiIiKNMVAQERGRxhgoiIiISGMMFERERKQxBgoiIiLSWJP6ngC9vMBxpyvdlpLqVoczISIiUsQzFERERKQxBgoiIiLSGAMFERERaYyBgoiIiDTGQEFEREQaY6AgIiIijTFQEBERkcYYKIiIiEhjDBRERESkMQYKIiIi0hgDBREREWmMgYKIiIg0xkBBREREGmOgICIiIo0xUBAREZHGGCiIiIhIYwwUREREpDEGCiIiItIYAwURERFpjIGCiIiINFangSIjIwODBw9G27ZtYWVlhZ49eyI+Ph7FxcVin7KyMiQkJKBz586wtraGr68vzp49qzTWhQsXMGzYMNjY2MDZ2RmLFi1CSUmJQp/6GIuIiEgb1WmgyM3NRf/+/fH5559j27ZtePfdd5GQkIBZs2aJfRITExEfH49p06Zh69atMDY2hr+/P27fvi32kclk8Pf3h46ODlJTUxEVFYWkpCTExsYqHK+uxyIiItJWTeryYBMnTlR43L9/f+Tn52Pt2rVYunQpioqKsHz5ckRERGDy5MkAAHd3d7i4uGDt2rWYPXs2AGD9+vUoKChAcnIyTExMMHDgQOTn5yMuLg5hYWEwMTFBYWFhnY9FRESkrep9DYWZmRmePHkCADh+/Djy8vIwfPhwcbuRkRF8fHyQmZkptmVmZsLLywsmJiZi24gRI1BQUICsrKx6G4uIiEhb1UugKCkpgVwux9GjR7F69WqEhIRAR0cHUqkUenp6aN++vUJ/JycnSKVS8bFUKoVEIlHoY2dnB0NDQ7FffYxFRESkrer0kke5Vq1aoaioCAAQEBCABQsWAHi2nsHIyAh6enoK/QVBgFwuR3FxMfT19SGTyWBqaqo0riAIkMlk9TZWZXJycqorSZXK9y8sLKy1Y7yKWBP1sXbqYd3Ux9qpr65qZ2trW+X2egkUP/74IwoKCnDq1CksXboUkZGRSEhIqI+p1InqfglVkUql4v4GBndq5RivoufrRqph7dTDuqmPtVNfQ6pdvQSK7t27AwB69+4NCwsLhIaG4sMPP4QgCHj8+DFKSkoUzgbIZDIYGhqKZwEEQUBeXp7SuDKZDIIgiH3qeiwiIiJtVe+LMrt16wYAuHr1KiQSCUpKSnD58mWFPtnZ2QrrHCQSidLahZycHMjlcrFffYxFRESkreo9UBw/fhwAYG9vj169esHExATp6enidrlcjr1798Lb21ts8/b2xk8//YT8/HyxLS0tDc2bN0ffvn0BoF7GIiIi0lZ1eslj5MiRGDBgAJydnaGnp4djx44hKSkJI0aMQNu2bQEA4eHhiI+PhyAIcHR0RFJSEkpLS8X7PwBASEgIVq9ejaCgIISHh+PKlSuIi4vDlClTxI9/GhgY1PlYRERE2qpOA4WrqytSU1Nx7do16OnpwcHBAXPmzEFISIjYJyIiAqWlpUhMTERubi5cXV2RlpYGS0tLsY8gCMjIyEBkZCQCAgJgamqK0NBQxMTEKByvrsciIiLSVjoymaysvidBlXv+PhmB405X2i8l1a2uptQoVHR/EXo5rJ16WDf1sXbqa0i1q/c1FERERNT4MVAQERGRxhgoiIiISGMMFERERKQxBgoiIiLSGAMFERERaYyBgoiIiDTGQEFEREQaY6AgIiIijTFQEBERkcYYKIiIiEhjDBRERESkMQYKIiIi0hgDBREREWmMgYKIiIg0xkBBREREGmOgICIiIo0xUBAREZHGGCiIiIhIYwwUREREpDEGCiIiItIYAwURERFpjIGCiIiINMZAQURERBpjoCAiIiKNMVAQERGRxhgoiIiISGMMFERERKQxBgoiIiLSWJ0GivT0dAQEBKBjx45o3bo1PD09sX37doU+Q4cOhSAISj+FhYUK/W7evInAwEDY2tqiXbt2iIyMhFwuVzrmxo0b4ebmBisrK3h6euLQoUNKfWpyLCIiIm3UpC4PlpSUBHt7eyxevBjm5ubIzMzEpEmTcP/+fbz//vtiPw8PD8yZM0dh32bNmon/fvLkCUaOHImmTZti3bp1ePjwIWbNmoWHDx9izZo1Yr/t27cjIiIC0dHReOONN5CSkoIxY8bgwIED6NSpU42PRUREpK3qNFBs3boVFhYW4mNPT0/cunULSUlJCoHCzMwM7u7ulY6TkZGBixcv4vTp03BwcAAANG3aFCEhIZgxYwbat28PAIiLi8PYsWMRFRUFAOjXrx9+//13LF++XAwLNTkWERGRtqrTSx7Ph4lyLi4uuHXrlkrjZGZmws3NTQwAwLNLJfr6+ti/fz8A4MqVK7h06RKGDx8u9tHV1YWfnx8yMzNrZSwiIiJtVe+LMk+cOIEOHTootB08eBA2NjawsbHBiBEj8P/+3/9T2C6VSiGRSBTa9PX10bZtW0ilUgBAdnY2ACj1c3JywoMHD3Dv3r0aH4uIiEhb1ekljxcdOnQIu3btwsqVK8W2vn37YuzYsWjXrh2uX7+OhIQEDBkyBIcPH4a9vT0AQCaTwdTUVGk8QRAgk8nEPgCU+gmCIG5v0aJFjY5VmZycnCqqUL3y/V9cmFqTx3gVsSbqY+3Uw7qpj7VTX13VztbWtsrt9RYorl69ikmTJmHIkCEIDAwU22fOnKnQb8CAAXB3d8eqVasQFxdX19OsEdX9EqoilUrF/Q0M7tTKMV5Fz9eNVMPaqYd1Ux9rp76GVLt6ueTx4MEDjB49GnZ2dli7dm2Vfa2srPDGG2/gzJkzYpsgCMjLy1PqK5PJxLMG5f/7Yr/ysw3P96upsYiIiLRVnQcKuVyOMWPGoLi4GN9++y0MDQ2r3UdHRwc6OjriY4lEIq5vKFdcXIwrV66I6xwcHR0BQKlfdnY2zMzMxEsUNTkWERGRtqrTQPH06VNMmDABf/75J7777ju0bNmy2n1u376No0ePonv37mKbt7c3Tp8+jWvXrolte/bsQVFREQYNGgQAcHBwQIcOHZCeni72KS0tRXp6Ory9vWtlLCIiIm1Vp2sopk+fjn379iEuLg65ubnIzc0Vt7m4uEAqlWL+/Pnw8/ODnZ0dcnJykJiYCF1dXYSGhop9/fz8kJCQgKCgIMyaNQt5eXmYOXMmRo8eLd43AgCio6MxefJktGnTBr169cKWLVtw+fJlfP3117UyFhERkbaq00Bx4MABAM/enF905swZmJubo6ysDPPnz0dubi6MjY3Rr18/pKSkwM7OTuzbtGlTbN++HZGRkZg4cSL09fUxcuRIzJ8/X2HMUaNG4fHjx1i+fDni4+Ph7OyMb7/9VuHOljU5FhERkbbSkclkZfU9Carc8/fJCBx3utJ+KaludTWlRqGi+4vQy2Ht1MO6qY+1U19Dql2939iKiIiIGj8GCiIiItIYAwURERFpjIGCiIiINMZAQURERBpjoCAiIiKNMVAQERGRxhgoiIiISGMMFERERKQxBgoiIiLSGAMFERERaYyBgoiIiDTGQEFEREQaY6AgIiIijTFQEBERkcYYKIiIiEhjDBRERESkMQYKIiIi0hgDBREREWmMgYKIiIg0plKg+OOPP2prHkRERNSIqRQo+vXrh4EDB2LdunWQyWS1NSciIiJqZFQKFDt27ICTkxPmzp2Ljh074r333sPBgwdRVlZWW/MjIiKiRqCJKp09PDzg4eGBx48f4/vvv0dqaipGjBiB1q1bIyAgAIGBgWjbtm1tzZWIiIgaKLUWZRoZGSEoKAh79uzBr7/+Cjs7Oyxbtgw9evTAkCFDsHPnzpqeJxERETVgan/K4+rVq4iNjcWIESNw8uRJeHt7Y/ny5bC0tERISAhiYmJqcp5ERETUgKl0yUMulyMjIwMpKSk4evQo7O3tMX78eIwbNw7W1tYAgODgYGzevBkxMTGIjY2tlUkTERFRw6JSoHB0dERpaSneeustpKenw8PDo8J+bm5uMDMzq5EJEhERUcOnUqCYN28eRo0aBVNT0yr7derUCWfPntVoYkRERNR4qLSG4r333qs2TFQlPT0dAQEB6NixI1q3bg1PT09s375dqd/GjRvh5uYGKysreHp64tChQ0p9bt68icDAQNja2qJdu3aIjIyEXC6v97GIiIi0kUqBYsqUKQgJCalw23vvvYewsLAq909KSoKxsTEWL16M1NRUeHh4YNKkSVi9erXYZ/v27YiIiEBAQAC2bdsGZ2dnjBkzBufOnRP7PHnyBCNHjsT169exbt06xMXFIT09HeHh4QrHq+uxiIiItJVKlzx+/vlnLFq0qMJtw4YNw6xZs6rcf+vWrbCwsBAfe3p64tatW0hKSsL7778PAIiLi8PYsWMRFRUF4NndOX///XcsX74ca9asAQBkZGTg4sWLOH36NBwcHAAATZs2RUhICGbMmIH27dvXy1hERETaSqUzFPfu3at0saUgCLh7926V+z8fJsq5uLjg1q1bAIArV67g0qVLGD58+P8mqKsLPz8/ZGZmim2ZmZlwc3MTAwAADB06FPr6+ti/f3+9jUVERKStVAoUdnZ2yMrKqnBbVlYWWrVqpfIETpw4gQ4dOgAAsrOzAQASiUShj5OTEx48eIB79+4BAKRSqVIffX19tG3bFlKptN7GIiIi0lYqXfIYN24clixZgpYtW2Ls2LEwNjbGo0ePsHXrVnz++eeYMWOGSgc/dOgQdu3ahZUrVwKA+IVjLy78FARB3N6iRQvIZLIKF4cKgiCOUR9jVSYnJ6fSbS+jfP/CwsJaO8ariDVRH2unHtZNfayd+uqqdra2tlVuVylQhIeH46+//kJUVBRmzJgBIyMjPH78GGVlZZgwYYLSQsaqXL16FZMmTcKQIUMQGBioyjQanep+CVWRSqXi/gYGd2rlGK+i5+tGqmHt1MO6qY+1U19Dqp1KgUJXVxdffPEFwsLC8O9//xsPHjyAubk5+vfvL162eBkPHjzA6NGjYWdnh7Vr14rt5X/x5+Xlif8G/neGoLxNEATk5eUpjSuTydClS5d6G4uIiEhbqRQoykkkEqX1BC9LLpdjzJgxKC4uxrfffgtDQ0Nxm6OjI4BniatNmzZie3Z2NszMzMTLChKJRFzfUK64uBhXrlzBxIkT620sIiIibaXWl4NdunQJhw4dwr59+5R+qvL06VNMmDABf/75J7777ju0bNlSYbuDgwM6dOiA9PR0sa20tBTp6enw9vYW27y9vXH69Glcu3ZNbNuzZw+KioowaNCgehuLiIhIW6l0huLChQsICQnBhQsXUFZWprRdR0cHubm5le4/ffp07Nu3D3FxccjNzVXo6+LigmbNmiE6OhqTJ09GmzZt0KtXL2zZsgWXL1/G119/Lfb18/NDQkICgoKCMGvWLOTl5WHmzJkYPXq0eN8IAHU+FhERkbZSKVBERESguLgYycnJcHZ2RtOmTVU62IEDBwA8e3N+0ZkzZ2Bvb49Ro0bh8ePHWL58OeLj4+Hs7Ixvv/0WnTp1Evs2bdoU27dvR2RkJCZOnAh9fX2MHDkS8+fPVxizrsciIiLSVjoymUz5VEMlWrdujXXr1sHHx6c250TPef4+GYHjTlfaLyXVra6m1GuyGsAAACAASURBVChUdH8RejmsnXpYN/WxduprSLVTaQ2Fg4MDioqKamsuRERE1EipFCgWLVqEhIQEXLlypZamQ0RERI2RSmso5s2bh7///hvu7u5o06ZNhXeYLF8nQURERNpDpUDRsWNHdOzYsbbmQkRERI2USoHiyy+/rK15EBERUSOm1o2tysrKkJOTg+PHj+Px48c1PSciIiJqZFQOFF9//TU6duyIrl27wtfXV7xt9bvvvsszGERERFpKpUDx+eefY9asWQgODsaOHTsU7pbZr18/pKWl1fgEiYiIqOFTaQ3F2rVrMXPmTEybNg0lJSUK2yQSCS5dulSjkyMiIqLGQaUzFHfu3EH37t0rHkhXlze9IiIi0lIqBYp27drhl19+qXBbVlYWnJycamRSRERE1LiodMkjNDQU06dPh76+Pvz8/AAA9+7dw6ZNm/Dll19ixYoVtTJJIiIiathUChTBwcGQyWRYunQpYmNjAQCjR4+GoaEhoqOjMXr06FqZJBERETVsKgUKAAgLC8PEiRNx4sQJ5ObmwszMDO7u7hXehpuIiIi0g8qBAgBee+01eHl51fRciIiIqJFSKVB8/fXX1faZNGmS2pMhIiKixkmlQBEZGVnpNh0dHQAMFERERNpIpUDx4MEDpTaZTIYDBw5g+fLlWLduXY1NjIiIiBoPtdZQPE8QBIwYMQJ5eXkIDw/Hrl27amJeRERE1Iio9W2jFbG3t8dvv/1WU8MRERFRI1IjgeLWrVtYuXIl7O3ta2I4IiIiamRUuuTRvn17cfFlueLiYjx69AgGBgZITk6u0ckRERFR46BSoJg0aZJSoDAwMECrVq0waNAgmJub1+jkiIiIqHFQKVDExMTU1jyIiIioEauxRZlERESkvVQ6Q+Hi4qJ0yaMqZ86cUXlCRERE1PioFCj8/Pzw/fffQy6XY+DAgWjRogXu3buHgwcPwsjICMOHD6+teRIREVEDplKgEAQBDg4O+L//+z8YGRmJ7Y8ePcKYMWNgYmJS5e25iYiI6NWk0hqKr7/+GmFhYQphAgCMjY0xderUl/rysMuXLyM8PBx9+vSBubk5hg4dqtSna9euEARB4cfR0VGp34ULFzBs2DDY2NjA2dkZixYtQklJiUKfsrIyJCQkoHPnzrC2toavry/Onj1bq2MRERFpG5XOUOTn5+POnTsVbrtz5w4eP35c7Rjnz59HZmYmevbsiadPn1bab/To0Zg8ebL4uGnTpgrbZTIZ/P394eTkhNTUVPz111+YPXs2ysrKMHv2bLFfYmIi4uPjMX/+fDg6OiIpKQn+/v44evQorKysanwsIiIibaRSoPDx8cGcOXNgYmICX19f6Ovro7i4GLt378bcuXPh4+NT7Ri+vr7iWYng4GDcv3+/wn5WVlZwd3evdJz169ejoKAAycnJMDExwcCBA5Gfn4+4uDiEhYXBxMQEhYWFWL58OSIiIsRw4u7uDhcXF6xdu1YMCzU5FhERkTZS6ZJHQkIC+vTpgwkTJsDa2hpt2rSBtbU1Jk6ciN69eyMhIaH6A+rWzCdVMzMz4eXlBRMTE7FtxIgRKCgoQFZWFgDg+PHjyMvLU1gsamRkBB8fH2RmZtbKWERERNpIpXd3U1NTpKSk4MiRI/jiiy/w0UcfYeXKlTh69ChSU1NhampaYxNLTk5Gy5Yt0aZNGwQHB+PatWsK26VSKSQSiUKbnZ0dDA0NIZVKxT56enpo3769Qj8nJyexT02PRUREpI3U+vryjh07omPHjjU9F9GQIUPg7u6OVq1aITs7G0uWLMGQIUOQlZUlhhaZTFZhgBEEATKZTOxjZGQEPT09pT5yuRzFxcXQ19ev0bGIiIi0kcqB4u7du1i5ciX+85//4ObNm0hOTkbHjh2xatUq9OjRA6+//rrGk1qyZIn47z59+uD111+Hh4cHUlJS8MEHH2g8fl3Lycmpkf0LCwtr7RivItZEfaydelg39bF26qur2tna2la5XaVAcerUKQwfPhwWFhbo27cvfvnlFxQVFQEAbt++jZUrV2LTpk3qz7YSnTp1gkQiUbjzpiAIyMvLU+ork8kgCILY5/HjxygpKVE4syCTyWBoaCieUajJsSpS3S+hKlKpVNzfwKDiT9hoeoxX0fN1I9Wwduph3dTH2qmvIdVOpTUUM2fORL9+/XDq1CksX74cZWVl4jY3NzecPn26xidYTkdHR+G23xKJRGntQk5ODuRyubgeQiKRoKSkBJcvX1bol52drbBmoibHIiIi0kYqBYozZ85g0qRJ0NXVVfpOD3Nzc9y9e7dGJ1fu3LlzyM7ORvfu3cU2b29v/PTTT8jPzxfb0tLS0Lx5c/Tt2xcA0KtXL5iYmCA9PV3sI5fLsXfvXnh7e9fKWERERNpIpUseJiYmuHfvXoXbrly5gpYtW1Y7hlwuFz9m+ffffyM/Px8ZGRkAnr2xHz58GP/3f/+Hf/zjH7C2toZUKsVnn30GW1tbjBs3ThwnJCQEq1evRlBQEMLDw3HlyhXExcVhypQp4sc/DQwMEB4ejvj4ePFum0lJSSgtLVW4aVZNjkVERKSNVAoUvr6+iI2Nxeuvvw47OzsAzy5F3L9/HytXrsTbb79d7Rh3797F+PHjFdrKH585cwatW7fG3bt3ERMTg4cPH8Lc3BxeXl7iDbXKCYKAjIwMREZGIiAgAKampggNDUVMTIzC2BERESgtLUViYiJyc3Ph6uqKtLQ0WFpa1spYRERE2khHJpOVVd/tGZlMhmHDhuHixYvo3r07Tpw4ATc3N1y+fBn29vbYuXMnXnvttdqcr9Z5/h4ZgeMqX6OSkupWV1NqFCq6twi9HNZOPayb+lg79TWk2qn8baP79+/H1q1b8e9//xuGhoYwMzNDcHAwAgIC0KxZs9qaJxERETVgLx0oCgsLMXbsWHz00UcIDg5GcHBwbc6LiIiIGpGX/pSHgYEBTp8+jdLS0tqcDxERETVCKn1s1NfXFz/88ENtzYWIiIgaKZXWUJR/2uL27dvw9vaGpaWl0v0oBg8eXKMTJCIiooZPpUBRfr+FnTt3YufOnUrbdXR0kJubWzMzIyIiokaj2kAxfPhwLF26VPwujbKyMhw6dAg9e/aEsbFxXcyRiIiIGrhqA8XPP/8sfnFWmzZtUFJSgvDwcBw4cABt2rSp9QkSERFRw6fSosxyz38pGBEREZFagYKIiIjoeS8VKF78JEdlbURERKSdXupTHiNGjECTJopd/fz8lNoA4NKlSzUzMyIiImo0qg0UM2bMqIt5EBERUSNWbaCIjo6ui3kQERFRI8ZFmURERKQxBgoiIiLSGAMFERERaYyBgoiIiDTGQEFEREQaY6AgIiIijTFQEBERkcYYKIiIiEhjDBRERESkMQYKIiIi0hgDBREREWmMgYKIiIg0xkBBREREGmOgICIiIo0xUBAREZHG6jxQXL58GeHh4ejTpw/Mzc0xdOhQpT5lZWVISEhA586dYW1tDV9fX5w9e1ap34ULFzBs2DDY2NjA2dkZixYtQklJSb2PRUREpG3qPFCcP38emZmZkEgk6NChQ4V9EhMTER8fj2nTpmHr1q0wNjaGv78/bt++LfaRyWTw9/eHjo4OUlNTERUVhaSkJMTGxtbrWERERNqozgOFr68v/vjjD2zcuBHOzs5K2wsLC7F8+XJERERg8uTJGDBgAL755hvo6Ohg7dq1Yr/169ejoKAAycnJGDhwIEJCQjBjxgwkJSUhLy+v3sYiIiLSRnUeKHR1qz7k8ePHkZeXh+HDh4ttRkZG8PHxQWZmptiWmZkJLy8vmJiYiG0jRoxAQUEBsrKy6m0sIiIibdTgFmVKpVLo6emhffv2Cu1OTk6QSqUK/SQSiUIfOzs7GBoaiv3qYywiIiJt1OAChUwmg5GREfT09BTaBUGAXC5HcXGx2M/U1FRpf0EQIJPJ6m0sIiIibdSkviegDXJycmpk/8LCwlo7xquINVEfa6ce1k19rJ366qp2tra2VW5vcIFCEAQ8fvwYJSUlCmcDZDIZDA0Noa+vL/YrXzD5PJlMBkEQ6m2silT3S6iKVCoV9zcwuFMrx3gVPV83Ug1rpx7WTX2snfoaUu0a3CUPiUSCkpISXL58WaE9OztbYZ2DRCJRWruQk5MDuVwu9quPsYiIiLRRgwsUvXr1gomJCdLT08U2uVyOvXv3wtvbW2zz9vbGTz/9hPz8fLEtLS0NzZs3R9++fettLCIiIm1U55c85HK5+DHLv//+G/n5+cjIyADw7I3d0NAQ4eHhiI+PhyAIcHR0RFJSEkpLSzF58mRxnJCQEKxevRpBQUEIDw/HlStXEBcXhylTpogf/zQwMKjzsYiIiLRRnQeKu3fvYvz48Qpt5Y/PnDkDe3t7REREoLS0FImJicjNzYWrqyvS0tJgaWkp7iMIAjIyMhAZGYmAgACYmpoiNDQUMTExCmPX9VhERETaSEcmk5XV9ySocs/fIyNw3OlK+6WkutXVlBqFiu4tQi+HtVMP66Y+1k59Dal2DW4NBRERETU+DBRERESkMQYKIiIi0hgDBREREWmMgYKIiIg0xkBBREREGmOgICIiIo0xUBAREZHGGCiIiIhIYwwUREREpDEGCiIiItIYAwURERFpjIGCiIiINFbnX19OtYffRkpERPWFZyiIiIhIYwwUREREpDEGCiIiItIYAwURERFpjIGCiIiINMZAQURERBpjoCAiIiKNMVAQERGRxhgoiIiISGMMFERERKQxBgoiIiLSGAMFERERaYyBgoiIiDTGQEFEREQaY6AgIiIijTXIQJGSkgJBEJR+1q9fL/YpKytDQkICOnfuDGtra/j6+uLs2bNKY124cAHDhg2DjY0NnJ2dsWjRIpSUlCj0qcmxiIiItFGT+p5AVXbs2IHmzZuLjx0cHMR/JyYmIj4+HvPnz4ejoyOSkpLg7++Po0ePwsrKCgAgk8ng7+8PJycnpKam4q+//sLs2bNRVlaG2bNn18pYRERE2qhBBwo3NzcYGxsrtRcWFmL58uWIiIjA5MmTAQDu7u5wcXHB2rVrxTf49evXo6CgAMnJyTAxMcHAgQORn5+PuLg4hIWFwcTEpEbHIiIi0lYN8pJHdY4fP468vDwMHz5cbDMyMoKPjw8yMzPFtszMTHh5eSm82Y8YMQIFBQXIysqq8bGIiIi0VYMOFK6urrCwsEDPnj2xYcMGsV0qlUJPTw/t27dX6O/k5ASpVKrQTyKRKPSxs7ODoaGh2K8mxyIiItJWDfKSh7W1NWbNmoUePXqgpKQE3333HSIiIiCXyzFlyhTIZDIYGRlBT09PYT9BECCXy1FcXAx9fX3IZDKYmpoqjS8IAmQyGQDU6FiVycnJUbUEFe5fWFhYZZ/qtmsbbXzONYW1Uw/rpj7WTn11VTtbW9sqtzfIQOHl5QUvLy/xsbe3N4qKivDZZ58hNDS0Hmemnup+CVWRSqXi/gYGd6o8RnXbtcnzdSPVsHbqYd3Ux9qpryHVrkFf8nien58fHjx4gGvXrkEQBDx+/FjpI5symQyGhobQ19cH8OzsQV5entJYMpkMgiCIfWpqLCIiIm3VaAKFjo6O+G+JRIKSkhJcvnxZoU92drbCOgeJRKK0viEnJwdyuVzsV5NjERERaatGEygyMjJgYWGBNm3aoFevXjAxMUF6erq4XS6XY+/evfD29hbbvL298dNPPyE/P19sS0tLQ/PmzdG3b18AqNGxiIiItFWDXEMRFBSEHj16oHPnzigpKcH333+P77//HkuWLIGuri4MDAwQHh6O+Ph4CIIg3oyqtLRUvJcEAISEhGD16tUICgpCeHg4rly5gri4OEyZMkX8+GdNjkWNW+C405VuS0l1q8OZEBE1Pg0yUEgkEmzevBk3btxAWVkZnJyc8NVXXyEgIEDsExERgdLSUiQmJiI3Nxeurq5IS0uDpaWl2EcQBGRkZCAyMhIBAQEwNTVFaGgoYmJiFI5Xk2MRERFpIx2ZTFZW35Ogyj1//4vq/oLmX9j/U9F9Q6rD+j2jTu2IddMEa6e+hlS7RrOGgoiIiBquBnnJg6g2aHoGgmcwiIgqx0BBr4zn3/AfP34MI6P/fSKnLt7wGTiISJvxkgcRERFpjGcoqNFo7GcAGvv8iYiqwkBB1EBUFjjKw0Z124mI6hMveRAREZHGeIaCGgxeEiAiarx4hoKIiIg0xkBBREREGuMlD6oxvDV4/eKiTSKqTzxDQURERBrjGQotwjME2o1nMIioNvEMBREREWmMZyiICMD/zmDUx/egEFHjx0BBL42XTIiIqDIMFCRiYKCqcA0GEVWFayiIiIhIYzxDQUQ1gmcwiLQbAwUR1QkGDqJXGy95EBERkcYYKIiIiEhjvORBRA0CL4kQNW48Q0FEREQa4xkKImoUeAaDqGFjoCCiVwIDB1H9YqAgIq1QXeBgICHSDNdQEBERkcZ4hoKI6CXwDAZR1RgoVHThwgVERUXh5MmTMDU1RVBQEKKjo6Gnp1ffUyOiehT58S2Fr30vx8BB2oKBQgUymQz+/v5wcnJCamoq/vrrL8yePRtlZWWYPXt2fU+PiBowruGgVx0DhQrWr1+PgoICJCcnw8TEBAMHDkR+fj7i4uIQFhYGExOT+p4iEb2iGEiooWOgUEFmZia8vLwUgsOIESMwd+5cZGVlwdfXtx5nR0RUOQYSqm06MpmsrL4n0Vh06NAB7733HmJiYhTaW7VqhejoaISFhdXTzIiIiOoXPzaqAplMBlNTU6V2QRAgk8nqYUZEREQNAwMFERERaYyBQgWCICAvL0+pXSaTQRCEepgRERFRw8BAoQKJRAKpVKrQlpOTA7lcDolEUk+zIiIiqn8MFCrw9vbGTz/9hPz8/928Ji0tDc2bN0ffvn1r7DgXLlzAsGHDYGNjA2dnZyxatAglJSU1Nn5jdPnyZYSHh6NPnz4wNzfH0KFDlfqUlZUhISEBnTt3hrW1NXx9fXH27FmlftpU3/T0dAQEBKBjx45o3bo1PD09sX37dqV+GzduhJubG6ysrODp6YlDhw4p9bl58yYCAwNha2uLdu3aITIyEnK5vC6eRp3LyMjA4MGD0bZtW1hZWaFnz56Ij49HcXGx2Ievt+rdvHkTrVu3hiAIePTokdjO2ilLSUmBIAhKP+vXrxf7NPS6MVCoICQkBM2aNUNQUBB+/vlnfPPNN4iLi8OUKVNq7B4U5TfP0tHRQWpqKqKiopCUlITY2NgaGb+xOn/+PDIzMyGRSNChQ4cK+yQmJiI+Ph7Tpk3D1q1bYWxsDH9/f9y+fVvso231TUpKgrGxMRYvXozU1FR4eHhg0qRJWL16tdhn+/btiIiIQEBAALZt2wZnZ2eMGTMG586dE/s8efIEI0eOxPXr17Fu3TrExcUhPT0d4eHh9fG0al1ubi769++Pzz//HNu2bcO7776LhIQEzJo1S+zD11v15syZAyMjI6V21q5yO3bsQGZmpvjz9ttvi9saet34sVEVXbhwAZGRkQq33o6JiamxW28vW7YMK1aswO+//y6GlBUrViAuLg4XL17U2ptnlZaWQlf3Wf4NDg7G/fv3sWvXLnF7YWEhHB0dMWXKFMyYMQMA8PjxY7i4uGDixIninUy1rb7379+HhYWFQtukSZNw4sQJ8S+bnj17olevXkhKSgLwrNb9+vVDly5dsGbNGgDPQsfkyZNx+vRpODg4AHh2di4kJAS//vor2rdvX3dPqp4sWLAAa9euxdWrV1FUVMTXWzWysrIQGBiI6dOn45NPPkFOTg6MjY3532olUlJSMGXKFLFOL2oMdeMZChU5Oztj586duHXrFi5evIjZs2fX6Pd4VHbzrIKCAmRlZdXYcRqb8jBRmePHjyMvLw/Dhw8X24yMjODj44PMzEyxTdvq+2KYAAAXFxfcunULAHDlyhVcunRJoW66urrw8/NTqpubm5sYJgBg6NCh0NfXx/79+2vvCTQgZmZmePLkCQC+3qpTUlKCqKgoREVFwdzcXGEba6eexlA3BooGRiqVKi3wtLOzg6GhodKCUPofqVQKPT09pb+UnZycFOrG+gInTpwQLxtlZ2cDgFJNnJyc8ODBA9y7dw9AxXXT19dH27ZtX+m6lZSUQC6X4+jRo1i9ejVCQkKgo6PD11s11q9fj+LiYvzzn/9U2sbaVc3V1RUWFhbo2bMnNmzYILY3hrrx1tsNDG+epR6ZTAYjIyOls0WCIEAul6O4uBj6+vpaX99Dhw5h165dWLlyJQCIz/nFmpR/DFomk6FFixZaW7dWrVqhqKgIABAQEIAFCxYA4OutKrm5uVi0aBHWrFmDpk2bKm1n7SpmbW2NWbNmoUePHigpKcF3332HiIgIyOVyTJkypVHUjYGCSEtcvXoVkyZNwpAhQxAYGFjf02kUfvzxRxQUFODUqVNYunQpIiMjkZCQUN/TatAWLFgAd3d3DB48uL6n0qh4eXnBy8tLfOzt7Y2ioiJ89tlnCA0NrceZvTwGigaGN89SjyAIePz4MUpKShQSvEwmg6GhIfT19cV+2ljfBw8eYPTo0bCzs8PatWvF9vLnnJeXp/D8y/+SKW+rqm5dunSpzanXq+7duwMAevfuDQsLC4SGhuLDDz/k660S58+fx+bNm7F7927xNVRQUADg2WtMT0+PtVOBn58f0tLScO3atUZRN66haGB48yz1SCQSlJSU4PLlywrt2dnZCnXTxvrK5XKMGTMGxcXF+Pbbb2FoaChuc3R0BAClmmRnZ8PMzAwtWrQAUHHdiouLceXKlVe2bi/q1q0bgGdnevh6q9iff/6JJ0+ewNvbGw4ODnBwcMDHH38MAOjUqROioqJYOxXo6OiI/24MdWOgaGDq6uZZr5pevXrBxMQE6enpYptcLsfevXvh7e0ttmlbfZ8+fYoJEybgzz//xHfffYeWLVsqbHdwcECHDh0U6lZaWor09HSlup0+fRrXrl0T2/bs2YOioiIMGjSo9p9IA3D8+HEAgL29PV9vlejduzd27typ8FN+r5Jt27YhLCyMtVNBRkYGLCws0KZNm0ZRN73o6OhPa/UIpJKOHTtiw4YNOHz4MKytrfHzzz9j/vz5+OCDDxReNNpGLpdj9+7duHjxIg4cOACZTIaWLVvi4sWLaNOmDZo3by7eRc7U1BSPHj3CrFmzcOPGDaxatUq8uY621TciIgLff/895s6dCzMzM9y8eVP8adGiBZo0aQJzc3MsXrwYurq6KCkpwZIlS3D06FGsWrVKDCASiQQ7duzAjh070Lp1a/znP/9BdHQ0hg4divHjx9fzs6x5I0eOxJ07d5CXl4erV69iy5YtWLJkCd5++21MmDABTZo04eutAoaGhrC3t1f4uXHjBnbv3o3ExETY2NiwdpUICgrCtWvXkJ+fD6lUiqVLl2L79u349NNP4e7u3ijqxhtbNUC1ffOsxujq1aviKecXnTlzBvb29uJ/bOvXr0dubi5cXV0RFxentJ821bdr1664fv16hdvK6wY8u/X28uXLcePGDTg7O2PBggXw9PRU6H/jxg1ERkbi0KFD0NfXx8iRIzF//nyFSyivioULF2LXrl24du0a9PT04ODggMDAQISEhIifXODr7eVUdMMm1k7Z/PnzsWPHDty4cQNlZWVwcnJCaGgoAgICxD4NvW4MFERERKQxrqEgIiIijTFQEBERkcYYKIiIiEhjDBRERESkMQYKIiIi0hgDBREREWmMgYJITSkpKfD09IStrS3s7e3h4eGBmTNnqjxOaGgoBgwYUPMTrGGPHj2CIAhISUmpst+1a9cwefJkdOnSBVZWVujcuTPGjh2LrKysOppp4yUIAtasWVPf0xAdOHAAX375pVJ7Y3nNUt1ioCBSw7JlyxAWFgYvLy8kJyfjq6++wpAhQ7Bnz576nlq9kslk8Pb2xoULFzBnzhxs27YNMTEx0NXVxcmTJ+t7eqSiAwcOYNWqVfU9DWok+G2jRGpYu3YtJk6ciDlz5ohtvr6+iI6OrsdZaa6srAxFRUUwMDBQa/+MjAzcuXMHv/zyi8L3hrz77rsoK+M99IheZTxDQaSGhw8fwtLSUqn9+W8HPHz4MARBwLlz5xT6DB06FMHBwUr7/vDDD3B3d4eVlRV8fHxw4cIFcdu//vUvDB8+XHwslUohCALeffddse23336DIAj4888/xbY1a9bAzc0NlpaWcHV1RVJSksIxY2Nj0a5dOxw9ehQDBw6ElZWV+OVDGRkZ6NGjB6ytreHr66v0DYaV1UVfXx9mZmZV1gYAjhw5giFDhsDGxgZt27ZFWFiYwhcaAUBWVhb69u0LKysreHp64vjx42jXrh1iY2PFPl27dsXs2bMV9ktJSYEgCHj06JHY9uDBA0ybNg0SiQRWVlYYPHgwfv31V4X9BEHAqlWrMH/+fLRv3x4dOnTAxx9/jKKiIoV+165dw3vvvYd27drBxsYGffr0wbZt28TthYWFmDNnDjp37gxLS0v07dsX+/btq7Z+1SktLUViYiJcXV1haWmJHj16IDU1VaFP+etr27ZtcHV1hZ2dHUaNGoUbN24o9Lt+/TpGjRoFa2truLi4ICUlBcHBwRg6dCiAZ6+NlStX4vr16xAEAYIgIDQ0VGGMgwcPok+fPmjVqhV8fHxw/vx5jZ8jNV48Q0Gkhm7dumHNmjWwtbWFj48PzM3NNRrv+vXrmDVrFmbNmgUDAwPExcVh5MiROHXqFAwMDNCnTx/MnDkTJSUl0NPTw5EjR2BgYIBjx46JY2RlZcHS0hLt27cH8Oz7OaKiojBlyhR4eXnh8OHDmD17NoqLixERESHuV1BQgNDQUEybNg3t27eHjY0NfvvtN4SEhOCtt95CXFwczp8/jwkTJrxUXYqKivD+++9j6tSpcHFxga6u8t8tx44dg7+/P4YOHYqNGzciNzcX8+bNg0wmw6ZNkqoxZwAAC3BJREFUmwAAf//9N0aPHg03Nzds3LgRt27dwj//+U8UFBSoXN+ioiL4+fnh4cOHmD9/Plq2bIl169bB398fp06dgpWVldg3KSkJHh4eWLNmDf744w/MmzcPdnZ2mDZtGgDg7t27GDx4MJo3b44FCxbA1tYW586dU3jDHj9+PE6dOoWYmBi0bdsWaWlpGDt2LA4ePAgXFxeV518uKioKW7ZsQVRUFLp164aDBw/iww8/hLm5OXx8fMR+p06dwq1bt7Bw4UIUFhYiOjoa4eHhYugpKyvD2LFj8fDhQ6xcuRLNmjVDfHw87t+/DwcHBwBAcHAwLl++jH//+9/YvHkzAIhfZw88+0rsTz75BB9//DEMDAzwySefICQkBEeOHFEKj6QdGCiI1BAfH4/AwEB88MEH0NHRgZOTE95++21MnToVJiYmKo93//59pKamolevXgCA7t27w9XVFampqQgJCUHv3r3x6NEjnD17Fq6urjhy5AjGjh2L5ORkZGdnw9HREUePHkXv3r0BPPtLNi4uDuPGjcOiRYsAAG+++Sby8vKQmJiI0NBQ8bJGQUEBFi1aJP5lCgATJkxAhw4d8M0330BHRwfe3t4oLi7GwoULq3wenp6e+OCDD7Bq1Sp89913eO211zBgwP9v715j2qr7AI5/2zgKTNmgtEgR5lAnQaa0c0hhkbHqEgwG+0rm3EXm5gWROZYhxtnUKXMqJMucm2aAQnSKbzaZUxadTGM3Z5gajJiJM6ZMaWkHsgQZWefzounJDi1ye5InPvt9kr44p//+by96fud/OWcp69atUy3iczqd5OTk0NTUpJxLTk6mpKSEH3/8kczMTPbs2YNOp6O1tVV5AVlsbCwbNmyYcv++//77dHd3c+LECSXgWrp0KbfffjuvvfYa27ZtU9KmpqYq6wZsNhsnTpygra1NCShef/11hoaG6Ojo4Nprr1XaHXLs2DHa29s5dOgQS5YsAYJ939PTQ11dHW+//faU6w9w5swZGhoa2L17Nw888IDShr6+Pnbs2KEKKM6fP09raytz584FwOPx8Mwzz/DXX38RExPDkSNH+OGHHzh69CgWiwWARYsWceuttyoBRUpKCklJSURFRbF48eKw+gwMDNDe3q7056VLl3jwwQf5+eefWbBgwbTaKP7dZMpDiGnIysri5MmT7N+/n4cffpi///6bV155hcLCQtUw+2QZDAYlmABIS0sjOzubzs5OIPj6cIPBgMvlAoLTBXfddRe33XYbx48fB4J3/aGA4uzZs/zxxx/cd999qnLsdjtDQ0OqaZhQwHC5zs5OioqKVHea995776TaUltbS2dnJ9u2bSM/P5/PPvsMu91OY2MjEHwV/cmTJ7Hb7Vy8eFH5WK1WZs2axXfffafUobCwUPU20+Li4knVYaxjx46RnZ3NvHnzlPIA8vPz+fbbb1Vply1bpjrOyMjg999/V46/+OILbDabEkyM1dHRQVJSErm5uar2FRQUhJU11TZotVqKi4vD8u3q6iIQCChpzWazEkyE2gDBUR+AU6dOkZSUpAQTACaTiezs7EnXJy0tTQkmLi/j8r4SVxYZoRBimnQ6HUVFRRQVFQHQ3NzMk08+SUtLS9hc80QuX8AYkpiYiMfjUY6tVivHjx+npKSE3t5erFYrVqsVl8tFbm4uPp9PCShCvxu7ziN0PDAwoJybO3cuUVFRqnRer1c1vD1eHceTnp5ORUUFFRUV+P1+7HY7zz//PA899BCDg4MEAgGqqqqoqqoK+21o6sDr9XLLLbeovouNjVVegT0Vfr+fb775JqxNAPPnz1cdz5kzR3U8a9YsRkZGlONz586pLsSRyvJ4PBHLmsnro/1+P4FAgLS0tIjf9/X1kZKSAkRuA6C0w+v1otfrw/LQ6/WTDognKkNceSSgEOK/ZPXq1TgcDmXxYmhKYXR0VJVucHAw7M+8v78/LD+fz6fc9UEwoKirq8PlcpGRkUFCQgJWq5WamhpcLhdxcXEsXLgQQFkTMDZfr9cLoFo0GWm+22g04vP5JqzjZOj1elauXEl1dTX9/f3MmTMHjUbD008/zfLly8PSh+78I9VheHg47IIXHR0dsY8vFx8fj9lspr6+Pqy8scHURBISEujr6xv3+/j4eEwm04TP65iq+Ph4rrrqKtrb2yOuS5lKwGc0GvH7/WHn/X4/Op1uRvUUVy6Z8hBiGsYLAIaGhpQ/dpPJBMDp06eVNL29vRF3S/T39/P1118rx263m++//55FixYp5/Ly8vD5fLz11lvk5eUp59xuNx988AE5OTnKhSYlJYXk5GRlx0bIgQMHiIuLIzMz8x/bZ7FY+Pjjj1VbPdva2v7xN6E+iOSXX35Bp9MRFxfH7NmzWbx4MT09PZjN5rBPcnKyUofPP/+c4eFhJZ9Dhw6F5W0ymVR9DMHdB5crKCjgzJkzXHfddWHljR0FmUhBQQFHjx5VgrNI33s8HmbPnh2xfdN15513EggEGBoaipjvVAIji8WCx+NRptQgOFURmm4KiYqKCtvhIsR4ZIRCiGnIy8vjnnvuYdmyZSQmJuJ2u9m1axexsbGsWLECCF7UzWYzL774IjExMVy6dIn6+vqIWyr1ej0bNmzg2WefJTo6mu3bt2MwGJTFdxDcHhkXF4fL5WLdunVA8K41IyMDl8vF1q1blbRarVZZ2Z+QkEBhYSFfffUVDQ0NPPfccxM+Z2Ljxo3YbDbWrl3LqlWr6O7upqWlZcJ+2b9/P62trZSWlpKVlcXFixfp6OigoaGBsrIypVyn00lJSQkajYaSkhKuvvpqent7OXLkCFu3buXGG2/kscceY9++fdx///2Ul5fT19dHfX09MTExqjKLi4vZsmULdXV1WCwWPvzwQ9WWW4DS0lIaGxspLi7miSee4Prrr+fcuXOcOnUKo9FIeXn5hG0Lefzxx3nvvfcoKiqiqqqKlJQUTp8+zfDwMJWVlRQWFmKz2bDb7VRWVpKRkcH58+fp6uriwoULOByOf8y/q6uLgwcPqs7p9XqWLFlCWVkZZWVlVFZWYjabGRkZ4aeffqKnp4ddu3ZNug3Lly8nKyuLtWvX4nA4iI6OZseOHRiNRtXox0033YTX6+Wdd94hMzOThIQE5s2bN+lyxJVFAgohpmHLli0cPnyY6upqBgYGMBqN3HHHHTQ1NSmr5AEaGhqoqKjgkUcewWQy4XQ6Iz7KODU1lU2bNuF0OnG73ZjNZvbt26e68Gu1WnJycvj000+VEQoIToV0d3eTm5urynPNmjWMjIywd+9e9u7di8lk4oUXXpjUxdNsNtPY2IjT6WTlypWYzWaamprCFiyOdffdd/Pbb7/R3NzM2bNn0Wq1zJ8/n5dffpk1a9ao6nz48GG2b9/Oo48+SiAQIDU1FZvNphrhaW1tpbq6mtWrV7NgwQLefPNNVZAFwR0pv/76K2+88QYXLlygtLSUzZs3s3HjRiVNdHQ0bW1t1NbW8tJLL+H1ejEYDFgsFmUNzGQlJibyySef4HA4qKmpYXR0lPT0dDZt2gQEp5BaWlqoq6tjz5499Pb2Eh8fz8KFCye1Q6WlpSUseMvPz+ejjz7i1Vdf5YYbbqC5uZna2lquueYabr75ZlatWjWlNmg0Gt59912eeuopysvLMRgMbN68mYMHD6oCNrvdzpdffonD4cDn87FixQp5cqYYl2ZwcFAeXyeE+NdIT09n/fr11NTU/K+r8n/lzz//JDs7m/Xr10/rnTRCyAiFEEJcgRobG9FqtaSnp+P3+9m9ezejo6Oqp68KMRUSUAghxBVIp9Oxc+dO3G43Go0Gi8XCgQMHxt2WKsREZMpDCCGEEDMm20aFEEIIMWMSUAghhBBixiSgEEIIIcSMSUAhhBBCiBmTgEIIIYQQMyYBhRBCCCFm7D+4mQEd4eXpbAAAAABJRU5ErkJggg==%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dynamic-Padding">
<a class="anchor" href="#Dynamic-Padding" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dynamic Padding<a class="anchor-link" href="#Dynamic-Padding"> </a>
</h3>
<p>From the above graph we can intuit that if we draw random samples from the data to form a batch, we would have few examples which are significantly longer than the rest. This would mean we would have to add lot of padding tokens. This holds even if we clean the very short length instances as noise. Let's implement dynamic padding and measure how much.</p>
<p>We can use torch's <code>DataLoader</code> abstraction to do efficient batching with multi-processing. Since our tokenized outputs are of different lengths we have to implement a <code>collate</code> function to pad them dynamically together. We can pass the <code>tokenizer.pad</code> function to do this.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">examples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="c1"># Since huggingface has already implemented this, this function is just to illustrate what a collator does.</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>

<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">wiki_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assume we can accomodate at maximum a batch size of 32 for max sequence length of 512 in our training hardware. The tokens per batch would be <code>512 * 32 = 16384</code>. Let's compute how much of it is padding tokens and what is the distribution of the batch's sequence length(which depends on the maximum element in the batch).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">padding_tokens</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">batch_lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)):</span>
    <span class="n">batched_input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
    <span class="n">batch_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batched_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">batched_input_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="n">padding_tokens</span> <span class="o">+=</span> <span class="n">batched_input_ids</span><span class="p">[</span><span class="n">batched_input_ids</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 36390/36390 [05:42&lt;00:00, 106.17it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Batches    : </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Padding Tokens   : </span><span class="si">{</span><span class="n">padding_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Input Tokens     : </span><span class="si">{</span><span class="n">total_tokens</span> <span class="o">-</span> <span class="n">padding_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Tokens     : </span><span class="si">{</span><span class="n">total_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Padding Tokens % : </span><span class="si">{</span><span class="p">(</span><span class="n">padding_tokens</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">/</span><span class="n">total_tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total Batches    : 36390
Padding Tokens   : 244072396
Input Tokens     : 119699332
Total Tokens     : 363771728
Padding Tokens % : 67.09493267712108
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Look at that, <strong>67% of our net tokens are padding tokens</strong>. This would imply that of all the computations we do only 33% of it is done usefully. So this starkly highlights the problem with static batch lengths even when accounting for dynamic padding.</p>
<p>Let's also plot the distribution of batch lengths.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">'fivethirtyeight'</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">batch_lengths</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#0504aa'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'y'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Batch Sequence Length'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Static Batch - Dynamic Padding Length Distribution'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As batches are randomly sampled, we see a normal distribution as we can by the Central Limit Theorem. The frequency in the final bin is deviant because we have a significant number of sentences which we had truncated, hence batches with them will have the maximum sequence length.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="General-approach-to-dynamic-batching-and-it's-challenges.">
<a class="anchor" href="#General-approach-to-dynamic-batching-and-it's-challenges." aria-hidden="true"><span class="octicon octicon-link"></span></a>General approach to dynamic batching and it's challenges.<a class="anchor-link" href="#General-approach-to-dynamic-batching-and-it's-challenges."> </a>
</h3>
<p>Now that we have seen the problem with static batching, let's see how to solve that.</p>
<p>Instead of drawing samples in random, had we sorted our dataset by length, then we can form batches by packing similar length sequences together until we reach the maximum number of tokens that we can fit. This would typically be our previous memory limit of <em>static_batch x max_sequence_length</em>. This allows us to pack more instances in one batch without much padding.</p>
<p>But we can't do that because machine learning training is based on the assumption that our instances are drawn independently from an identical distribution. If we were to sort the entire dataset this breaks the assumption completely as our samples are no longer drawn independently from each other. If sentence length were a confunding factor then the model might fit on this spurious correlation.</p>
<p>So we have a trade-off here between statistical power derived from randomization of our samples and lesser error in gradient updates derived from larger batch sizes if we batch dynamically.</p>
<p>Generally, we can have a positive trade off by sampling a window of instances and sorting withing the window and forming batches.</p>
<p>The <code>Dataset</code> we implemented above is a <a href="https://pytorch.org/docs/stable/data.html#map-style-datasets">map-style</a> dataset. It implements length and random access to each individual data sample with index (<code>__getitem__</code>). The sampling into batches is taken care of a sampler passed to <code>DataLoader</code>.</p>
<p>I don't think there is a clean way to implement a map-style dataset and a collate function such that we get batches with dynamic batch sizes but same number of tokens per batch. This comes from the basic mismatch of number of dynamic batches which you can form keeps changing based on the larger window you sample.</p>
<p>So it turns out that we have to do all the shuffling, windowing, sorting and batching inside a <a href="https://pytorch.org/docs/stable/data.html#iterable-style-datasets">iterable-style</a> <code>IterableDataset</code> dataset abstraction.</p>
<p>This is where we will turn to those built by infinibatch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Checkpointing-Data-Iteration">
<a class="anchor" href="#Checkpointing-Data-Iteration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Checkpointing Data Iteration<a class="anchor-link" href="#Checkpointing-Data-Iteration"> </a>
</h2>
<p>In large datasets, it's typical not to wait for an entire epoch to checkpoint your model to recover from failures. So to be able to recover and continue training in a deterministic manner, such that it converges to same state if the failure hadn't occured, we have to checkpoint the random state that controls the order in which our samples are generated.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Infinibatch-to-the-rescue">
<a class="anchor" href="#Infinibatch-to-the-rescue" aria-hidden="true"><span class="octicon octicon-link"></span></a>Infinibatch to the rescue<a class="anchor-link" href="#Infinibatch-to-the-rescue"> </a>
</h1>
<blockquote>
<p>Infinibatch is a library of checkpointable iterators for randomized data loading of massive data sets in deep neural network training.</p>
</blockquote>
<p>It has the following features that makes processing large datasets practical.</p>

<pre><code>support for corpora much larger than fit into RAM
hierarchical block+sentence-level randomization over the whole corpus, different randomization in each epoch
only load the data that is needed
very fast start-up time (does not need to read full corpus)
only requires the most basic of data preparation (e.g. no indexing)
for multi-GPU, only load what the respective GPU needs
100% accurate check-pointing, restore from checkpoint should not read all data up to the checkpoint
support automatic bucketed batching with dynamic batch sizes
pre-fetching thread
composable, as to support for complex batching, e.g. negative samples from multiple documents

</code></pre>
<p>It's basically a collection of pure python classes that implement <code>__iter__</code> interface. They can be composed inside one another easily and the final composed iterator can be checkpointed as a single entity.</p>
<p>You can checkout it's basic tutorial <a href="https://github.com/microsoft/infinibatch">here</a>. We will use it to address the listed challenges piece by piece and then finally make it work inside <code>IterableDataset</code> and <code>DataLoader</code> abstractions also handling tricky bits with distributed data parallel training.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sharding-Dataset-and-shuffling-iterator">
<a class="anchor" href="#Sharding-Dataset-and-shuffling-iterator" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sharding Dataset and shuffling iterator<a class="anchor-link" href="#Sharding-Dataset-and-shuffling-iterator"> </a>
</h2>
<p>Following the infinibatch tutorial, let's first divide our dataset into multiple gzip chunks of 10000 sentences each.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>mkdir -p wikitext-103-chunks
<span class="o">!</span>split  -a <span class="m">4</span> --lines <span class="m">10000</span>  --numeric-suffixes --filter <span class="s1">'gzip &gt; wikitext-103-chunks/$FILE.txt.gz'</span> wikitext-103-raw/wiki.train.raw  train.
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can create an iterator using infinibatch with a function that can deserialize a shard. Infinibatch takes care of loading multiple in a shuffled order. We can control the amount of deserialized examples (not shards!!) to be buffered using <code>buffer_size</code> parameter.</p>
<p>The library returns a python iterator on which we can call <code>next</code> or iterate with <code>for</code> to get next example.</p>
<p>Note: Passing <code>train=True</code> creates an infinite iterator that cycles after a full run on the dataset. The <code>chunked_dataset_iterator</code> method returns a composition of iterators, you can refer the source code <a href="https://github.com/microsoft/infinibatch/blob/master/infinibatch/iterators.py">here</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gzip</span><span class="o">,</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">from</span> <span class="nn">infinibatch</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">iterators</span>

<span class="k">def</span> <span class="nf">read_chunk</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">read</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">lines</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>

<span class="n">sentence_it</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">chunked_dataset_iterator</span><span class="p">(</span>
    <span class="n">chunk_refs</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">),</span>
    <span class="n">read_chunk_fn</span> <span class="o">=</span> <span class="n">read_chunk</span><span class="p">,</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">1337</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">sentence_it</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> = = Production = = 
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tensorize-our-dataset-with-a-map-iterator">
<a class="anchor" href="#Tensorize-our-dataset-with-a-map-iterator" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tensorize our dataset with a map iterator<a class="anchor-link" href="#Tensorize-our-dataset-with-a-map-iterator"> </a>
</h2>
<p>Let's compose our tokenizer upon our sentence iterator. Infinibatch has two ways of doing this,</p>
<ol>
<li>
<code>MapIterator</code> - Single Process</li>
<li>
<code>ParallelMap</code> multiprocessing</li>
</ol>
<p>Let's try <code>ParallelMap</code> with 4 workers.</p>
<p>If you use pytorch and need multiprocessing to do costly transformations over your data on the fly, use the <code>ParallelMap</code> and set <code>num_workers=0</code> in your dataloader.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenize_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">features_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">ParallelMapIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">sentence_it</span><span class="p">,</span>
    <span class="n">num_processes</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_items_per_process</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">tokenize_fn</span>
<span class="p">)</span>
<span class="nb">next</span><span class="p">(</span><span class="n">features_it</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'input_ids': [101, 134, 134, 6401, 134, 134, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dynamic-Batching">
<a class="anchor" href="#Dynamic-Batching" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dynamic Batching<a class="anchor-link" href="#Dynamic-Batching"> </a>
</h2>
<p>Now comes the magic of dynamic batching with <code>BucketedReadaheadBatchIterator</code>. Let's fix the maximum tokens per batch to  <code>32 * 512 = 16384</code>. This iterator allows you to compute dynamic batch size with a callback over the current longest example it read in a sorting <code>read_ahead</code> window fetched from the iterator composed within it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens_per_batch</span> <span class="o">=</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">512</span>
<span class="n">batches_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">BucketedReadaheadBatchIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">features_it</span><span class="p">,</span>
    <span class="c1"># read_ahead is the number of items to be read from previous iterator,</span>
    <span class="c1"># these are sorted and over which dynamic batches are formed.</span>
    <span class="n">read_ahead</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> 
    <span class="c1"># key determines the length used to sort and choose the longest remaining record.</span>
    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">example</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span> 
     <span class="c1"># Determines the dynamic batch size</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="k">lambda</span> <span class="n">longest_example</span><span class="p">:</span> <span class="n">tokens_per_batch</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest_example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span> 
<span class="p">)</span>
<span class="n">dynamic_batch_wo_padding</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches_it</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Dynamic batch size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dynamic_batch_wo_padding</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">dynamic_batch_wo_padding</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches_it</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Dynamic batch size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dynamic_batch_wo_padding</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dynamic_batch_wo_padding</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dynamic batch size: 130
Dynamic batch size: 98
[{'input_ids': [101, 139, 19700, 1233, 1626, 1108, 1103, 1148, 1884, 26281, 1883, 137, 118, 137, 27958, 8880, 1106, 1129, 3033, 1107, 1103, 19569, 13645, 14286, 3309, 2572, 132, 1122, 1108, 1973, 1439, 25341, 126, 2137, 137, 118, 137, 5942, 119, 1109, 10281, 1108, 14432, 1852, 1103, 1746, 137, 118, 137, 1745, 9840, 1919, 1194, 1103, 2642, 1104, 1103, 142, 137, 118, 137, 1990, 1219, 1103, 6468, 1206, 1103, 6372, 11689, 1665, 17223, 1596, 1105, 1103, 4503, 6667, 6461, 119, 1109, 8880, 1108, 8662, 137, 118, 137, 2781, 1105, 1108, 3229, 1103, 5041, 4276, 9278, 1107, 1103, 19569, 13645, 14286, 3309, 2572, 119, 6291, 4106, 5970, 1616, 16102, 1127, 2856, 1219, 1103, 4584, 1432, 5844, 1219, 1231, 3702, 12065, 1158, 1104, 1103, 3550, 117, 1120, 1134, 1159, 1103, 16102, 1127, 1894, 8043, 2155, 10334, 1223, 1103, 1503, 5383, 1104, 1103, 12157, 119, 1109, 16102, 1529, 1210, 185, 23415, 1732, 11457, 7463, 1114, 12477, 6262, 20226, 2584, 132, 1103, 4331, 5054, 1113, 1103, 7463, 3229, 1138, 20771, 7467, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [101, 1109, 1237, 2062, 12851, 3098, 1120, 156, 6378, 1279, 8677, 1108, 25197, 1118, 11495, 1361, 20452, 6583, 21944, 113, 3566, 170, 6796, 1104, 2868, 1615, 4367, 20452, 6583, 21944, 114, 117, 1105, 1103, 11378, 1916, 1108, 2374, 1118, 1764, 3806, 27680, 15796, 1389, 10944, 119, 20452, 6583, 21944, 1310, 1250, 1107, 1364, 1106, 3133, 5778, 2610, 1105, 1167, 6736, 1111, 4127, 1190, 1103, 1353, 8327, 137, 118, 137, 5039, 5778, 1227, 1112, 7693, 8221, 1775, 1115, 1127, 1215, 1111, 3936, 1113, 1103, 3521, 119, 1109, 1965, 2028, 1338, 1106, 8803, 1615, 12334, 7296, 117, 1150, 1108, 1126, 4531, 2062, 112, 188, 3495, 117, 1105, 1681, 4434, 4109, 117, 170, 5432, 10193, 2301, 1114, 12657, 2541, 119, 2868, 1615, 9800, 7625, 2660, 12702, 117, 1107, 2965, 1104, 1103, 2905, 3948, 1104, 1103, 3521, 117, 2028, 1455, 7296, 1106, 1321, 1167, 4812, 1107, 1103, 2062, 12851, 3098, 117, 1272, 107, 146, 1821, 1107, 3121, 9261, 1183, 8362, 1394, 13199, 112, 173, 1112, 1106, 4620, 4181, 119, 107, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can collate our examples and see how much  this scheme has saved us. Since a training iterator is infinite, we will recreate our iterators with a non-infinite iterator.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence_it_finite</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">chunked_dataset_iterator</span><span class="p">(</span>
    <span class="n">chunk_refs</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">),</span>
    <span class="n">read_chunk_fn</span> <span class="o">=</span> <span class="n">read_chunk</span><span class="p">,</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> 
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">1337</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">features_it_finite</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">ParallelMapIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">sentence_it_finite</span><span class="p">,</span>
    <span class="n">num_processes</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_items_per_process</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">tokenize_fn</span>
<span class="p">)</span>
<span class="n">batches_it_finite</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">BucketedReadaheadBatchIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">features_it_finite</span><span class="p">,</span>
    <span class="n">read_ahead</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="c1"># Determines the window for the bucket which</span>
    <span class="c1"># will be sorted and  converted to batches.</span>
    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">example</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span> <span class="c1"># Determines the length used</span>
    <span class="c1"># to sort and choose the longest remaining record.</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="k">lambda</span> <span class="n">longest</span><span class="p">:</span> <span class="n">tokens_per_batch</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
    <span class="c1"># Determines the dynamic batch size</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span> 
<span class="p">)</span>
<span class="n">collate_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>
<span class="n">tensors_it_finite</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MapIterator</span><span class="p">(</span>
    <span class="n">batches_it_finite</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">collate_fn</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">total_batches_dynamic</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="n">total_tokens_dynamic</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">padding_tokens_dynamic</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">batch_lengths_dynamic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">tensors_it_finite</span><span class="p">):</span>
    <span class="n">total_batches_dynamic</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">batched_input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
    <span class="n">batch_lengths_dynamic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batched_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">total_tokens_dynamic</span> <span class="o">+=</span> <span class="n">batched_input_ids</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="n">padding_tokens_dynamic</span> <span class="o">+=</span> <span class="n">batched_input_ids</span><span class="p">[</span><span class="n">batched_input_ids</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>7642it [07:51, 16.22it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Batches    : </span><span class="si">{</span><span class="n">total_batches_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span> <span class="c1"># Seeing the tqdm stats.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Padding Tokens   : </span><span class="si">{</span><span class="n">padding_tokens_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Input Tokens     : </span><span class="si">{</span><span class="n">total_tokens_dynamic</span> <span class="o">-</span> <span class="n">padding_tokens_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Tokens     : </span><span class="si">{</span><span class="n">total_tokens_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Padding Tokens % : </span><span class="si">{</span><span class="p">(</span><span class="n">padding_tokens_dynamic</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">/</span><span class="n">total_tokens_dynamic</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total Batches    : 7642
Padding Tokens   : 3841447
Input Tokens     : 119701264
Total Tokens     : 123542711
Padding Tokens % : 3.1094080491725653
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>LOOK AT THAT! We have reduced the percentage of padding tokens per epoch from 67% to just around 3%.The total batches needed to process it in the same max tokens per batch limitation hence got reduced nearly five times from 36390 to 7642.</p>
<p>The processing time is just one minute added. I guess that's due to IO, but you could try benchmarking that with more rigour.</p>
<p>Now, plotting the length distribution for dynamic batches.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">'fivethirtyeight'</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">batch_lengths_dynamic</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#0504aa'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'y'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Batch Sequence Length'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Frequency'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Dynamic Batch - Dynamic Padding Length Distribution'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now see that the expected per batch sequence length has reduced from 300 to 200.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Checkpointing">
<a class="anchor" href="#Checkpointing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Checkpointing<a class="anchor-link" href="#Checkpointing"> </a>
</h2>
<p>One cool feature of <code>infinibatch</code> is that you can checkpoint a particular state in which the composed iterators is at and restore it back to that state. This is very cool considering it works recursively on the composed iterators and even on infinite iterator. Let's recreate our iterators and check this out.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="n">sentence_it</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">chunked_dataset_iterator</span><span class="p">(</span>
    <span class="n">chunk_refs</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">),</span>
    <span class="n">read_chunk_fn</span> <span class="o">=</span> <span class="n">read_chunk</span><span class="p">,</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> 
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">1337</span><span class="p">,</span> 
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">features_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">ParallelMapIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">sentence_it</span><span class="p">,</span>
    <span class="n">num_processes</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_items_per_process</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">tokenize_fn</span>
<span class="p">)</span>
<span class="n">batches_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">BucketedReadaheadBatchIterator</span><span class="p">(</span>
    <span class="n">source_iterator</span><span class="o">=</span><span class="n">features_it</span><span class="p">,</span>
    <span class="n">read_ahead</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="c1"># Determines the window for the bucket which</span>
    <span class="c1"># will be sorted and  converted to batches.</span>
    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">example</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span> <span class="c1"># Determines the length used</span>
    <span class="c1"># to sort and choose the longest remaining record.</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="k">lambda</span> <span class="n">longest</span><span class="p">:</span> <span class="n">tokens_per_batch</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
    <span class="c1"># Determines the dynamic batch size</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span> 
<span class="p">)</span>
<span class="n">collate_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>
<span class="n">tensors_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MapIterator</span><span class="p">(</span>
    <span class="n">batches_it</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">collate_fn</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">tensors_it</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span> 
<span class="nb">print</span><span class="p">(</span><span class="s2">"Initial State of composed iterators"</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">)</span>
<span class="c1"># Draw 5 batches</span>
<span class="n">batches</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">tensors_it</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Current State after sampling 5 batches: </span><span class="si">{</span><span class="n">tensors_it</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Reset the Iterator</span>
<span class="n">tensors_it</span><span class="o">.</span><span class="n">setstate</span><span class="p">(</span><span class="n">initial_state</span><span class="p">)</span>
<span class="c1"># Redraw 5 batches</span>
<span class="n">redraw_batches</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">tensors_it</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"State after resampling 5 batches: </span><span class="si">{</span><span class="n">tensors_it</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="c1"># Check equal</span>
<span class="n">all_equal</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">for</span> <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batches</span><span class="p">,</span> <span class="n">redraw_batches</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">b1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">b1</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">b2</span><span class="p">[</span><span class="n">k</span><span class="p">])):</span>
            <span class="k">continue</span>
        <span class="n">all_equal</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">break</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">all_equal</span><span class="p">:</span>
        <span class="k">break</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"All items drawn after resetting are equal: </span><span class="si">{</span><span class="n">all_equal</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Initial State of composed iterators {'source_state': None, 'random_state': None, 'num_served': 0}
Current State after sampling 5 batches: {'source_state': {'source_state': None, 'flattened_items_yielded': 0}, 'random_state': (3, (2147483648, 766982754, 497961170, 3952298588, 2331775348, 1811986599, 3100132149, 3188119873, 3937547222, 215718963, 3315684082, 2978012849, 2428261856, 1298227695, 1704729580, 54668373, 3285201915, 3285178464, 1552935063, 988471319, 3135387943, 1691402966, 2757551880, 416056905, 907387413, 1072924981, 33903495, 2168419592, 2429050353, 831159753, 430343641, 3315943586, 1761671042, 864453023, 334804929, 1627478028, 2596811275, 3468733638, 3994375553, 1457139722, 3139722021, 1334790738, 2656639915, 3535811098, 1464315470, 2397423927, 885719490, 1140895889, 3284299483, 2854516462, 2734973817, 147484763, 792049954, 114360641, 3345458839, 1159898878, 1410498733, 2242989638, 453922141, 1344019764, 413870456, 3089405849, 1494382840, 470157779, 4266372830, 2831181573, 1361928602, 1589253513, 1381373062, 753045124, 987032420, 781978839, 2953638767, 3258570111, 3006718191, 1675218601, 1854232715, 3655829819, 1731242722, 2192104666, 1736665161, 740150002, 1195833394, 1610203160, 159492766, 4041488705, 3128952632, 2867295744, 3272632449, 886824304, 1791482600, 221114776, 3867175393, 4020804062, 1077871826, 1298953503, 996366221, 4149754679, 2483052703, 2615558283, 274318093, 1716359450, 4099129961, 1026774175, 288240973, 1459347562, 2365566296, 3690105224, 3065780221, 2050634722, 2652606621, 3185241207, 3026457375, 3456165734, 1880121515, 3398461093, 1795638629, 2379692076, 608668379, 1261955525, 84456522, 1913485156, 106878280, 757183891, 2913957588, 160418091, 2025664758, 141497907, 1657818026, 3053760160, 672193054, 4157546743, 223046484, 1623470498, 1201972930, 675008814, 684162366, 1738776330, 3025656654, 159760723, 1908867305, 3933381342, 2545706671, 467196949, 1427819885, 842150314, 4032903454, 2140851898, 3269883445, 975813755, 4177392955, 1556690684, 2535611513, 462962732, 67591358, 1729610528, 2025206740, 3153739740, 3255032049, 4186226368, 1070144624, 3107867195, 1621006038, 63742485, 835629717, 3189842019, 3950227584, 3184714559, 841836938, 1685394870, 657939920, 766156242, 1412314179, 1048281639, 4037161120, 2044490307, 1923947830, 3900790422, 907554295, 276417304, 860658646, 3574201134, 3508771399, 2110232300, 1636296241, 1405006077, 1093408401, 3243057343, 1519791182, 1994660136, 3829840937, 2644974199, 957955566, 3487641161, 1646922510, 1907939989, 3836029453, 3429168778, 201307778, 72550089, 2464394982, 1695794191, 3344785682, 996786130, 3589457196, 1241754792, 1291082245, 4224603667, 1194379475, 2693491244, 881186965, 2705535111, 445306946, 440274268, 1980827733, 2482488861, 3205215943, 2119332222, 2928713046, 1418736938, 652581136, 2474070665, 2208621536, 4171251876, 2303664214, 443762656, 2981912989, 2199228311, 2652261633, 3166738494, 3443009210, 3498764432, 424010848, 4065487566, 2262993542, 1756076712, 1477098233, 2742171915, 306185806, 3610666541, 923091830, 1034267993, 2336668648, 1880719718, 676878038, 3788797208, 3763351494, 3985428106, 1101865631, 1130501258, 3672967388, 3432003530, 4124438011, 1660392285, 4025484827, 2108074566, 3815409682, 42955331, 3248965569, 1643835718, 1246665668, 1071162194, 3814069229, 115491158, 985096811, 3311029186, 2990827378, 3101633320, 1648574497, 1470117052, 174145027, 2019894819, 2035501481, 459104123, 3507464599, 2093352659, 3369174406, 618767835, 4009895756, 935587447, 3956987426, 33753995, 307782427, 2473424805, 1440371818, 2382619594, 2138695812, 3164510238, 1318650933, 2910086616, 3886677510, 566832801, 3718063320, 1559818704, 183047272, 1142362855, 26306548, 645536402, 3875596208, 2272778168, 3512733409, 1897046338, 38248886, 2570759766, 1806313150, 860304898, 2433450338, 4124013408, 1216634590, 1275388896, 1169566669, 652504502, 761221427, 1448403764, 3129135949, 2513214949, 1269533687, 2413509541, 1226750363, 2450740925, 4094137910, 945759293, 3636927736, 3178020081, 2509964157, 3878869300, 1848504895, 2018369720, 1579755740, 1023627943, 924838836, 2653160914, 1812804174, 1521323076, 4012390528, 1338763317, 2608655937, 16022784, 1672945066, 2177189646, 2944458483, 2213810972, 1369873847, 1224017670, 130901785, 3595066712, 2259115284, 3316038259, 455873927, 2917250465, 3599550610, 1502173758, 684943436, 3079863840, 3144992244, 942855823, 1771140188, 2118780653, 3411494225, 2711180217, 4239611184, 1371891067, 3398566397, 3105518599, 1310665701, 3345178451, 2959821156, 242241789, 2148966880, 3192740583, 404401893, 3605380577, 1446464038, 3920522056, 2577523013, 1079274576, 286634372, 1752710796, 2351075979, 981312309, 3410516352, 3468455736, 1938779182, 1592494371, 1533303080, 88045436, 438252489, 1220512168, 3487004938, 3724852871, 1073434882, 3728218947, 2977555283, 4105408406, 3553772656, 1462006821, 3917158017, 119003006, 3470530198, 3439192457, 2829375771, 3555715155, 32324691, 588735808, 1459221702, 803072782, 2699519868, 1530797005, 79738580, 671990400, 4289511388, 3207115447, 2584684068, 832698998, 760958416, 1217440464, 2517898131, 2418819938, 3629956222, 3445024962, 206619378, 365007395, 522114139, 1707954431, 540423623, 1786750801, 369253262, 4239016754, 147889201, 1637777773, 236798285, 2806120188, 586972608, 2201782716, 1323327827, 819485723, 406078680, 3407345698, 1537169369, 1821691865, 527271655, 3751827102, 1465426495, 3321682429, 2179672664, 401355478, 1068871880, 24609462, 1403522408, 2311580015, 1532058170, 3877815340, 1768430711, 1619755157, 2832904331, 475102697, 354987331, 3295386430, 2816873951, 1039415736, 363972779, 1499307670, 2895506264, 3746345349, 2678027234, 3251899088, 955392878, 2329157295, 1343358773, 309573887, 2410178377, 2843173466, 361132917, 1755816798, 1319204283, 609284796, 1998842567, 1892325921, 223190385, 1483015769, 2876023365, 3876009312, 3199738344, 491524099, 160383137, 1219178873, 3870310498, 1114580266, 4279604166, 855339774, 1983818547, 2297848784, 4118592947, 4084409863, 2225095054, 4215601993, 946447434, 4205503762, 146088676, 778046685, 1876936928, 3157333726, 2173097090, 3215738813, 4135448234, 1219619643, 1936128689, 2897130162, 3336043946, 3779039524, 4200886837, 1359380925, 3402593091, 3140713935, 50855190, 3122065768, 1501584468, 2512255124, 687125154, 2666013386, 837819715, 3057258172, 3653455791, 2868624990, 322131992, 42534870, 4036564806, 798099710, 3533853670, 190914037, 3726947981, 2601169403, 602059656, 1365668439, 1918780004, 394790500, 277566007, 3891847777, 3365421094, 3139612253, 1380519090, 1183088424, 4203794803, 3049949521, 4214159484, 3446206962, 1875544460, 3207220027, 3288287026, 913535288, 178159620, 1410694581, 4190575040, 880731713, 1427805121, 404869072, 3413191414, 2865934056, 2899472677, 4239222733, 688404529, 3923323887, 933651074, 1199453686, 642723732, 2850614853, 3104368451, 3054041024, 3129913503, 2805843726, 1829781129, 3479062313, 650272704, 4224852052, 4085038685, 2616580676, 1793860711, 585126334, 2995262791, 520446536, 3855655015, 1571815563, 2240778227, 2051010344, 1694977983, 788402852, 1988089041, 2035558649, 1800063056, 1234412692, 2490862867, 417320514, 2415019489, 3374117797, 136034611, 898704236, 1247106941, 3923519397, 3563607190, 2454738671, 3522360389, 2672645476, 146828884, 3985140042, 4233949333, 1184742586, 860278824, 2815489967, 983483427, 3190081845, 3288865305, 3575181235, 1292151129, 4007823805, 4049420597, 3499391972, 1611182906, 1721268432, 2944249577, 2487212557, 789127738, 4027610014, 1057334138, 2902720905, 624), None), 'num_served': 5}
State after resampling 5 batches: {'source_state': {'source_state': None, 'flattened_items_yielded': 0}, 'random_state': (3, (2147483648, 766982754, 497961170, 3952298588, 2331775348, 1811986599, 3100132149, 3188119873, 3937547222, 215718963, 3315684082, 2978012849, 2428261856, 1298227695, 1704729580, 54668373, 3285201915, 3285178464, 1552935063, 988471319, 3135387943, 1691402966, 2757551880, 416056905, 907387413, 1072924981, 33903495, 2168419592, 2429050353, 831159753, 430343641, 3315943586, 1761671042, 864453023, 334804929, 1627478028, 2596811275, 3468733638, 3994375553, 1457139722, 3139722021, 1334790738, 2656639915, 3535811098, 1464315470, 2397423927, 885719490, 1140895889, 3284299483, 2854516462, 2734973817, 147484763, 792049954, 114360641, 3345458839, 1159898878, 1410498733, 2242989638, 453922141, 1344019764, 413870456, 3089405849, 1494382840, 470157779, 4266372830, 2831181573, 1361928602, 1589253513, 1381373062, 753045124, 987032420, 781978839, 2953638767, 3258570111, 3006718191, 1675218601, 1854232715, 3655829819, 1731242722, 2192104666, 1736665161, 740150002, 1195833394, 1610203160, 159492766, 4041488705, 3128952632, 2867295744, 3272632449, 886824304, 1791482600, 221114776, 3867175393, 4020804062, 1077871826, 1298953503, 996366221, 4149754679, 2483052703, 2615558283, 274318093, 1716359450, 4099129961, 1026774175, 288240973, 1459347562, 2365566296, 3690105224, 3065780221, 2050634722, 2652606621, 3185241207, 3026457375, 3456165734, 1880121515, 3398461093, 1795638629, 2379692076, 608668379, 1261955525, 84456522, 1913485156, 106878280, 757183891, 2913957588, 160418091, 2025664758, 141497907, 1657818026, 3053760160, 672193054, 4157546743, 223046484, 1623470498, 1201972930, 675008814, 684162366, 1738776330, 3025656654, 159760723, 1908867305, 3933381342, 2545706671, 467196949, 1427819885, 842150314, 4032903454, 2140851898, 3269883445, 975813755, 4177392955, 1556690684, 2535611513, 462962732, 67591358, 1729610528, 2025206740, 3153739740, 3255032049, 4186226368, 1070144624, 3107867195, 1621006038, 63742485, 835629717, 3189842019, 3950227584, 3184714559, 841836938, 1685394870, 657939920, 766156242, 1412314179, 1048281639, 4037161120, 2044490307, 1923947830, 3900790422, 907554295, 276417304, 860658646, 3574201134, 3508771399, 2110232300, 1636296241, 1405006077, 1093408401, 3243057343, 1519791182, 1994660136, 3829840937, 2644974199, 957955566, 3487641161, 1646922510, 1907939989, 3836029453, 3429168778, 201307778, 72550089, 2464394982, 1695794191, 3344785682, 996786130, 3589457196, 1241754792, 1291082245, 4224603667, 1194379475, 2693491244, 881186965, 2705535111, 445306946, 440274268, 1980827733, 2482488861, 3205215943, 2119332222, 2928713046, 1418736938, 652581136, 2474070665, 2208621536, 4171251876, 2303664214, 443762656, 2981912989, 2199228311, 2652261633, 3166738494, 3443009210, 3498764432, 424010848, 4065487566, 2262993542, 1756076712, 1477098233, 2742171915, 306185806, 3610666541, 923091830, 1034267993, 2336668648, 1880719718, 676878038, 3788797208, 3763351494, 3985428106, 1101865631, 1130501258, 3672967388, 3432003530, 4124438011, 1660392285, 4025484827, 2108074566, 3815409682, 42955331, 3248965569, 1643835718, 1246665668, 1071162194, 3814069229, 115491158, 985096811, 3311029186, 2990827378, 3101633320, 1648574497, 1470117052, 174145027, 2019894819, 2035501481, 459104123, 3507464599, 2093352659, 3369174406, 618767835, 4009895756, 935587447, 3956987426, 33753995, 307782427, 2473424805, 1440371818, 2382619594, 2138695812, 3164510238, 1318650933, 2910086616, 3886677510, 566832801, 3718063320, 1559818704, 183047272, 1142362855, 26306548, 645536402, 3875596208, 2272778168, 3512733409, 1897046338, 38248886, 2570759766, 1806313150, 860304898, 2433450338, 4124013408, 1216634590, 1275388896, 1169566669, 652504502, 761221427, 1448403764, 3129135949, 2513214949, 1269533687, 2413509541, 1226750363, 2450740925, 4094137910, 945759293, 3636927736, 3178020081, 2509964157, 3878869300, 1848504895, 2018369720, 1579755740, 1023627943, 924838836, 2653160914, 1812804174, 1521323076, 4012390528, 1338763317, 2608655937, 16022784, 1672945066, 2177189646, 2944458483, 2213810972, 1369873847, 1224017670, 130901785, 3595066712, 2259115284, 3316038259, 455873927, 2917250465, 3599550610, 1502173758, 684943436, 3079863840, 3144992244, 942855823, 1771140188, 2118780653, 3411494225, 2711180217, 4239611184, 1371891067, 3398566397, 3105518599, 1310665701, 3345178451, 2959821156, 242241789, 2148966880, 3192740583, 404401893, 3605380577, 1446464038, 3920522056, 2577523013, 1079274576, 286634372, 1752710796, 2351075979, 981312309, 3410516352, 3468455736, 1938779182, 1592494371, 1533303080, 88045436, 438252489, 1220512168, 3487004938, 3724852871, 1073434882, 3728218947, 2977555283, 4105408406, 3553772656, 1462006821, 3917158017, 119003006, 3470530198, 3439192457, 2829375771, 3555715155, 32324691, 588735808, 1459221702, 803072782, 2699519868, 1530797005, 79738580, 671990400, 4289511388, 3207115447, 2584684068, 832698998, 760958416, 1217440464, 2517898131, 2418819938, 3629956222, 3445024962, 206619378, 365007395, 522114139, 1707954431, 540423623, 1786750801, 369253262, 4239016754, 147889201, 1637777773, 236798285, 2806120188, 586972608, 2201782716, 1323327827, 819485723, 406078680, 3407345698, 1537169369, 1821691865, 527271655, 3751827102, 1465426495, 3321682429, 2179672664, 401355478, 1068871880, 24609462, 1403522408, 2311580015, 1532058170, 3877815340, 1768430711, 1619755157, 2832904331, 475102697, 354987331, 3295386430, 2816873951, 1039415736, 363972779, 1499307670, 2895506264, 3746345349, 2678027234, 3251899088, 955392878, 2329157295, 1343358773, 309573887, 2410178377, 2843173466, 361132917, 1755816798, 1319204283, 609284796, 1998842567, 1892325921, 223190385, 1483015769, 2876023365, 3876009312, 3199738344, 491524099, 160383137, 1219178873, 3870310498, 1114580266, 4279604166, 855339774, 1983818547, 2297848784, 4118592947, 4084409863, 2225095054, 4215601993, 946447434, 4205503762, 146088676, 778046685, 1876936928, 3157333726, 2173097090, 3215738813, 4135448234, 1219619643, 1936128689, 2897130162, 3336043946, 3779039524, 4200886837, 1359380925, 3402593091, 3140713935, 50855190, 3122065768, 1501584468, 2512255124, 687125154, 2666013386, 837819715, 3057258172, 3653455791, 2868624990, 322131992, 42534870, 4036564806, 798099710, 3533853670, 190914037, 3726947981, 2601169403, 602059656, 1365668439, 1918780004, 394790500, 277566007, 3891847777, 3365421094, 3139612253, 1380519090, 1183088424, 4203794803, 3049949521, 4214159484, 3446206962, 1875544460, 3207220027, 3288287026, 913535288, 178159620, 1410694581, 4190575040, 880731713, 1427805121, 404869072, 3413191414, 2865934056, 2899472677, 4239222733, 688404529, 3923323887, 933651074, 1199453686, 642723732, 2850614853, 3104368451, 3054041024, 3129913503, 2805843726, 1829781129, 3479062313, 650272704, 4224852052, 4085038685, 2616580676, 1793860711, 585126334, 2995262791, 520446536, 3855655015, 1571815563, 2240778227, 2051010344, 1694977983, 788402852, 1988089041, 2035558649, 1800063056, 1234412692, 2490862867, 417320514, 2415019489, 3374117797, 136034611, 898704236, 1247106941, 3923519397, 3563607190, 2454738671, 3522360389, 2672645476, 146828884, 3985140042, 4233949333, 1184742586, 860278824, 2815489967, 983483427, 3190081845, 3288865305, 3575181235, 1292151129, 4007823805, 4049420597, 3499391972, 1611182906, 1721268432, 2944249577, 2487212557, 789127738, 4027610014, 1057334138, 2902720905, 624), None), 'num_served': 5}
All items drawn after resetting are equal: True
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since the <code>state</code> of the iterator is just a dictionary, you can serialize it along with your model weights and restore them to continue training from exact point where you have checkpointed it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Making-Infinibatch-work-with-Pytorch-Dataloaders">
<a class="anchor" href="#Making-Infinibatch-work-with-Pytorch-Dataloaders" aria-hidden="true"><span class="octicon octicon-link"></span></a>Making Infinibatch work with Pytorch Dataloaders<a class="anchor-link" href="#Making-Infinibatch-work-with-Pytorch-Dataloaders"> </a>
</h1>
<p>Infinibatch by its very nature can be used only with <code>IterableDataset</code>. The training iterator with shuffling is infinite, so you must limit the training batches to some <code>n</code> steps if you want to maintain the notion of "epochs" to start validation. Or you can eschew whole notion of epochs by validating every <code>nth</code> step.
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>The multi processing workers of <code>DataLoader</code> should be set to zero, with <code>num_workers=0</code>. Rather use <code>ParallelMapIterator</code> to parallelize your pre-processing.
</div>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>While using <code>IterableDataset</code> and typical multi-gpu <code>DistributedDataParallel</code> (ddp) , you can pass <code>instance_rank</code> and <code>num_instances</code> as we will see in the final example below.
</div>
<div class="flash flash-error">
    <svg class="octicon octicon-alert" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 000 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 00.01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg>
    <strong>Warning: </strong>When using finite iterators with <code>ddp</code> for validation set, if you split the data using <code>instance_rank</code> option, the validation can get stuck.
</div>
This can happen either when your dataset is not divisible by number of <code>ddp</code> processes or doing dynamic batching caused an uneven number of batches produced for each instance. So it's better to do the validation in one GPU setting <code>instance_rank=0</code>. This is a quick hack, if you find a better option please let me know in the comments.

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">IterableDataset</span>


<span class="k">class</span> <span class="nc">IterableCheckpointedDataset</span><span class="p">(</span><span class="n">IterableDataset</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Wraps a CheckpointableIterator into a PyTorch IterableDataset, which is </span>
<span class="sd">    recognized by its type by PyTorch's DataLoader class.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="n">iterators</span><span class="o">.</span><span class="n">CheckpointableIterator</span><span class="p">,</span> 
                 <span class="n">should_reset</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="n">source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source_state</span> <span class="o">=</span> <span class="n">source</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_should_reset</span> <span class="o">=</span> <span class="n">should_reset</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># this is called in the forked clone</span>
        <span class="n">worker_info</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get_worker_info</span><span class="p">()</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">worker_info</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">worker_info</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># not supported since we can't get at the checkpoint for each worker</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_reset</span><span class="p">:</span>
            <span class="c1"># For training, since it's infinite iterator, if we train for </span>
            <span class="c1"># `n` batches with total instances less than dataset size</span>
            <span class="c1"># it's better not to reset the iterator by itself will cycle back</span>
            <span class="c1"># with a new shuffle order when all the instances are iterated once.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">setstate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_source_state</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span>



<span class="k">def</span> <span class="nf">create_wiki_dataloader</span><span class="p">(</span><span class="n">chunks_glob</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                           <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizerFast</span><span class="p">,</span>
                           <span class="n">is_train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
                           <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
                           <span class="n">tokens_per_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">16</span><span class="p">,</span> 
                           <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
                           <span class="n">buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span> 
                           <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1337</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
    <span class="n">sentence_it</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">chunked_dataset_iterator</span><span class="p">(</span>
        <span class="n">chunk_refs</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">chunks_glob</span><span class="p">),</span>
        <span class="n">read_chunk_fn</span> <span class="o">=</span> <span class="n">read_chunk</span><span class="p">,</span>
        <span class="n">buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span><span class="p">,</span> 
        <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> 
        <span class="n">train</span><span class="o">=</span><span class="n">is_train</span><span class="p">,</span> 
        <span class="n">shuffle</span><span class="o">=</span><span class="n">is_train</span> <span class="c1"># Shuffle Only on Train</span>
    <span class="p">)</span>
    <span class="n">tokenize_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">features_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">ParallelMapIterator</span><span class="p">(</span>
        <span class="n">source_iterator</span><span class="o">=</span><span class="n">sentence_it</span><span class="p">,</span>
        <span class="n">num_processes</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">num_items_per_process</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">tokenize_fn</span>
    <span class="p">)</span>
    <span class="n">batches_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">BucketedReadaheadBatchIterator</span><span class="p">(</span>
        <span class="n">source_iterator</span><span class="o">=</span><span class="n">features_it</span><span class="p">,</span>
        <span class="n">read_ahead</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> 
        <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">example</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="k">lambda</span> <span class="n">longest</span><span class="p">:</span> <span class="n">tokens_per_batch</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">longest</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span>
    <span class="p">)</span>
    <span class="n">collate_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>
    <span class="n">tensors_it</span> <span class="o">=</span> <span class="n">iterators</span><span class="o">.</span><span class="n">MapIterator</span><span class="p">(</span>
        <span class="n">batches_it</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">collate_fn</span>
    <span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">IterableCheckpointedDataset</span><span class="p">(</span>
        <span class="n">source</span><span class="o">=</span><span class="n">tensors_it</span><span class="p">,</span>
        <span class="n">should_reset</span><span class="o">=</span><span class="ow">not</span> <span class="n">is_train</span> <span class="c1">#Reset only for validation</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                      <span class="c1"># Very important to set this to 0.</span>
                      <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                      <span class="c1"># Important as we have already batched. </span>
                      <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="c1"># Since batch has only one member which has all the </span>
                      <span class="c1">#tensors already collated, we just return it.</span>
                      <span class="n">collate_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 
                      <span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"bert-base-cased"</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">create_wiki_dataloader</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">,</span>
                                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                                      <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">val_loader</span> <span class="o">=</span>  <span class="n">create_wiki_dataloader</span><span class="p">(</span><span class="s1">'wikitext-103-chunks/train.*.txt.gz'</span><span class="p">,</span>
                                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                                      <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#print(next(iter(train_loader)))</span>
<span class="c1">#print(next(iter(val_loader)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>

<script type="application/vnd.jupyter.widget-state+json">
{"fe358cc0ef5746cf9e5d33414a73ffac": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_view_name": "HBoxView", "_dom_classes": [], "_model_name": "HBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_f54dd763e89947f7aa5ebbd38b712011", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_83993e3ecc3f494eb0b452beeb6f8de1", "IPY_MODEL_494e8b56f10f4f8fa7e2699640ff37a7"]}}, "fb82a09047c147bb81a9544a86da1190": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_view_name": "HBoxView", "_dom_classes": [], "_model_name": "HBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_9a3d401a0a0f491987c40479405f22f1", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_2d158fd3b6b645d5b16e01012634368b", "IPY_MODEL_3704ff5f4ed74bb78fc9b32745c2fc7f"]}}}
</script>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="sai-prasanna/saiprasanna.in"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Blog on machine learning, NLP, Computer Science, philosophy, economics, animal rights, music, programming languages and endless other things that pique my curiosity.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/sai-prasanna" title="sai-prasanna"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/sai_prasanna" title="sai_prasanna"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
