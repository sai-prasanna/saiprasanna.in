<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-03-23">
<meta name="description" content="A deep dive into the math with code examples for the Cross Entropy Method (CEM).">

<title>λf.(λg.f (g g)) (λg.f (g g)) Sai - A Guide to the Cross Entropy Method (CEM)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><em>λf.(λg.f (g g)) (λg.f (g g))</em> <strong>Sai</strong></span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sai-prasanna"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/sai_prasanna"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A Guide to the Cross Entropy Method (CEM)</h1>
                  <div>
        <div class="description">
          <p>A deep dive into the math with code examples for the Cross Entropy Method (CEM).</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Optimization</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 23, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#rare-event-probability-estimation" id="toc-rare-event-probability-estimation" class="nav-link active" data-scroll-target="#rare-event-probability-estimation">Rare-event Probability Estimation</a>
  <ul class="collapse">
  <li><a href="#monte-carlo-sampling" id="toc-monte-carlo-sampling" class="nav-link" data-scroll-target="#monte-carlo-sampling">Monte-Carlo sampling</a></li>
  <li><a href="#importance-sampling" id="toc-importance-sampling" class="nav-link" data-scroll-target="#importance-sampling">Importance sampling</a></li>
  <li><a href="#cem-algorithm-for-rare-event-simulation" id="toc-cem-algorithm-for-rare-event-simulation" class="nav-link" data-scroll-target="#cem-algorithm-for-rare-event-simulation">CEM Algorithm for rare event simulation</a></li>
  </ul></li>
  <li><a href="#function-optimization" id="toc-function-optimization" class="nav-link" data-scroll-target="#function-optimization">Function optimization</a>
  <ul class="collapse">
  <li><a href="#cem-algorithm-for-optimization" id="toc-cem-algorithm-for-optimization" class="nav-link" data-scroll-target="#cem-algorithm-for-optimization">CEM algorithm for optimization</a></li>
  </ul></li>
  <li><a href="#discrete-or-combinatorial-optimization-with-cem" id="toc-discrete-or-combinatorial-optimization-with-cem" class="nav-link" data-scroll-target="#discrete-or-combinatorial-optimization-with-cem">Discrete or combinatorial optimization with CEM</a></li>
  <li><a href="#planning-with-cem" id="toc-planning-with-cem" class="nav-link" data-scroll-target="#planning-with-cem">Planning with CEM</a>
  <ul class="collapse">
  <li><a href="#when-is-cem-appropriate-in-mbrl" id="toc-when-is-cem-appropriate-in-mbrl" class="nav-link" data-scroll-target="#when-is-cem-appropriate-in-mbrl">When is CEM appropriate in MbRL?</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#acknowledgments" id="toc-acknowledgments" class="nav-link" data-scroll-target="#acknowledgments">Acknowledgments</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>The Cross-entropy method (CEM) is a technique for rare event simulation that can also used for solving black-box function optimization. A black box optimization technique allows us to find a function’s extremum (minima or maxima) without computing gradients. It is useful when computing gradients is costly or not possible. Moreover, since it is a global technique, it is theoretically guaranteed to converge to a global optimum, although, as we will see, it might not be the case in practice.</p>
<p>Our tutorial is adapted from the <span class="citation" data-cites="deboer05tutorial">Boer et al. (<a href="#ref-deboer05tutorial" role="doc-biblioref">2005</a>)</span>, <span class="citation" data-cites="rubinstein04crossentropy">Rubinstein and Kroese (<a href="#ref-rubinstein04crossentropy" role="doc-biblioref">2004</a>)</span>, <span class="citation" data-cites="botev13crossentropy">Botev et al. (<a href="#ref-botev13crossentropy" role="doc-biblioref">2013</a>)</span> and <span class="citation" data-cites="bhattacharyya21demystifying">Bhattacharyya (<a href="#ref-bhattacharyya21demystifying" role="doc-biblioref">2021</a>)</span>.</p>
<section id="rare-event-probability-estimation" class="level2">
<h2 class="anchored" data-anchor-id="rare-event-probability-estimation">Rare-event Probability Estimation</h2>
<p>Before looking at function optimization, we will dive into another mathematical problem of rare event probability estimate. This problem allows us to motivate and derive the CEM method, which can be extended later to optimization by viewing optimization as a rare event simulation problem. Rare event simulation is necessary to estimate the rare-event probability of non-trivial probability distributions.</p>
<p>Rare-event probability estimation is a useful problem in itself. For example, estimating the probability of ruin if you have a model or simulation of an insurance company is a rare-event estimation problem.</p>
<p>Consider the case of a random variable <span class="math inline">\(X\)</span> with a probability density function <span class="math inline">\(f(x; u)\)</span> parameterized by <span class="math inline">\(u\)</span>. Now if there is a function <span class="math inline">\(S(X)\)</span> such that we define <span class="math inline">\(\forall x; S(x) \ge \gamma\)</span> as rare events, then the rare event probability l</p>
<p><span class="math display">\[
\begin{align}
l &amp;:= P(S(X) \ge \gamma)
  &amp;= \int \mathcal{1}_{\{S(x) \ge \gamma\}} f(x; u)dx
\end{align}
\]</span></p>
<p>So now the question is how to estimate this quantity. It is intractable to compute this as S(X) could be complicated, or you do not know the actual pdf <span class="math inline">\(f\)</span> as an analytic function, only having access to sample from it or estimate it at a given input.</p>
<section id="monte-carlo-sampling" class="level3">
<h3 class="anchored" data-anchor-id="monte-carlo-sampling">Monte-Carlo sampling</h3>
<p>We can convert this probability to an expectation by</p>
<p><span class="math display">\[
\begin{align}
l &amp;= \int \mathcal{1}_{\{S(x) \ge \gamma\}} f(x; u)dx \\
  &amp;= \mathbb{E}_{x \sim f(.;u)}[\mathcal{1}_{\{S(x) \ge \gamma\}}]
\end{align}
\]</span></p>
<p>If we generate <span class="math inline">\(n\)</span> samples from the distribution, we can use Monte Carlo sampling to estimate the rare-event probability. Monte Carlo sampling involves estimating some statistics by using samples to approximate the distribution.</p>
<p><span class="math display">\[
\begin{align}
l &amp;= \mathbb{E}_{x \sim f(.;u)}\left[\mathcal{1}_{\{S(x) \ge \gamma\}}\right] \\
  &amp;\approx \dfrac{1}{n} \sum_{k=1}^{n} \mathcal{1}_{\{S(x_k) \ge \gamma\}}
\end{align}
\]</span></p>
<p>Where <span class="math inline">\(x_1 ... x_k\)</span> are i.i.d samples from f(.; u).</p>
<p>Let us implement some code to see how this works. First, we will define a <span class="math inline">\(f(.;u)\)</span> as a standard normal distribution <span class="math inline">\(\mathcal{N}(0, 1)\)</span> and rare event as <span class="math inline">\(X &gt; 2\)</span>, so <span class="math inline">\(S(X):= X\)</span> is an identity function. Since it is a normal distribution, we can compute l in closed form. It is just the <span class="math inline">\(1 - \text{CDF}(2)\)</span>. We picked the normal distribution for the sake of illustration; in the real world, the distribution could be something more complex, without a closed form CDF, or as noted before, you might not even know the functional form of the pdf, only can sample from it and evaluate it at a point or if S(X) is something complicated, again the integral might be intractable.</p>
<div id="cell-2" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm, uniform</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Problem setup</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x, u<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Standard normal distribution PDF</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> norm.pdf(x, loc<span class="op">=</span>u)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_f(num_samples, u<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.random.normal(loc<span class="op">=</span>u, size<span class="op">=</span>(num_samples,))</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> S(x):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># identity function</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># rare event threshold (gamma)</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>GAMMA <span class="op">=</span> <span class="fl">2.5</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>N_SEEDS <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterative Monte Carlo</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>NUM_SAMPLES <span class="op">=</span> np.array([<span class="dv">10</span><span class="op">**</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>, <span class="dv">9</span>)])</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Closed form solution using CDF</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>L_GT <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> norm.cdf(GAMMA)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rare_event_indicator(x):</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> S(x) <span class="op">&gt;=</span> GAMMA</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> monte_carlo_estimate(num_samples, sampler, estimand_fn):</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> sampler(num_samples)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(estimand_fn(samples))</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>mc_errors <span class="op">=</span> []</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> NUM_SAMPLES:</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    mc_probs <span class="op">=</span> []</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Repeat the experiment for multiple seeds and report average</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_SEEDS):</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> monte_carlo_estimate(n, sample_f, rare_event_indicator)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        mc_probs.append(p)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    errors <span class="op">=</span> np.<span class="bu">abs</span>(np.array(mc_probs) <span class="op">-</span> L_GT)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    mc_errors.append(np.mean(errors))</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the pdf and the rare event threshold and area</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">1000</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f(x))</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>plt.axvline(GAMMA, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x, f(x), where<span class="op">=</span>S(x) <span class="op">&gt;</span> GAMMA, color<span class="op">=</span><span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'f(x; u=[mu=0, sigma=1])'</span>)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PDF and rare event threshold'</span>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the error and std band</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>plt.plot(NUM_SAMPLES, mc_errors)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Samples (log scale)'</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Error (log scale)'</span>)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Error between Closed Form and Monte Carlo Estimate (log-log plot)'</span>)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-2-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Since sampling rare events implies we need many Monte Carlo samples to improve in error. Can we do something better?</p>
</section>
<section id="importance-sampling" class="level3">
<h3 class="anchored" data-anchor-id="importance-sampling">Importance sampling</h3>
<p>Instead of generating samples from <span class="math inline">\(f(.; u)\)</span>, what if we generate data from another distribution with p.d.f <span class="math inline">\(g(x)\)</span> where the rare samples are easier to obtain? Then, if we can compute the p.d.f of our original distribution <span class="math inline">\(f(.; u)\)</span> and our new distribution <span class="math inline">\(g(x)\)</span>, we can use importance sampling to compute <span class="math inline">\(l\)</span> using these samples.</p>
<p><span class="math display">\[ \begin{align}
l &amp;= \int \mathcal{1}_{\{S(x) \ge \gamma\}} f(x; u)dx \\
  &amp;= \int \mathcal{1}_{\{S(x) \ge \gamma\}} f(x; u) \dfrac{g(x)}{g(x)} dx \\
  &amp;= \mathbb{E}_{x \sim g(.)}\left[ \mathcal{1}_{\{S(x) \ge \gamma\}} \dfrac{f(x; u)}{g(x)} \right]
\end{align} \]</span></p>
<p>And the monte-carlo estimate now can be done over samples from <span class="math inline">\(g(x)\)</span></p>
<p><span class="math display">\[
\begin{align}
l &amp;=\mathbb{E}_{x \sim g(.)}\left[ \mathcal{1}_{\{S(x) \ge \gamma\}} \dfrac{f(x; u)}{g(x)} \right] \\
  &amp;\approx \dfrac{1}{n} \sum_{k=1}^{n} \mathcal{1}_{\{S(x_k) \ge \gamma\}} \dfrac{f(x_k; u)}{g(x_k)}
\end{align}
\]</span> Where <span class="math inline">\(x_1 ... x_k\)</span> are i.i.d samples from g(x). Now the question becomes how do we select this <span class="math inline">\(g(x)\)</span>? Let us first try a few examples of <span class="math inline">\(g(x)\)</span> and see how it compares to our previous Monte Carlo estimate.</p>
<div id="cell-4" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pick g1 to be uniform distribution near the rare event threshold and g2 to be a normal distribution near the rare event threshold</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> g1_uniform(x):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> uniform.pdf(x, loc<span class="op">=</span>GAMMA <span class="op">-</span> <span class="fl">0.5</span>, scale<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_g1(num_samples):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.random.uniform(size<span class="op">=</span>(num_samples,), low<span class="op">=</span>GAMMA <span class="op">-</span> <span class="fl">0.5</span>, high<span class="op">=</span>GAMMA <span class="op">+</span> <span class="fl">0.5</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> g2_normal(x):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> norm.pdf(x, loc<span class="op">=</span>GAMMA, scale<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_g2(num_samples):</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.random.normal(loc<span class="op">=</span>GAMMA, scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>(num_samples,))</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot f, g1, and g2 and rare event threshold</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">1000</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f(x), label<span class="op">=</span><span class="st">'f'</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>plt.plot(x, g1_uniform(x), label<span class="op">=</span><span class="st">'g1: Uniform(2.5, 1)'</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>plt.plot(x, g2_normal(x), label<span class="op">=</span><span class="st">'g2: Normal(3.0, 0.5)'</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>plt.axvline(GAMMA, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Rare Event Threshold'</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x, f(x), where<span class="op">=</span>S(x) <span class="op">&gt;</span> GAMMA, color<span class="op">=</span><span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Rare Event Area'</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PDFs'</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Importance Sampling</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rare_event_prob_importance_sampling(num_samples, rare_event_threshold, g, sample_g):</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> sample_g(num_samples)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean((S(x) <span class="op">&gt;=</span> rare_event_threshold) <span class="op">*</span> f(x) <span class="op">/</span> g(x)) </span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the probabilities using importance sampling for g1 and g2 for the n in num_samples and plot everything in one log-log plot</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>g1_is_errors <span class="op">=</span> []</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>g2_is_errors <span class="op">=</span> []</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> NUM_SAMPLES:</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    g1_is_estimates <span class="op">=</span> []</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_SEEDS):</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> rare_event_prob_importance_sampling(n, GAMMA, g1_uniform, sample_g1)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>        g1_is_estimates.append(p)</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>    g1_is_error <span class="op">=</span> np.<span class="bu">abs</span>(np.mean(g1_is_estimates) <span class="op">-</span> L_GT)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    g1_is_errors.append(g1_is_error)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>    g2_is_estimates <span class="op">=</span> []</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_SEEDS):</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> rare_event_prob_importance_sampling(n, GAMMA, g2_normal, sample_g2)</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>        g2_is_estimates.append(p)</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    g2_is_error <span class="op">=</span> np.<span class="bu">abs</span>(np.mean(g2_is_estimates) <span class="op">-</span> L_GT)</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    g2_is_errors.append(g2_is_error)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the order of error for importance sampling</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>plt.plot(NUM_SAMPLES, mc_errors, label<span class="op">=</span><span class="st">'Vanilla Monte Carlo'</span>)</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>plt.plot(NUM_SAMPLES, g1_is_errors, label<span class="op">=</span><span class="st">'MC with IS - g1: Uniform Distribution'</span>)</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>plt.plot(NUM_SAMPLES, g2_is_errors, label<span class="op">=</span><span class="st">'MC with IS - g2: Normal Distribution'</span>)</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Samples (log scale)'</span>)</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Error (log scale)'</span>)</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Error between Closed Form and Different Estimates (log-log plot)'</span>)</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Different importance sampling distribution leads to better or worse performance compared to Monte Carlo sampling. Intuitively, if <span class="math inline">\(g(x)\)</span> puts a lot of probability mass over areas where <span class="math inline">\(S(x) &gt; \gamma\)</span>, then we can get accurate estimates faster.</p>
<p>The optimal importance sampling estimator (which has zero variance) can be derived to be</p>
<p><span id="eq-g-star"><span class="math display">\[
g^*(x) = \mathcal{1}_{\{S(x) \ge \gamma\}} \dfrac{f(x; u)}{l}
\tag{1}\]</span></span></p>
<p>Let us plot it to see why it is optimal.</p>
<div id="cell-8" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> optimal_g(x):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (S(x) <span class="op">&gt;=</span> GAMMA) <span class="op">*</span> f(x) <span class="op">/</span> L_GT</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># plot it with f </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">1000</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f(x), label<span class="op">=</span><span class="st">'f'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>optimal_g_pdf <span class="op">=</span> optimal_g(x)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>plt.plot(x[optimal_g_pdf <span class="op">&gt;</span> <span class="dv">0</span>], optimal_g_pdf[optimal_g_pdf <span class="op">&gt;</span> <span class="dv">0</span>], label<span class="op">=</span><span class="st">'Optimal g'</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(GAMMA, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Rare Event Threshold'</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x, f(x), where<span class="op">=</span>S(x) <span class="op">&gt;</span> GAMMA, color<span class="op">=</span><span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Rare Event Area'</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PDFs'</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can see that this distribution corresponds to the region where rare samples occur, and it is proportional to the <span class="math inline">\(f(x; u)\)</span>. To further convince yourself of this, plug <span class="math inline">\(g*(x)\)</span> into the importance sampling Monte Carlo estimator.</p>
<p><span class="math display">\[
\begin{align}
\hat{l} &amp;= \dfrac{1}{n} \sum_{k=1}^{n} \mathcal{1}_{\{S(x_k) \ge \gamma\}} \dfrac{f(x_k; u)}{g^*(x_k)} \\
        &amp;= \dfrac{1}{n} \sum_{k=1}^{n} l \\
        &amp;= l
\end{align}
\]</span></p>
<p><strong>But wait!</strong> We wanted to estimate <span class="math inline">\(l\)</span>, but now our optimal importance sampling distribution has l in it. However, this indicates what we want our <span class="math inline">\(g(x)\)</span> to approach. We want to find a g that’s as close as possible to <span class="math inline">\(g*\)</span>. Theoretically, g can be any distribution, but since we want something we want to sample from, let us restrict g(x) to the same family as the original pdf <span class="math inline">\(f\)</span>. So <span class="math inline">\(g(x) = f(x; v)\)</span> with <span class="math inline">\(v\)</span> being the parameters of this distribution. We aim to optimize v so that <span class="math inline">\(g(x)\)</span> approximates <span class="math inline">\(g^*(x)\)</span> as close as possible. The closeness between two distributions can be captured by the notion of cross-entropy between distributions, i.e., <span class="math inline">\(\mathcal{D} (g^*(x), f(x; v))\)</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Cross-entropy is not a symmetric metric. The formulation we use tries to place probability mass on the mean of the optimal distribution.</p>
</div>
</div>
<p>Our <span class="math inline">\(g^*(x) = f (x; v)\)</span> if the cross entropy is zero. <span class="math display">\[
\begin{align*}
v^{*} &amp;= \arg\min_{v} \mathcal{D} (g^*(x), f(x; v)) \\
      &amp;= \arg\min_{v} E [\ln f(x; v)] \\
      &amp;= \arg\min_{v} \int g^*(x) \ln g^*(x) dx - \int g^*(x) \ln f(x; v) dx.
\end{align*}
\]</span></p>
<p>Since the <span class="math inline">\(g^*(x)\)</span> is independent of v, our minimization objective is left with</p>
<p><span class="math display">\[
\begin{align*}
v^{*} &amp;=  \arg\min_{v} - \int g^*(x) \ln f(x; v) dx.
\end{align*}
\]</span></p>
<p>Removing the negative sign by converting minimization to maximization and plugging in the expression for <span class="math inline">\(g^*(x)\)</span> {<a href="#eq-g-star" class="quarto-xref">Equation&nbsp;1</a>}</p>
<p><span class="math display">\[
\begin{align*}
v^{*} &amp;=  \arg\max_{v} \int  \mathcal{1}_{\{S(x) \ge \gamma\}} \dfrac{f(x; u)}{l} \ln f(x; v) dx.
\end{align*}
\]</span> Since l is independent of v, we can finally discard it. This removes the <strong>chicken and egg</strong> problem of knowing <span class="math inline">\(l\)</span> to estimate <span class="math inline">\(l\)</span>. We now have</p>
<p><span class="math display">\[
\begin{align*}
v^{*} &amp;=  \arg\max_{v} \int  \mathcal{1}_{\{S(x) \ge \gamma\}} f(x; u) \ln f(x; v) dx,\\
      &amp;=  \arg\max_{v} E_{x \sim f(.;u)} [\mathcal{1}_{\{S(x) \ge \gamma\}}  \ln f(x; v)] ,
\end{align*}
\]</span></p>
<p>Now, we have a maximization problem to find the parameters of the importance sampling density function closest to the optimal one. This expectation is now the same as finding the maximum likelihood estimate of the parameter <span class="math inline">\(v\)</span> for rare data samples (<span class="math inline">\(S(x) \ge \gamma\)</span>). It has a closed-form solution for distributions in the natural exponential family. But we are not done yet; the maximum likelihood is over rare samples! If we naively sample from <span class="math inline">\(f(.; u)\)</span>, we need lots of samples for at least some indicators <span class="math inline">\(S(x) \ge \gamma\)</span> to be one and hence allowing maximization of v. It Seems like we end up where we started with monte-carlo. However, it turns out that we can do something better with this objective.</p>
<p>First, we introduce <span class="math inline">\(w\)</span>, a reference parameter, and apply the same trick used in importance sampling to switch expectations to samples under distribution parameterized by <span class="math inline">\(w\)</span> instead of <span class="math inline">\(u\)</span>. The reason why we introduce this parameter will become apparent next.</p>
<p><span class="math display">\[
\begin{align*}
v^{*} &amp;= \arg\max_{v} E_{x \sim f(.;u)} [\mathcal{1}_{\{S(x) \ge \gamma\}}  \ln f(x; v)] , \\
      &amp;= \arg\max_{v} E_{x \sim f(.;w)} [\mathcal{1}_{\{S(x) \ge \gamma\}} \dfrac{f(x; u)}{f(x; w)} \ln f(x; v)] , \\
      &amp;= \arg\max_{v} E_{x \sim f(.;w)} [\mathcal{1}_{\{S(x) \ge \gamma\}} \dfrac{f(x; u)}{f(x; w)} \ln f(x; v)] ,
\end{align*}
\]</span></p>
<p>Our problem was <span class="math inline">\(S(x) &gt; \gamma\)</span> is rare; instead of trying to solve for this, we make the problem easier by constructing a sequence of threshold of rare event thresholds <span class="math inline">\(\{ \gamma_t \}\)</span> and reference parameters <span class="math inline">\(\{v_t\}\)</span> to converge to <span class="math inline">\(\gamma^*, v^*\)</span>. At each iteration <span class="math inline">\(t\)</span> we sample <span class="math inline">\(x_1, ... x_n\)</span> from the current importance sampling density <span class="math inline">\(f(., v_t)\)</span> and let <span class="math inline">\(\gamma_t\)</span> be the <span class="math inline">\((1 - \rho)\)</span> quantile value of the set <span class="math inline">\(S(x_1),...,S(x_n)\)</span>, where <span class="math inline">\(\rho\)</span> is a hyperparameter also known as <em>rarity parameter</em>. We then find <span class="math inline">\(v_{t+1}\)</span> by maximizing the empirical expectation, <span class="math display">\[
v_{t+1} = \arg\max_{v} \dfrac{1}{n} \sum_{k=1}^{n} \left[\mathcal{1}_{\{S(x_k) \ge \gamma_t\}} \dfrac{f(x_k; u)}{f(x_k; v_t)} \ln f(x_k; v)\right]
\]</span></p>
<p>This maximization yields <span class="math inline">\(f(., v_{t+1})\)</span>, which minimizes the cross entropy of the optimal importance sampling distribution <span class="math inline">\(g*(x)\)</span> for the <span class="math inline">\(\gamma_t\)</span> threshold. The solution of this maximization is the maximum-likelihood solution for the “elite samples” weighted by the <span class="math inline">\(\dfrac{f(x_k; u)}{f(x_k; v_t)}\)</span> also known as the “likelihood ratio.” The total elite samples <span class="math inline">\(n_e = [\rho n]\)</span>, and they by construction of <span class="math inline">\(\rho_t\)</span> satisfy <span class="math inline">\(S(x_i) \ge \rho_t\)</span>.</p>
</section>
<section id="cem-algorithm-for-rare-event-simulation" class="level3">
<h3 class="anchored" data-anchor-id="cem-algorithm-for-rare-event-simulation">CEM Algorithm for rare event simulation</h3>
<ol type="1">
<li><p>Define <span class="math inline">\(v_1 = u\)</span> and set t=1. Let <span class="math inline">\(n_e = \lceil \rho n \rceil\)</span></p></li>
<li><p>Generate <span class="math inline">\(n\)</span> i.i.d samples <span class="math inline">\(x_i, ... x_n\)</span> drawn from <span class="math inline">\(f(.; v_t)\)</span>. Calculate <span class="math inline">\(S_i = S(x_i)\)</span> for all i and order these from smallest to largest <span class="math inline">\(S_{(1)} ... \le S_{(n)}\)</span>. Let <span class="math inline">\(\gamma_t\)</span> to be the <span class="math inline">\((1 - \rho)\)</span>-quantile; that is <em>t = S</em>{(n - n_e + 1)}. If <span class="math inline">\(\gamma_t &gt;  \gamma\)</span>, we set it to the original problem value, i.e., <span class="math inline">\(\gamma_t = \gamma\)</span>.</p></li>
<li><p>Then, with the same samples we got in (2), we solve the following maximization to obtain <span class="math inline">\(v_{t+1}\)</span> <span class="math display">\[
         \begin{align*}
         v_{t+1} &amp;= \arg\max_{v} \dfrac{1}{n} \sum_{k=1}^{n} \left[\mathcal{1}_{\{S(x_k) \ge \gamma_t\}} \dfrac{f(x_k; u)}{f(x_k; v_t)} \ln f(x_k; v)\right] , \\
         \end{align*}
   \]</span></p></li>
<li><p><strong>If</strong> <span class="math inline">\(\gamma_t &lt; \gamma\)</span> and $ t &lt; $, set <span class="math inline">\(t = t+1\)</span> and reiterate from step 2. <strong>Else</strong>, continue to step 5.</p></li>
<li><p>Sample <span class="math inline">\(x_1, x_2, ... x_{n'}\)</span> from <span class="math inline">\(f(.; v_T)\)</span>, where <span class="math inline">\(t=T\)</span> is the total iterations our algorithm ran. Estimate the rare-event probability <span class="math inline">\(l\)</span> using importance sampling <span class="math inline">\(l = \approx \dfrac{1}{n'} \sum_{k=1}^{n'} \mathcal{1}_{\{S(x_k) \ge \gamma\}} \dfrac{f(x_k; u)}{f(x_k; v_T)}\)</span>.</p></li>
</ol>
<p>For distributions that belong to a natural exponential family, the maximization at (3) has the following closed-form solution for v being the mean parameter of the distribution.</p>
<p><span class="math display">\[
v_{t+1} = \dfrac{\sum_{k=1}^{n} \mathcal{1}_{\{S(x_k) \ge \gamma_t\} W(x_i; u, v_t) x_i}}{\mathcal{1}_{\{S(x_k) \ge \gamma_t\} W(x_i; u, v_t)}}
\]</span></p>
<p>where <span class="math inline">\(W(x_i; u, v_t) = \dfrac{f(x_i; u)}{f(x_i; v_t)}\)</span> is the likelihood ratio. To derive this solution, compute the derivative w.r.t <span class="math inline">\(v\)</span> and set it to zero.</p>
<p>Now, with this setup, let us jump into the code.</p>
<div id="cell-10" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cem_rare_event_estimate(n, max_sample_n, u<span class="op">=</span><span class="dv">0</span>, rho<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    v_t <span class="op">=</span> u</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    gamma_t <span class="op">=</span> <span class="va">None</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    n_e <span class="op">=</span> <span class="bu">int</span>(np.ceil(n <span class="op">*</span> rho))</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    max_iter <span class="op">=</span> max_sample_n <span class="op">//</span> n</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> t <span class="op">&lt;</span> max_iter <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> sample_f(n)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        s <span class="op">=</span> S(samples)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute the quantile of the samples</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        sort_idx <span class="op">=</span> np.argsort(s)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        sorted_s <span class="op">=</span> s[sort_idx]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        gamma_t <span class="op">=</span> sorted_s[<span class="op">-</span>n_e]</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> gamma_t <span class="op">&gt;</span> GAMMA:</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            gamma_t <span class="op">=</span> GAMMA</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        elite_samples <span class="op">=</span> samples[sort_idx][<span class="op">-</span>n_e:]</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> f(elite_samples, u) <span class="op">/</span> f(elite_samples, v_t)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># maximize the cross entropy objective to get the next v_t.</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Here we use the closed form solution for the normal distribution</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        v_t <span class="op">=</span> np.<span class="bu">sum</span>(weights <span class="op">*</span> elite_samples) <span class="op">/</span> np.<span class="bu">sum</span>(weights)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        t <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> gamma_t <span class="op">==</span> GAMMA:</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    actual_sample_n <span class="op">=</span> t <span class="op">*</span> n</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    remaining_samples <span class="op">=</span> max_sample_n <span class="op">-</span> actual_sample_n</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    estimate <span class="op">=</span> rare_event_prob_importance_sampling(remaining_samples, GAMMA, <span class="kw">lambda</span> x: f(x, v_t), <span class="kw">lambda</span> n: sample_f(n, v_t))</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> estimate</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>cem_errors <span class="op">=</span> []</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> NUM_SAMPLES:</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    max_samples <span class="op">=</span> n</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    estimates <span class="op">=</span> []</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(N_SEEDS):</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        estimate <span class="op">=</span> cem_rare_event_estimate(max_samples <span class="op">//</span> <span class="dv">10</span>, max_samples)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        estimates.append(estimate)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    cem_errors.append(np.<span class="bu">abs</span>(np.mean(estimates) <span class="op">-</span> L_GT))</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the order of error for importance sampling</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>plt.plot(NUM_SAMPLES, mc_errors, label<span class="op">=</span><span class="st">'Vanilla Monte Carlo'</span>)</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>plt.plot(NUM_SAMPLES, cem_errors, label<span class="op">=</span><span class="st">'Error of CEM Estimate'</span>)</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Samples (log scale)'</span>)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Error (log scale)'</span>)</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Error (log-log plot)'</span>)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We see orders of magnitude improvement in the error using CEM compared to the naive Monte Carlo method for the same number of samples. We can get even better if we carefully tune the hyperparameters of the number of maximum iterations, samples per iteration, the number of samples to use for the final importance sampling, and the rarity parameter <span class="math inline">\(rho\)</span>.</p>
</section>
</section>
<section id="function-optimization" class="level2">
<h2 class="anchored" data-anchor-id="function-optimization">Function optimization</h2>
<p>While rare event probability has real-world uses, function optimization is a more common problem. Say you want to find the maximum of <span class="math inline">\(S(x)\)</span> over a given set <span class="math inline">\(\mathcal{X}\)</span>. For simplicity, assume that there is only one maximum. Then,</p>
<p><span class="math display">\[
S(x^*) = \gamma^* = \max_{x \in \mathcal{X}} S(x)
\]</span></p>
<p>For some arbitrary distribution <span class="math inline">\(f(x)\)</span> over <span class="math inline">\(\mathcal{X}\)</span>, since the maximum is rare, we can associate the maximization with the problem of estimating <span class="math inline">\(l = P_f(S(x) \ge \gamma)\)</span>. The difference with rare event estimation is that we do not have <span class="math inline">\(\gamma\)</span>, and we only care about finding <span class="math inline">\(\gamma_*\)</span> and not <span class="math inline">\(l\)</span> for our arbitrary initial distribution <span class="math inline">\(f\)</span>. However, from our prior algorithm for rare event estimation, we now have a method to get monotonically better <span class="math inline">\(gamma_t\)</span> (there are some proofs for this I do not know and am glossing over). We can modify the rare event estimation algorithm in three important ways,</p>
<ol type="1">
<li>We can set <span class="math inline">\(u\)</span> to <span class="math inline">\(v_t\)</span> in each step. This implies we are trying to estimate optimal importance sampling distribution concerning the previous step parameter <span class="math inline">\(v_t\)</span> and not <span class="math inline">\(u\)</span>. This makes the likeihood ratio <span class="math inline">\(f(x; u)/f(x; v_t) = 1\)</span>.</li>
<li>Since we only care about <span class="math inline">\(\gamma^*\)</span> we do not have to compute the <a href="#cem-algorithm-for-rare-event-simulation">step 4</a>.</li>
<li>Finally, since we do not have the actual <span class="math inline">\(\gamma^*\)</span>, we must define some stopping criterion. It could be checking if <span class="math inline">\(\gamma_t\)</span> in some <span class="math inline">\(c\)</span> steps have the same or close enough values.</li>
</ol>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Some references assume f(x) to be uniform. I do not understand how to have a uniform distribution if <span class="math inline">\(x \in [-\inf, \inf]\)</span>.</p>
</div>
</div>
<section id="cem-algorithm-for-optimization" class="level3">
<h3 class="anchored" data-anchor-id="cem-algorithm-for-optimization">CEM algorithm for optimization</h3>
<ol type="1">
<li><p>Define <span class="math inline">\(v_1 = u\)</span> where <span class="math inline">\(u\)</span> is some arbitrary initial parameter and set t=1. Let <span class="math inline">\(n_e = \lceil \rho n \rceil\)</span>.</p></li>
<li><p>Generate <span class="math inline">\(n\)</span> i.i.d samples <span class="math inline">\(x_i, ... x_n\)</span> drawn from <span class="math inline">\(f(.; v_t)\)</span>. Calculate <span class="math inline">\(S_i = S(x_i)\)</span> for all i and order these from smallest to largest <span class="math inline">\(S_{(1)} ... \le S_{(n)}\)</span>. Let <span class="math inline">\(\gamma_t\)</span> to be the <span class="math inline">\((1 - \rho)\)</span>-quantile; that is <span class="math inline">\(\gamma_t = S_{(n - n_e + 1)}\)</span>.</p></li>
<li><p>Then, with the same samples we got in (2), we solve the following maximization to obtain <span class="math inline">\(v_{t+1}\)</span> <span class="math display">\[
         \begin{align*}
         v_{t+1} &amp;= \arg\max_{v} \dfrac{1}{n} \sum_{k=1}^{n} \left[\mathcal{1}_{\{S(x_k) \ge \gamma_t\}} \ln f(x_k; v)\right] , \\
         \end{align*}
   \]</span></p></li>
<li><p><strong>If</strong> stopping criterion is not met <strong>and</strong> $t &lt; $; Set <span class="math inline">\(t = t+1\)</span> and reiterate from step 2. <strong>Else</strong>; Stop.</p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>An alternative heuristic is to update <span class="math inline">\(v_{t+1}\)</span> in step 3 with an exponential moving average instead of a simple replacement. <span class="math inline">\(v_{t+1} = (1 - \alpha) v_t + \alpha v_{\text{new}}\)</span></p>
</div>
</div>
<p>In practice, we pick f as a normal distribution for optimizing functions on a continuous domain. Moreover, in this case, we can pick both mean and standard deviation as the parameters of the distribution family. i.e., <span class="math inline">\(v_t = [\mu, \sigma]\)</span>. The maximization of step 3 is just the MLE estimate of elites, which is simply the mean and standard deviation for the elite samples for our normal distribution. Now, let us dive into the code to implement CEM and optimize the Rastrigin function, a highly nonlinear function with many local minima.</p>
<div id="cell-13" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>) <span class="co"># CEM doesn't converge always, so this is the best case scenario, in practice you have to tune the hyperparameters</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># # Define the Rastrigin 1d function which has lots of local minima</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> S_rastrigin(x, A<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> A <span class="op">+</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> A <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Cross-Entropy Method (CEM)</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cem(f, u, num_samples, rho, max_iterations):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    num_elites <span class="op">=</span> <span class="bu">int</span>(math.ceil(rho <span class="op">*</span> num_samples))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    v_t <span class="op">=</span> u  <span class="co"># mean &amp; std</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    gamma_t <span class="op">=</span> <span class="va">None</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    history_v <span class="op">=</span> [v_t]</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(max_iterations):</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We simply use max_iterations iterations here, but in practice we can also check if the mean and std have converged</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        mean_t, std_t <span class="op">=</span> v_t</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> np.random.normal(mean_t, std_t, num_samples)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># -f(x) because we want to minimize the function</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> np.array([<span class="op">-</span>f(x) <span class="cf">for</span> x <span class="kw">in</span> samples])</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        sorted_idx <span class="op">=</span> np.argsort(scores)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        elite_idx <span class="op">=</span> sorted_idx[<span class="op">-</span>num_elites:]</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        gamma_t <span class="op">=</span> samples[elite_idx[<span class="dv">0</span>]]</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        elites <span class="op">=</span> samples[elite_idx]</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The MLE of the elites is the closed-form solution for the cross-entropy objective for the normal distribution</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        v_t <span class="op">=</span> np.array([</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            np.mean(elites, axis<span class="op">=</span><span class="dv">0</span>), </span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            np.std(elites, axis<span class="op">=</span><span class="dv">0</span>),</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        history_v.append(v_t)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># In practise we might not coverge to a gamma_* in the  given number of iterations, so we can use the mean v_t[0] as the solution instead of gamma_t</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    solution <span class="op">=</span> v_t[<span class="dv">0</span>]</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> gamma_t, history_v</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_optimization(smooth<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run the functions</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    solution, v_t_history <span class="op">=</span> cem(S_rastrigin, np.array([<span class="op">-</span><span class="dv">4</span>, <span class="dv">1</span>]), <span class="dv">10000</span>, <span class="fl">0.001</span>, <span class="dv">3</span>)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">100</span>)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> S_rastrigin(x)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    plt.plot(x, y, label<span class="op">=</span><span class="st">'S(x) (Rastrigin Function)'</span>)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t, v_t <span class="kw">in</span> <span class="bu">enumerate</span>(v_t_history):</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        mean, std <span class="op">=</span> v_t</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate data for the x axis</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> np.linspace(mean <span class="op">-</span> <span class="dv">3</span><span class="op">*</span>std, mean <span class="op">+</span> <span class="dv">3</span><span class="op">*</span>std, <span class="dv">100</span>)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate data for the y axis</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> norm.pdf(x, mean, std)</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot the normal distribution curve</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        plt.plot(x, y, label<span class="op">=</span><span class="ss">f"v_</span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'S(x)'</span>)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Quadratic function (smooth=</span><span class="sc">{</span>smooth<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    plt.ylim(<span class="dv">0</span>, <span class="dv">20</span>)</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Solution is </span><span class="sc">{</span>solution<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>plot_optimization()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Solution is 1.0823134976106763e-05</code></pre>
</div>
</div>
<p>The above example illustrates how we can converge to the global minimum in black-box optimization with CEM.</p>
</section>
</section>
<section id="discrete-or-combinatorial-optimization-with-cem" class="level1">
<h1>Discrete or combinatorial optimization with CEM</h1>
<p>We saw an example of applying CEM to optimize continuous parameters. It can also be applied to discrete settings. <span class="citation" data-cites="botev13crossentropy">Botev et al. (<a href="#ref-botev13crossentropy" role="doc-biblioref">2013</a>)</span> highlights a few examples of applying CEM to discrete optimization, such as the Knapsack packing problem, boolean satisfiability problem, and network planning problem.</p>
</section>
<section id="planning-with-cem" class="level1">
<h1>Planning with CEM</h1>
<p>Consider the reinforcement learning setting where we want a policy that maximizes rewards (or conversely minimizes some cost in optimal control setting) in an environment.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rl.png" class="img-fluid figure-img"></p>
<figcaption>RL Environment - <span class="citation" data-cites="Sutton1998">Sutton and Barto (<a href="#ref-Sutton1998" role="doc-biblioref">2018</a>)</span></figcaption>
</figure>
</div>
<p>A policy comprises actions. Assume we have a simulator or even a learned model of the environment, which can predict the next state $P(S’|S, A) and the reward function <span class="math inline">\(R(S, A)\)</span> given the current state and action. Then, we can directly aim to optimize the set of actions that maximizes the rewards for a given horizon <span class="math inline">\(H\)</span>. <span class="math display">\[
\begin{equation}
\arg\max_{a_k, ... a_{k+H}} \sum_{t=k}^{k+H} R(s_t, a_t)
\end{equation}
\]</span></p>
<p>Where starting from some arbirtary state (usually the current state) <span class="math inline">\(s_k\)</span> we can rollout future states <span class="math inline">\(s_k ... s_{k+H}\)</span> using the model, either sampling the next state or using the mode of the distribution if the next state is stochastic. Then, we compute the rewards and maximize them.</p>
<p>We can apply CEM here on the trajectory <span class="math inline">\(a_1... a_k\)</span> to solve this problem.</p>
<p>Since our model of the environment might be imperfect, the common practice is only to act the first action <span class="math inline">\(a_k\)</span> in the real environment and then re-solve the same problem from the real s_{k+1}. This is known as model predictive control (MPC).</p>
<p>Some relevant works in MbRL using CEM for planning are <span class="citation" data-cites="hafner2018learning">Hafner et al. (<a href="#ref-hafner2018learning" role="doc-biblioref">2018</a>)</span>, <span class="citation" data-cites="ChuaCML18">Chua et al. (<a href="#ref-ChuaCML18" role="doc-biblioref">2018</a>)</span>, <span class="citation" data-cites="HansenSW22">Hansen, Su, and Wang (<a href="#ref-HansenSW22" role="doc-biblioref">2022</a>)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The above formulation does not yield an optimal trajectory even for a perfect model, as we do not consider the whole horizon till episode termination. If we learn an optimal value function V(S) along with the CEM policy, we can compute the final cost by using it. i.e., maximize <span class="math inline">\(\arg\max_{a_k, ... a_{k+H}} \sum_{t=k}^{k+H} R(s_t, a_t) + V(s_{k+H+1})\)</span> where we rely on the model being more accurate than the value for some steps. <span class="citation" data-cites="HansenSW22">Hansen, Su, and Wang (<a href="#ref-HansenSW22" role="doc-biblioref">2022</a>)</span> does this precisely.</p>
</div>
</div>
<section id="when-is-cem-appropriate-in-mbrl" class="level3">
<h3 class="anchored" data-anchor-id="when-is-cem-appropriate-in-mbrl">When is CEM appropriate in MbRL?</h3>
<p>In modern deep MbRL, we usually learn a model that is based on a neural network. In this case, instead of CEM, we can consider optimizing actions based on gradients instead of black-box CEM, as we can compute the gradients of the rewards concerning the actions. But this is tricky as models parameterized by neural nets could have a non-convex optimization landscape, directly optimizing actions could get stuck in local minima. This is usually used to motivate using black-box approach such as CEM for planning. But note that there are new works <span class="citation" data-cites="v2023gradientbased">(<a href="#ref-v2023gradientbased" role="doc-biblioref">V et al. 2023</a>)</span> pointing to efficiency of pure-gradient based optimization even for complex models.</p>
<p>And there is another issue, if the model is stochastic, we can only estimate an approximation of the gradient through the sampling step <span class="math inline">\(s_{t+1} \sim p(s_{t+1}| s_t, a_t)\)</span>. This can make our gradient based optimization in-exact. But I do not know if this is as big of an issue as getting stuck in local minima to motiviate using black box approach such as CEM.</p>
<p>One hybrid approach is <span class="citation" data-cites="huang2021cemgd">Huang et al. (<a href="#ref-huang2021cemgd" role="doc-biblioref">2021</a>)</span>. They formulate a simple method to combine CEM with gradient-based optimization for planning. They initially used CEM for some steps to explore the optimization landscape more “globally” than the first-order gradients and then used gradient descent to converge quickly to some optima.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>We dived into the CEM algorithm for rare-event probability estimation and applied it to black-box function optimization. CEM has been used in model-based RL to optimize the trajectory of actions that lead to the best predicted summed reward under the model.</p>
</section>
<section id="acknowledgments" class="level1">
<h1>Acknowledgments</h1>
<p>This work was partly made possible by funding the Konrad Zuse School of Excellence in Learning and Intelligent Systems (ELIZA) grant.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bhattacharyya21demystifying" class="csl-entry" role="listitem">
Bhattacharyya, Raunak. 2021. <span>“Draft: Demystifying the Cross Entropy Method.”</span> <a href="https://www.robots.ox.ac.uk/~raunakbh/AA228_HelperNote_CrossEntropyMethod.pdf">https://www.robots.ox.ac.uk/~raunakbh/AA228_HelperNote_CrossEntropyMethod.pdf</a>.
</div>
<div id="ref-deboer05tutorial" class="csl-entry" role="listitem">
Boer, Pieter-Tjerk de, Dirk P. Kroese, Shie Mannor, and Reuven Y. Rubinstein. 2005. <span>“A Tutorial on the Cross-Entropy Method.”</span> <em>Annals of Operations Research</em> 134: 19–67. <a href="http://link.springer.com/article/10.1007/s10479-005-5724-z/fulltext.html">http://link.springer.com/article/10.1007/s10479-005-5724-z/fulltext.html</a>.
</div>
<div id="ref-botev13crossentropy" class="csl-entry" role="listitem">
Botev, Z. I., D. P. Kroese, R. Y. Rubinstein, and P. L’Ecuyer. 2013. <span>“The Cross-Entropy Method for Optimization.”</span> <em>Handbook of Statistics - Machine Learning: Theory and Applications</em>, 35–59. <a href="https://people.smp.uq.edu.au/DirkKroese/ps/CEopt.pdf">https://people.smp.uq.edu.au/DirkKroese/ps/CEopt.pdf</a>.
</div>
<div id="ref-ChuaCML18" class="csl-entry" role="listitem">
Chua, Kurtland, Roberto Calandra, Rowan McAllister, and Sergey Levine. 2018. <span>“Deep Reinforcement Learning in a Handful of Trials Using Probabilistic Dynamics Models.”</span> In <em>Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr<span>é</span>al, Canada</em>, edited by Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett, 4759–70. <a href="https://proceedings.neurips.cc/paper/2018/hash/3de568f8597b94bda53149c7d7f5958c-Abstract.html">https://proceedings.neurips.cc/paper/2018/hash/3de568f8597b94bda53149c7d7f5958c-Abstract.html</a>.
</div>
<div id="ref-hafner2018learning" class="csl-entry" role="listitem">
Hafner, Danijar, T. Lillicrap, Ian S. Fischer, Ruben Villegas, David R Ha, Honglak Lee, and James Davidson. 2018. <span>“Learning Latent Dynamics for Planning from Pixels.”</span> <em>International Conference on Machine Learning</em>. <a href="https://arxiv.org/abs/1811.04551v5">https://arxiv.org/abs/1811.04551v5</a>.
</div>
<div id="ref-HansenSW22" class="csl-entry" role="listitem">
Hansen, Nicklas, Hao Su, and Xiaolong Wang. 2022. <span>“Temporal Difference Learning for Model Predictive Control.”</span> In <em>International Conference on Machine Learning, <span>ICML</span> 2022, 17-23 July 2022, Baltimore, Maryland, <span>USA</span></em>, edited by Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvári, Gang Niu, and Sivan Sabato, 162:8387–8406. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v162/hansen22a.html">https://proceedings.mlr.press/v162/hansen22a.html</a>.
</div>
<div id="ref-huang2021cemgd" class="csl-entry" role="listitem">
Huang, Kevin, Sahin Lale, Ugo Rosolia, Yuanyuan Shi, and Anima Anandkumar. 2021. <span>“CEM-GD: Cross-Entropy Method with Gradient Descent Planner for Model-Based Reinforcement Learning.”</span> <em>arXiv Preprint arXiv: 2112.07746</em>.
</div>
<div id="ref-rubinstein04crossentropy" class="csl-entry" role="listitem">
Rubinstein, Reuven Y., and Dirk P. Kroese. 2004. <em>The Cross-Entropy Method</em>. Springer New York. <a href="http://link.springer.com/content/pdf/10.1007/978-1-4757-4321-0.pdf">http://link.springer.com/content/pdf/10.1007/978-1-4757-4321-0.pdf</a>.
</div>
<div id="ref-Sutton1998" class="csl-entry" role="listitem">
Sutton, Richard S., and Andrew G. Barto. 2018. <em>Reinforcement Learning: An Introduction</em>. Second. The MIT Press. <a href="http://incompleteideas.net/book/the-book-2nd.html">http://incompleteideas.net/book/the-book-2nd.html</a>.
</div>
<div id="ref-v2023gradientbased" class="csl-entry" role="listitem">
V, Jyothir S, Siddhartha Jalagam, Yann LeCun, and Vlad Sobal. 2023. <span>“Gradient-Based Planning with World Models.”</span> <em>arXiv Preprint arXiv: 2312.17227</em>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("saiprasanna\.in");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="sai-prasanna/saiprasanna.in" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>