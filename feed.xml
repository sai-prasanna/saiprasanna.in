<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://saiprasanna.in/feed.xml" rel="self" type="application/atom+xml" /><link href="https://saiprasanna.in/" rel="alternate" type="text/html" /><updated>2020-09-14T08:17:09-05:00</updated><id>https://saiprasanna.in/feed.xml</id><title type="html">λf.(λg.f (g g)) (λg.f (g g)) Sai</title><subtitle>Blog on machine learning, NLP, Computer Science, philosophy, economics, animal rights, music, programming languages and endless other things that pique my curiosity.</subtitle><entry><title type="html">Efficient Dynamic Batching of Large Datasets with Infinibatch</title><link href="https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/" rel="alternate" type="text/html" title="Efficient Dynamic Batching of Large Datasets with Infinibatch" /><published>2020-09-13T00:00:00-05:00</published><updated>2020-09-13T00:00:00-05:00</updated><id>https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch</id><content type="html" xml:base="https://saiprasanna.in/posts/efficient-dynamic-batching-of-large-datasets-with-infinibatch/">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-13-efficient-dynamic-batching-of-large-datasets-with-infinibatch.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We will explore how to efficiently batch large datasets with varied sequence length for training using &lt;a href=&quot;https://github.com/microsoft/infinibatch/&quot;&gt;infinibatch&lt;/a&gt;. The focus will be on solving multiple challenges associated with this and making it work with &lt;code&gt;dataloader&lt;/code&gt; abstraction in pytorch library. Though our focus is on pytorch, Infinibatch is a pure python library agnostic of the deep learning library.&lt;/p&gt;
&lt;p&gt;This post was inspired by this thread on twitter.

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Late, but I think exactly what you are asking for: &lt;a href=&quot;https://t.co/gIyBzf5yoE&quot;&gt;https://t.co/gIyBzf5yoE&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;By colleagues from my team in MS.&lt;/p&gt;&amp;mdash; Marcin Junczys-Dowmunt (Marian NMT) (@marian_nmt) &lt;a href=&quot;https://twitter.com/marian_nmt/status/1292850875715604480?ref_src=twsrc%5Etfw&quot;&gt;August 10, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;We will use &lt;a href=&quot;https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/&quot;&gt;wikitext-103&lt;/a&gt; dataset as an example. It&amp;#8217;s a dataset with sentences from wikipedia. It has 103,227,021 word level tokens in it&amp;#8217;s training split. It is used only for illustration, the techniques discussed here are can work for far larger dataset sizes.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#hide_output&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip
&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;unzip wikitext-103-raw-v1.zip
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Challenges-in-efficiently-processing-large-datasets&quot;&gt;Challenges in efficiently processing large datasets&lt;a class=&quot;anchor-link&quot; href=&quot;#Challenges-in-efficiently-processing-large-datasets&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;1.-Loading-and-shuffling-large-datasets&quot;&gt;1. Loading and shuffling large datasets&lt;a class=&quot;anchor-link&quot; href=&quot;#1.-Loading-and-shuffling-large-datasets&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;For large datasets, loading the entire data into memory might not be possible. If we were to sample fully random batches we need to do random access on huge dataset. Depending on the disk latency this might be unfeasible.&lt;/p&gt;
&lt;p&gt;To solve this we can do the following.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shard the data into chunks larger than single instances so that it reduces the disk access.&lt;/li&gt;
&lt;li&gt;Shuffle the chunks and load few of them and shuffle the data loaded from the chunks.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If we shard the pieces into too big chunks we might end up loosing statistical power in our training updates as we are essentially reducing the randomness of our samples used for training. But we can't shard them too small either as that wouldn't solve our disk access problem.&lt;/p&gt;
&lt;p&gt;We need a flexible approach would make it easy to control how much data is to be loaded into memory for shuffling. To address this challenge in isolation, you can refer dataset sharding logic in NVIDIA's &lt;a href=&quot;https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/data/indexed_dataset.py&quot;&gt;MEGATRON language model training code&lt;/a&gt;. But infinibatch solves it in a more generalized manner along with our other challenges.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;2.-Dynamic-Batching&quot;&gt;2. Dynamic Batching&lt;a class=&quot;anchor-link&quot; href=&quot;#2.-Dynamic-Batching&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;NLP datasets generally have samples which are of varied lengths. When we batch the data for training on devices like GPU, we are forced to make them into n-dimensional tensors with fixed dimension. The most common type of input for NLP models is of the shape &lt;strong&gt;Mini-batch size x Sequence length&lt;/strong&gt;. The sequence length is either a fixed value or is the length of longest sequence in that batch. The shorter sequences in the minii-batch are generally padded with a &lt;em&gt;padding token&lt;/em&gt;. These padding tokens are wasteful in terms of computation as they don't do anything useful.&lt;/p&gt;
&lt;p&gt;Some tutorials and examples you would find for pre-processing data would pad batches to a pre-determined sequence length independent of the elements in each batch. This is fully wasteful as many batches would have all the members less than the pre-determined length.&lt;/p&gt;
&lt;p&gt;A better option would be to pad the elements of each batch to the sequence length which is maximum in that batch. This &lt;strong&gt;dynamic padding&lt;/strong&gt; can improve efficiency but it doesn't solve the entire problem. Let's see why with an example.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Tokenization-and-length-distribution&quot;&gt;Tokenization and length distribution&lt;a class=&quot;anchor-link&quot; href=&quot;#Tokenization-and-length-distribution&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Let's implement a typical dynamic padding workflow with pytorch dataloader and a subword level tokenizer. We use BERT-base-cased tokenizer from huggingface's transformers library. This tokenizes words to subwords. The BERT model was pre-trained with maximum subword length of 512. We can theoretically use sequence lengths larger than that but for our purposes we will leave it as such at 512.&lt;/p&gt;
&lt;p&gt;We will use torch's &lt;a href=&quot;https://pytorch.org/docs/stable/data.html&quot;&gt;dataset and dataloader&lt;/a&gt; abstraction for this. It will as both an illustration of real world usage and is convinent as it helps avoid having to entire tokenized dataset in memory. We still have to load the sentences into memory once. This is not a problem for small datasets, but for very large corpuses it's a big problem as mentioned before.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#hide_output&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;pip install git+https://github.com/microsoft/infinibatch.git transformers torch
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;transformers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PreTrainedTokenizerFast&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;seaborn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sns&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;matplotlib&lt;/span&gt; inline
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Wiki103&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PreTrainedTokenizerFast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;wikitext-103-raw/wiki.train.raw&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# We are &lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dp&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;bert-base-cased&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_fast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;wiki_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Wiki103&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sequence_lengths&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wiki_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sequence_lengths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stderr output_text&quot;&gt;
&lt;pre&gt;1164464it [04:51, 4000.17it/s]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;By plotting the truncated &lt;code&gt;Subword sequence length vs Frequency&lt;/code&gt; we see a distribution with a large variance.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;fivethirtyeight&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequence_lengths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;#0504aa&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rwidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Subword Sequence Length&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Frequency&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Frequency&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Sequence Length Distribution&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Dynamic-Padding&quot;&gt;Dynamic Padding&lt;a class=&quot;anchor-link&quot; href=&quot;#Dynamic-Padding&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;From the above graph we can intuit that if we draw random samples from the data to form a mini-batch, we would have few examples which are significantly longer than the rest. This would mean that we would add a lot of padding tokens. This holds even if we clean the very short length instances as noise.&lt;/p&gt;
&lt;p&gt;Let's implement dynamic padding and measure how much. We can use torch's &lt;code&gt;DataLoader&lt;/code&gt; abstraction to do efficient batching with multi-processing. Since our tokenized outputs are of different lengths we have to implement a collate function to pad them dynamically together. We can pass the &lt;code&gt;tokenizer.pad&lt;/code&gt; function implemented in huggingface's tokenizer as the collate function.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Since huggingface has already implemented this, this function is just to illustrate what a collator does.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;pt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wiki_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's assume that we can use maximum a batch size of 32 for max sequence length of 512 for our model in our training hardware without out-of-memory errors. The tokens per batch would be &lt;code&gt;512 * 32 = 16384&lt;/code&gt;. We can now compute how much of it is padding tokens and what is the distribution of the batch's sequence length(which depends on the maximum element in the batch).&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;padding_tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_lengths&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_lengths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total_tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;padding_tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stderr output_text&quot;&gt;
&lt;pre&gt;100%|██████████| 36390/36390 [06:35&amp;lt;00:00, 91.92it/s]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Total Batches    : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Padding Tokens   : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_tokens&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Input Tokens     : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding_tokens&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Total Tokens     : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_tokens&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Padding Tokens % : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_tokens&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;Total Batches    : 36390
Padding Tokens   : 244072396
Input Tokens     : 119699332
Total Tokens     : 363771728
Padding Tokens % : 67.09493267712108
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Surprise, surprise, &lt;strong&gt;67% of our net tokens are padding tokens&lt;/strong&gt;. This would imply that of all the computations that we do, only 33% of is done for useful work. This starkly highlights the problem with static batch lengths even when accounting for dynamic padding.&lt;/p&gt;
&lt;p&gt;Let's also plot the distribution of batch lengths.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;fivethirtyeight&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_lengths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;#0504aa&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rwidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Batch Sequence Length&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Frequency&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Frequency&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Static Batch - Dynamic Padding Length Distribution&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;As batches are randomly sampled, we see a normal distribution as we can should expect by the Central Limit Theorem. The frequency in the final bin is deviant because we have a significant number of sentences which we had truncated, hence batches with them will have the maximum sequence length.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;General-approach-to-dynamic-batching&quot;&gt;General approach to dynamic batching&lt;a class=&quot;anchor-link&quot; href=&quot;#General-approach-to-dynamic-batching&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Instead of drawing samples in random, had we sorted our dataset by length, then we can form batches by packing similar length sequences together into a batch till we reach the maximum number of tokens that we can fit. The maximum number of tokens that can be packed can be derived approximately from our previous memory limit &lt;em&gt;static_batch x max_sequence_length&lt;/em&gt;. This allows us to pack more instances in one batch without much padding because the sequences would be of similar lengths after sorting.&lt;/p&gt;
&lt;p&gt;We can't sort the entire dataset because machine learning training is based on the assumption that our instances are drawn independently from an identical distribution (IID). If we were to sort the entire dataset this breaks the assumption as our samples are no longer drawn independently from each other. If sentence length were a confounding factor then the model might fit on this spurious correlation.&lt;/p&gt;
&lt;p&gt;We have a trade-off here between statistical power derived from randomization of our samples and lesser error in gradient updates derived from larger batch sizes if we batch dynamically.&lt;/p&gt;
&lt;p&gt;Generally, we can have a positive trade off by sampling a window of instances and sorting withing the window and forming batches.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Dataset&lt;/code&gt; we implemented above is a &lt;a href=&quot;https://pytorch.org/docs/stable/data.html#map-style-datasets&quot;&gt;map-style&lt;/a&gt; dataset. It implements length and random access to each individual data sample with index (&lt;code&gt;__getitem__&lt;/code&gt;). The sampling into batches is taken care of a sampler passed to &lt;code&gt;DataLoader&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I don't think there is a clean way to implement a map-style dataset and a collate function such that we get batches with dynamic batch sizes but same number of tokens per batch. This comes from the basic mismatch of number of dynamic batches which you can form keeps changing based on the larger window you sample.&lt;/p&gt;
&lt;p&gt;So it turns out that we have to do all the shuffling, windowing, sorting and batching inside a &lt;a href=&quot;https://pytorch.org/docs/stable/data.html#iterable-style-datasets&quot;&gt;iterable-style&lt;/a&gt; &lt;code&gt;IterableDataset&lt;/code&gt; dataset abstraction. These features are implemented by infinibatch.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;3.-Checkpointing&quot;&gt;3. Checkpointing&lt;a class=&quot;anchor-link&quot; href=&quot;#3.-Checkpointing&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In large datasets, it's typical not to wait for an entire epoch to checkpoint your model to recover from failures. So to be able to recover and continue training in a deterministic manner, such that it converges to same state if the failure hadn't occured, we have to checkpoint the random state that controls the order in which our samples are generated.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Infinibatch-to-the-rescue&quot;&gt;Infinibatch to the rescue&lt;a class=&quot;anchor-link&quot; href=&quot;#Infinibatch-to-the-rescue&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;blockquote&gt;&lt;p&gt;Infinibatch is a library of checkpointable iterators for randomized data loading of massive data sets in deep neural network training.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is aimed at simplify the processing of large datasets. It is a collection of pure python classes that implement &lt;code&gt;__iter__&lt;/code&gt; interface. They can be composed inside one another easily and the final composed iterator can be checkpointed as a single entity.You can checkout it's basic tutorial &lt;a href=&quot;https://github.com/microsoft/infinibatch&quot;&gt;here&lt;/a&gt;. We will use it to address the listed challenges piece by piece and then finally make it work inside &lt;code&gt;IterableDataset&lt;/code&gt; and &lt;code&gt;DataLoader&lt;/code&gt; abstractions. We will also see the tricks needed to make it work distributed data parallel training.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;1.-Loading-and-shuffling-large-datasets&quot;&gt;1. Loading and shuffling large datasets&lt;a class=&quot;anchor-link&quot; href=&quot;#1.-Loading-and-shuffling-large-datasets&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Following the infinibatch tutorial, we divide our dataset into multiple gzip chunks of 10000 sentences each.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;mkdir -p wikitext-103-chunks
&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;split  -a &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt; --lines &lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;  --numeric-suffixes --filter &lt;span class=&quot;s1&quot;&gt;&amp;#39;gzip &amp;gt; wikitext-103-chunks/$FILE.txt.gz&amp;#39;&lt;/span&gt; wikitext-103-raw/wiki.train.raw  train.
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We can now create an iterator using infinibatch with a function that can deserialize a shard. Infinibatch takes care of loading multiple in a shuffled order. We can control the amount of deserialized individual examples from the shards be buffered using &lt;code&gt;buffer_size&lt;/code&gt; parameter. The library returns a python iterable. We can call &lt;code&gt;next(iterable)&lt;/code&gt; or iterate with a &lt;code&gt;for&lt;/code&gt; to get the examples.&lt;/p&gt;
&lt;p&gt;Note: Passing &lt;code&gt;train=True&lt;/code&gt; creates an infinite iterator that cycles after a full run on the dataset. The &lt;code&gt;chunked_dataset_iterator&lt;/code&gt; method returns a composition of iterators, you can refer the source code &lt;a href=&quot;https://github.com/microsoft/infinibatch/blob/master/infinibatch/iterators.py&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gzip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;glob&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;functools&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;infinibatch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;rb&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gzip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decompress&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splitlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sentence_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunked_dataset_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chunk_refs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;wikitext-103-chunks/train.*.txt.gz&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;read_chunk_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;buffer_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1337&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;= = = Oxides and hydroxides = = =
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Tensorize-our-dataset-with-a-map-iterator&quot;&gt;Tensorize our dataset with a map iterator&lt;a class=&quot;anchor-link&quot; href=&quot;#Tensorize-our-dataset-with-a-map-iterator&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We can now compose our tokenizer upon our sentence iterator. Infinibatch has two ways of doing this,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;MapIterator&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ParallelMapIterator&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you use pytorch and need multiprocessing to do costly transformations over your data on the fly, use the &lt;code&gt;ParallelMap&lt;/code&gt; and set the &lt;code&gt;num_processes&lt;/code&gt; with what you would have with &lt;code&gt;num_workers&lt;/code&gt;. And set &lt;code&gt;num_workers=0&lt;/code&gt; in your dataloader.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;features_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParallelMapIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;source_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_processes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_items_per_process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize_fn&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;{&amp;#39;input_ids&amp;#39;: [101, 134, 134, 134, 152, 8745, 4704, 1105, 177, 19694, 8745, 4704, 134, 134, 134, 102], &amp;#39;token_type_ids&amp;#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &amp;#39;attention_mask&amp;#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;2.-Dynamic-Batching&quot;&gt;2. Dynamic Batching&lt;a class=&quot;anchor-link&quot; href=&quot;#2.-Dynamic-Batching&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Now comes the magic of dynamic batching with &lt;code&gt;BucketedReadaheadBatchIterator&lt;/code&gt;. Let's fix the maximum tokens per batch to  &lt;code&gt;32 * 512 = 16384&lt;/code&gt;. This iterator allows you to compute dynamic batch size by iteratively applying a user given function over the current longest example (with length computed by user function) in a sorted &lt;code&gt;read_ahead&lt;/code&gt; window. This window is sorted and batches are formed by using the user provided &lt;code&gt;batch_size&lt;/code&gt; function iteratively.&lt;/p&gt;
&lt;h3 id=&quot;Example&quot;&gt;Example&lt;a class=&quot;anchor-link&quot; href=&quot;#Example&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Say we want 50 tokens per batch. If we set a read ahead window of 6. Assume we fetch six items [a, b, c, d, e, f] in the first read ahead window.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;Sequence id&lt;/th&gt;
&lt;th&gt;Length&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;e&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;f&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;First we sort this window with lengths in decreasing order. The sort order is stable. This preserves the shuffling of equal sized elements from previous iterator. So for our example it would be [a, b, e, c, d, f]&lt;/p&gt;
&lt;p&gt;Now we can Compute the dynamic batch sizes by applying the function &lt;code&gt;batch_size&lt;/code&gt; iteratively till the window is exhausted. Assume our function is &lt;code&gt;lambda longest_instance: 60 // len(longest_instance)&lt;/code&gt;. Then applying it once we get first longest item &lt;code&gt;a&lt;/code&gt;, current batch size will be &lt;code&gt;60 //50 = 1&lt;/code&gt;. The next longest item remaining can be used to calculate the size of the next batch and so on. So we will end up with [a], [b, e], [c, d, f]. Each of them will have 60 tokens.&lt;/p&gt;
&lt;p&gt;You can take a look at the code that does this computation &lt;a href=&quot;https://github.com/microsoft/infinibatch/blob/master/infinibatch/iterators.py#L1080&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokens_per_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batches_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BucketedReadaheadBatchIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;source_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# read_ahead is the number of items to be read from previous iterator,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# these are sorted and over which dynamic batches are formed.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;read_ahead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;c1&quot;&gt;# key determines the length used to sort and choose the longest remaining record.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; 
     &lt;span class=&quot;c1&quot;&gt;# Determines the dynamic batch size&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest_example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens_per_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest_example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dynamic_batch_wo_padding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batches_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Dynamic batch size: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dynamic_batch_wo_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dynamic_batch_wo_padding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batches_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Dynamic batch size: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dynamic_batch_wo_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dynamic_batch_wo_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;Dynamic batch size: 133
Dynamic batch size: 99
[{&amp;#39;input_ids&amp;#39;: [101, 1109, 10437, 10745, 1159, 1108, 1103, 1211, 10543, 7631, 1121, 19475, 119, 23364, 1276, 1103, 10745, 1551, 107, 1119, 27944, 107, 1105, 6315, 1115, 1103, 1591, 1329, 1160, 10437, 9307, 1939, 1104, 1141, 117, 1112, 4836, 10437, 24295, 2624, 1108, 2320, 1107, 1103, 1342, 119, 5512, 5912, 1116, 9279, 1276, 1103, 24295, 2624, 1104, 107, 1544, 170, 5955, 107, 22593, 27643, 27725, 170, 107, 12178, 107, 1113, 1103, 20694, 23676, 119, 26835, 3798, 1276, 1103, 107, 3321, 107, 2971, 1104, 10437, 24295, 2624, 1106, 1129, 1103, 1342, 112, 188, 2026, 3282, 4197, 117, 1112, 1218, 1112, 1103, 1263, 10745, 1551, 1115, 4977, 1122, 119, 8746, 2202, 1115, 21105, 1158, 1551, 1127, 107, 17562, 3345, 107, 1496, 1106, 1103, 12177, 10437, 2469, 1158, 119, 2061, 2202, 1115, 1103, 1342, 1125, 170, 10437, 2469, 9285, 107, 1177, 2213, 107, 1115, 1122, 1108, 1593, 4763, 1106, 2469, 22493, 1219, 11716, 117, 1112, 1103, 16408, 1733, 1766, 2230, 1108, 1579, 170, 1248, 1481, 4315, 10322, 5172, 119, 102], &amp;#39;token_type_ids&amp;#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &amp;#39;attention_mask&amp;#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {&amp;#39;input_ids&amp;#39;: [101, 2651, 4385, 1127, 1211, 1510, 1276, 8910, 15364, 1158, 12354, 2928, 1105, 1103, 15553, 1104, 5400, 15246, 117, 1105, 11561, 1317, 3050, 131, 172, 16717, 3848, 6126, 117, 16358, 2881, 5018, 117, 23639, 11239, 5326, 6126, 117, 1105, 7812, 21212, 119, 140, 16717, 3848, 2116, 1110, 1103, 7764, 1271, 1111, 16307, 172, 16717, 3447, 1105, 1143, 17670, 4199, 131, 18249, 1105, 4600, 5511, 1113, 1499, 1104, 170, 2095, 119, 9800, 2881, 5018, 1127, 4122, 9417, 1116, 1115, 11479, 2894, 1103, 2095, 117, 3525, 15024, 1106, 5211, 1120, 117, 1137, 3968, 4546, 1113, 117, 19450, 1120, 1103, 2259, 1104, 1103, 2095, 1443, 1515, 1106, 8290, 1679, 24755, 1361, 1193, 1166, 1103, 172, 16717, 3848, 6126, 117, 8267, 15952, 2310, 1106, 1231, 6163, 26264, 1183, 1783, 119, 6603, 11239, 5326, 6126, 1127, 2576, 25344, 1113, 1499, 1104, 170, 2095, 1114, 18199, 1115, 2148, 4546, 1106, 1129, 2434, 1113, 1126, 3437, 1120, 1103, 2259, 1104, 1103, 2095, 1107, 170, 1861, 4633, 1106, 16358, 2881, 5018, 119, 102], &amp;#39;token_type_ids&amp;#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &amp;#39;attention_mask&amp;#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now we can collate our examples and see how much  this scheme has saved us. Since a training iterator is infinite, we will recreate our iterators with a non-infinite iterator.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_it_finite&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunked_dataset_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chunk_refs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;wikitext-103-chunks/train.*.txt.gz&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;read_chunk_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;buffer_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1337&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;features_it_finite&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParallelMapIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;source_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_it_finite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_processes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_items_per_process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize_fn&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batches_it_finite&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BucketedReadaheadBatchIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;source_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_it_finite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;read_ahead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Determines the window for the bucket which&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# will be sorted and  converted to batches.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Determines the length used&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# to sort and choose the longest remaining record.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens_per_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Determines the dynamic batch size&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;pt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensors_it_finite&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MapIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batches_it_finite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_batches_dynamic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;total_tokens_dynamic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;padding_tokens_dynamic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_lengths_dynamic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensors_it_finite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total_batches_dynamic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_lengths_dynamic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total_tokens_dynamic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;padding_tokens_dynamic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batched_input_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stderr output_text&quot;&gt;
&lt;pre&gt;7645it [08:45, 14.54it/s]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Total Batches    : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_batches_dynamic&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Seeing the tqdm stats.&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Padding Tokens   : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_tokens_dynamic&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Input Tokens     : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_tokens_dynamic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding_tokens_dynamic&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Total Tokens     : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_tokens_dynamic&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Padding Tokens % : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_tokens_dynamic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_tokens_dynamic&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;Total Batches    : 7645
Padding Tokens   : 3848626
Input Tokens     : 119699332
Total Tokens     : 123547958
Padding Tokens % : 3.1150866937031854
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We have &lt;strong&gt;reduced&lt;/strong&gt; the % of &lt;strong&gt;padding tokens&lt;/strong&gt; per epoch from &lt;strong&gt;67% to just around 3%&lt;/strong&gt;.The total batches needed to process it in the same max tokens per batch limitation hence got reduced nearly five times from 36390 to 7642.&lt;/p&gt;
&lt;p&gt;The processing time is just one minute extra. I guess that might be due to IO, but you could try benchmarking that with more rigour.&lt;/p&gt;
&lt;p&gt;Now, plotting the length distribution for dynamic batches.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;fivethirtyeight&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_lengths_dynamic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;#0504aa&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rwidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Batch Sequence Length&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Frequency&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Frequency&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Dynamic Batch - Dynamic Padding Length Distribution&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We now see that the expected per batch sequence length has reduced from 300 to 200.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;3.-Checkpointing&quot;&gt;3. Checkpointing&lt;a class=&quot;anchor-link&quot; href=&quot;#3.-Checkpointing&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;One cool feature of &lt;code&gt;infinibatch&lt;/code&gt; is that you can checkpoint a particular state in which the composed iterators is at and restore (rewind?) it back to that state. This is very cool considering it works recursively on the composed iterators and even on infinite iterator. Let's recreate our iterators and check this out.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunked_dataset_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chunk_refs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;wikitext-103-chunks/train.*.txt.gz&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;read_chunk_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;buffer_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1337&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;features_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParallelMapIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;source_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_processes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_items_per_process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize_fn&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batches_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BucketedReadaheadBatchIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;source_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;read_ahead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Determines the window for the bucket which&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# will be sorted and  converted to batches.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Determines the length used&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# to sort and choose the longest remaining record.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens_per_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Determines the dynamic batch size&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;pt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MapIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batches_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getstate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Initial State of composed iterators&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Draw 5 batches&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Current State after sampling 5 batches: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getstate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Reset the Iterator&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setstate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Redraw 5 batches&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;redraw_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;State after resampling 5 batches: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getstate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# Check equal&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;all_equal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redraw_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;all_equal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;All items drawn after resetting are equal: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;all_equal&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;Initial State of composed iterators {&amp;#39;source_state&amp;#39;: None, &amp;#39;random_state&amp;#39;: None, &amp;#39;num_served&amp;#39;: 0}
Current State after sampling 5 batches: {&amp;#39;source_state&amp;#39;: {&amp;#39;source_state&amp;#39;: None, &amp;#39;flattened_items_yielded&amp;#39;: 0}, &amp;#39;random_state&amp;#39;: (3, (2147483648, 766982754, 497961170, 3952298588, 2331775348, 1811986599, 3100132149, 3188119873, 3937547222, 215718963, 3315684082, 2978012849, 2428261856, 1298227695, 1704729580, 54668373, 3285201915, 3285178464, 1552935063, 988471319, 3135387943, 1691402966, 2757551880, 416056905, 907387413, 1072924981, 33903495, 2168419592, 2429050353, 831159753, 430343641, 3315943586, 1761671042, 864453023, 334804929, 1627478028, 2596811275, 3468733638, 3994375553, 1457139722, 3139722021, 1334790738, 2656639915, 3535811098, 1464315470, 2397423927, 885719490, 1140895889, 3284299483, 2854516462, 2734973817, 147484763, 792049954, 114360641, 3345458839, 1159898878, 1410498733, 2242989638, 453922141, 1344019764, 413870456, 3089405849, 1494382840, 470157779, 4266372830, 2831181573, 1361928602, 1589253513, 1381373062, 753045124, 987032420, 781978839, 2953638767, 3258570111, 3006718191, 1675218601, 1854232715, 3655829819, 1731242722, 2192104666, 1736665161, 740150002, 1195833394, 1610203160, 159492766, 4041488705, 3128952632, 2867295744, 3272632449, 886824304, 1791482600, 221114776, 3867175393, 4020804062, 1077871826, 1298953503, 996366221, 4149754679, 2483052703, 2615558283, 274318093, 1716359450, 4099129961, 1026774175, 288240973, 1459347562, 2365566296, 3690105224, 3065780221, 2050634722, 2652606621, 3185241207, 3026457375, 3456165734, 1880121515, 3398461093, 1795638629, 2379692076, 608668379, 1261955525, 84456522, 1913485156, 106878280, 757183891, 2913957588, 160418091, 2025664758, 141497907, 1657818026, 3053760160, 672193054, 4157546743, 223046484, 1623470498, 1201972930, 675008814, 684162366, 1738776330, 3025656654, 159760723, 1908867305, 3933381342, 2545706671, 467196949, 1427819885, 842150314, 4032903454, 2140851898, 3269883445, 975813755, 4177392955, 1556690684, 2535611513, 462962732, 67591358, 1729610528, 2025206740, 3153739740, 3255032049, 4186226368, 1070144624, 3107867195, 1621006038, 63742485, 835629717, 3189842019, 3950227584, 3184714559, 841836938, 1685394870, 657939920, 766156242, 1412314179, 1048281639, 4037161120, 2044490307, 1923947830, 3900790422, 907554295, 276417304, 860658646, 3574201134, 3508771399, 2110232300, 1636296241, 1405006077, 1093408401, 3243057343, 1519791182, 1994660136, 3829840937, 2644974199, 957955566, 3487641161, 1646922510, 1907939989, 3836029453, 3429168778, 201307778, 72550089, 2464394982, 1695794191, 3344785682, 996786130, 3589457196, 1241754792, 1291082245, 4224603667, 1194379475, 2693491244, 881186965, 2705535111, 445306946, 440274268, 1980827733, 2482488861, 3205215943, 2119332222, 2928713046, 1418736938, 652581136, 2474070665, 2208621536, 4171251876, 2303664214, 443762656, 2981912989, 2199228311, 2652261633, 3166738494, 3443009210, 3498764432, 424010848, 4065487566, 2262993542, 1756076712, 1477098233, 2742171915, 306185806, 3610666541, 923091830, 1034267993, 2336668648, 1880719718, 676878038, 3788797208, 3763351494, 3985428106, 1101865631, 1130501258, 3672967388, 3432003530, 4124438011, 1660392285, 4025484827, 2108074566, 3815409682, 42955331, 3248965569, 1643835718, 1246665668, 1071162194, 3814069229, 115491158, 985096811, 3311029186, 2990827378, 3101633320, 1648574497, 1470117052, 174145027, 2019894819, 2035501481, 459104123, 3507464599, 2093352659, 3369174406, 618767835, 4009895756, 935587447, 3956987426, 33753995, 307782427, 2473424805, 1440371818, 2382619594, 2138695812, 3164510238, 1318650933, 2910086616, 3886677510, 566832801, 3718063320, 1559818704, 183047272, 1142362855, 26306548, 645536402, 3875596208, 2272778168, 3512733409, 1897046338, 38248886, 2570759766, 1806313150, 860304898, 2433450338, 4124013408, 1216634590, 1275388896, 1169566669, 652504502, 761221427, 1448403764, 3129135949, 2513214949, 1269533687, 2413509541, 1226750363, 2450740925, 4094137910, 945759293, 3636927736, 3178020081, 2509964157, 3878869300, 1848504895, 2018369720, 1579755740, 1023627943, 924838836, 2653160914, 1812804174, 1521323076, 4012390528, 1338763317, 2608655937, 16022784, 1672945066, 2177189646, 2944458483, 2213810972, 1369873847, 1224017670, 130901785, 3595066712, 2259115284, 3316038259, 455873927, 2917250465, 3599550610, 1502173758, 684943436, 3079863840, 3144992244, 942855823, 1771140188, 2118780653, 3411494225, 2711180217, 4239611184, 1371891067, 3398566397, 3105518599, 1310665701, 3345178451, 2959821156, 242241789, 2148966880, 3192740583, 404401893, 3605380577, 1446464038, 3920522056, 2577523013, 1079274576, 286634372, 1752710796, 2351075979, 981312309, 3410516352, 3468455736, 1938779182, 1592494371, 1533303080, 88045436, 438252489, 1220512168, 3487004938, 3724852871, 1073434882, 3728218947, 2977555283, 4105408406, 3553772656, 1462006821, 3917158017, 119003006, 3470530198, 3439192457, 2829375771, 3555715155, 32324691, 588735808, 1459221702, 803072782, 2699519868, 1530797005, 79738580, 671990400, 4289511388, 3207115447, 2584684068, 832698998, 760958416, 1217440464, 2517898131, 2418819938, 3629956222, 3445024962, 206619378, 365007395, 522114139, 1707954431, 540423623, 1786750801, 369253262, 4239016754, 147889201, 1637777773, 236798285, 2806120188, 586972608, 2201782716, 1323327827, 819485723, 406078680, 3407345698, 1537169369, 1821691865, 527271655, 3751827102, 1465426495, 3321682429, 2179672664, 401355478, 1068871880, 24609462, 1403522408, 2311580015, 1532058170, 3877815340, 1768430711, 1619755157, 2832904331, 475102697, 354987331, 3295386430, 2816873951, 1039415736, 363972779, 1499307670, 2895506264, 3746345349, 2678027234, 3251899088, 955392878, 2329157295, 1343358773, 309573887, 2410178377, 2843173466, 361132917, 1755816798, 1319204283, 609284796, 1998842567, 1892325921, 223190385, 1483015769, 2876023365, 3876009312, 3199738344, 491524099, 160383137, 1219178873, 3870310498, 1114580266, 4279604166, 855339774, 1983818547, 2297848784, 4118592947, 4084409863, 2225095054, 4215601993, 946447434, 4205503762, 146088676, 778046685, 1876936928, 3157333726, 2173097090, 3215738813, 4135448234, 1219619643, 1936128689, 2897130162, 3336043946, 3779039524, 4200886837, 1359380925, 3402593091, 3140713935, 50855190, 3122065768, 1501584468, 2512255124, 687125154, 2666013386, 837819715, 3057258172, 3653455791, 2868624990, 322131992, 42534870, 4036564806, 798099710, 3533853670, 190914037, 3726947981, 2601169403, 602059656, 1365668439, 1918780004, 394790500, 277566007, 3891847777, 3365421094, 3139612253, 1380519090, 1183088424, 4203794803, 3049949521, 4214159484, 3446206962, 1875544460, 3207220027, 3288287026, 913535288, 178159620, 1410694581, 4190575040, 880731713, 1427805121, 404869072, 3413191414, 2865934056, 2899472677, 4239222733, 688404529, 3923323887, 933651074, 1199453686, 642723732, 2850614853, 3104368451, 3054041024, 3129913503, 2805843726, 1829781129, 3479062313, 650272704, 4224852052, 4085038685, 2616580676, 1793860711, 585126334, 2995262791, 520446536, 3855655015, 1571815563, 2240778227, 2051010344, 1694977983, 788402852, 1988089041, 2035558649, 1800063056, 1234412692, 2490862867, 417320514, 2415019489, 3374117797, 136034611, 898704236, 1247106941, 3923519397, 3563607190, 2454738671, 3522360389, 2672645476, 146828884, 3985140042, 4233949333, 1184742586, 860278824, 2815489967, 983483427, 3190081845, 3288865305, 3575181235, 1292151129, 4007823805, 4049420597, 3499391972, 1611182906, 1721268432, 2944249577, 2487212557, 789127738, 4027610014, 1057334138, 2902720905, 624), None), &amp;#39;num_served&amp;#39;: 5}
State after resampling 5 batches: {&amp;#39;source_state&amp;#39;: {&amp;#39;source_state&amp;#39;: None, &amp;#39;flattened_items_yielded&amp;#39;: 0}, &amp;#39;random_state&amp;#39;: (3, (2147483648, 766982754, 497961170, 3952298588, 2331775348, 1811986599, 3100132149, 3188119873, 3937547222, 215718963, 3315684082, 2978012849, 2428261856, 1298227695, 1704729580, 54668373, 3285201915, 3285178464, 1552935063, 988471319, 3135387943, 1691402966, 2757551880, 416056905, 907387413, 1072924981, 33903495, 2168419592, 2429050353, 831159753, 430343641, 3315943586, 1761671042, 864453023, 334804929, 1627478028, 2596811275, 3468733638, 3994375553, 1457139722, 3139722021, 1334790738, 2656639915, 3535811098, 1464315470, 2397423927, 885719490, 1140895889, 3284299483, 2854516462, 2734973817, 147484763, 792049954, 114360641, 3345458839, 1159898878, 1410498733, 2242989638, 453922141, 1344019764, 413870456, 3089405849, 1494382840, 470157779, 4266372830, 2831181573, 1361928602, 1589253513, 1381373062, 753045124, 987032420, 781978839, 2953638767, 3258570111, 3006718191, 1675218601, 1854232715, 3655829819, 1731242722, 2192104666, 1736665161, 740150002, 1195833394, 1610203160, 159492766, 4041488705, 3128952632, 2867295744, 3272632449, 886824304, 1791482600, 221114776, 3867175393, 4020804062, 1077871826, 1298953503, 996366221, 4149754679, 2483052703, 2615558283, 274318093, 1716359450, 4099129961, 1026774175, 288240973, 1459347562, 2365566296, 3690105224, 3065780221, 2050634722, 2652606621, 3185241207, 3026457375, 3456165734, 1880121515, 3398461093, 1795638629, 2379692076, 608668379, 1261955525, 84456522, 1913485156, 106878280, 757183891, 2913957588, 160418091, 2025664758, 141497907, 1657818026, 3053760160, 672193054, 4157546743, 223046484, 1623470498, 1201972930, 675008814, 684162366, 1738776330, 3025656654, 159760723, 1908867305, 3933381342, 2545706671, 467196949, 1427819885, 842150314, 4032903454, 2140851898, 3269883445, 975813755, 4177392955, 1556690684, 2535611513, 462962732, 67591358, 1729610528, 2025206740, 3153739740, 3255032049, 4186226368, 1070144624, 3107867195, 1621006038, 63742485, 835629717, 3189842019, 3950227584, 3184714559, 841836938, 1685394870, 657939920, 766156242, 1412314179, 1048281639, 4037161120, 2044490307, 1923947830, 3900790422, 907554295, 276417304, 860658646, 3574201134, 3508771399, 2110232300, 1636296241, 1405006077, 1093408401, 3243057343, 1519791182, 1994660136, 3829840937, 2644974199, 957955566, 3487641161, 1646922510, 1907939989, 3836029453, 3429168778, 201307778, 72550089, 2464394982, 1695794191, 3344785682, 996786130, 3589457196, 1241754792, 1291082245, 4224603667, 1194379475, 2693491244, 881186965, 2705535111, 445306946, 440274268, 1980827733, 2482488861, 3205215943, 2119332222, 2928713046, 1418736938, 652581136, 2474070665, 2208621536, 4171251876, 2303664214, 443762656, 2981912989, 2199228311, 2652261633, 3166738494, 3443009210, 3498764432, 424010848, 4065487566, 2262993542, 1756076712, 1477098233, 2742171915, 306185806, 3610666541, 923091830, 1034267993, 2336668648, 1880719718, 676878038, 3788797208, 3763351494, 3985428106, 1101865631, 1130501258, 3672967388, 3432003530, 4124438011, 1660392285, 4025484827, 2108074566, 3815409682, 42955331, 3248965569, 1643835718, 1246665668, 1071162194, 3814069229, 115491158, 985096811, 3311029186, 2990827378, 3101633320, 1648574497, 1470117052, 174145027, 2019894819, 2035501481, 459104123, 3507464599, 2093352659, 3369174406, 618767835, 4009895756, 935587447, 3956987426, 33753995, 307782427, 2473424805, 1440371818, 2382619594, 2138695812, 3164510238, 1318650933, 2910086616, 3886677510, 566832801, 3718063320, 1559818704, 183047272, 1142362855, 26306548, 645536402, 3875596208, 2272778168, 3512733409, 1897046338, 38248886, 2570759766, 1806313150, 860304898, 2433450338, 4124013408, 1216634590, 1275388896, 1169566669, 652504502, 761221427, 1448403764, 3129135949, 2513214949, 1269533687, 2413509541, 1226750363, 2450740925, 4094137910, 945759293, 3636927736, 3178020081, 2509964157, 3878869300, 1848504895, 2018369720, 1579755740, 1023627943, 924838836, 2653160914, 1812804174, 1521323076, 4012390528, 1338763317, 2608655937, 16022784, 1672945066, 2177189646, 2944458483, 2213810972, 1369873847, 1224017670, 130901785, 3595066712, 2259115284, 3316038259, 455873927, 2917250465, 3599550610, 1502173758, 684943436, 3079863840, 3144992244, 942855823, 1771140188, 2118780653, 3411494225, 2711180217, 4239611184, 1371891067, 3398566397, 3105518599, 1310665701, 3345178451, 2959821156, 242241789, 2148966880, 3192740583, 404401893, 3605380577, 1446464038, 3920522056, 2577523013, 1079274576, 286634372, 1752710796, 2351075979, 981312309, 3410516352, 3468455736, 1938779182, 1592494371, 1533303080, 88045436, 438252489, 1220512168, 3487004938, 3724852871, 1073434882, 3728218947, 2977555283, 4105408406, 3553772656, 1462006821, 3917158017, 119003006, 3470530198, 3439192457, 2829375771, 3555715155, 32324691, 588735808, 1459221702, 803072782, 2699519868, 1530797005, 79738580, 671990400, 4289511388, 3207115447, 2584684068, 832698998, 760958416, 1217440464, 2517898131, 2418819938, 3629956222, 3445024962, 206619378, 365007395, 522114139, 1707954431, 540423623, 1786750801, 369253262, 4239016754, 147889201, 1637777773, 236798285, 2806120188, 586972608, 2201782716, 1323327827, 819485723, 406078680, 3407345698, 1537169369, 1821691865, 527271655, 3751827102, 1465426495, 3321682429, 2179672664, 401355478, 1068871880, 24609462, 1403522408, 2311580015, 1532058170, 3877815340, 1768430711, 1619755157, 2832904331, 475102697, 354987331, 3295386430, 2816873951, 1039415736, 363972779, 1499307670, 2895506264, 3746345349, 2678027234, 3251899088, 955392878, 2329157295, 1343358773, 309573887, 2410178377, 2843173466, 361132917, 1755816798, 1319204283, 609284796, 1998842567, 1892325921, 223190385, 1483015769, 2876023365, 3876009312, 3199738344, 491524099, 160383137, 1219178873, 3870310498, 1114580266, 4279604166, 855339774, 1983818547, 2297848784, 4118592947, 4084409863, 2225095054, 4215601993, 946447434, 4205503762, 146088676, 778046685, 1876936928, 3157333726, 2173097090, 3215738813, 4135448234, 1219619643, 1936128689, 2897130162, 3336043946, 3779039524, 4200886837, 1359380925, 3402593091, 3140713935, 50855190, 3122065768, 1501584468, 2512255124, 687125154, 2666013386, 837819715, 3057258172, 3653455791, 2868624990, 322131992, 42534870, 4036564806, 798099710, 3533853670, 190914037, 3726947981, 2601169403, 602059656, 1365668439, 1918780004, 394790500, 277566007, 3891847777, 3365421094, 3139612253, 1380519090, 1183088424, 4203794803, 3049949521, 4214159484, 3446206962, 1875544460, 3207220027, 3288287026, 913535288, 178159620, 1410694581, 4190575040, 880731713, 1427805121, 404869072, 3413191414, 2865934056, 2899472677, 4239222733, 688404529, 3923323887, 933651074, 1199453686, 642723732, 2850614853, 3104368451, 3054041024, 3129913503, 2805843726, 1829781129, 3479062313, 650272704, 4224852052, 4085038685, 2616580676, 1793860711, 585126334, 2995262791, 520446536, 3855655015, 1571815563, 2240778227, 2051010344, 1694977983, 788402852, 1988089041, 2035558649, 1800063056, 1234412692, 2490862867, 417320514, 2415019489, 3374117797, 136034611, 898704236, 1247106941, 3923519397, 3563607190, 2454738671, 3522360389, 2672645476, 146828884, 3985140042, 4233949333, 1184742586, 860278824, 2815489967, 983483427, 3190081845, 3288865305, 3575181235, 1292151129, 4007823805, 4049420597, 3499391972, 1611182906, 1721268432, 2944249577, 2487212557, 789127738, 4027610014, 1057334138, 2902720905, 624), None), &amp;#39;num_served&amp;#39;: 5}
All items drawn after resetting are equal: True
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Since the &lt;code&gt;state&lt;/code&gt; of the iterator is just a dictionary, you can serialize it along with your model weights and restore them to continue training from exact point where you have checkpointed it.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Making-Infinibatch-work-with-Pytorch-Dataloaders&quot;&gt;Making Infinibatch work with Pytorch Dataloaders&lt;a class=&quot;anchor-link&quot; href=&quot;#Making-Infinibatch-work-with-Pytorch-Dataloaders&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Infinibatch by its very nature can be used only with &lt;code&gt;IterableDataset&lt;/code&gt;. The training iterator with shuffling is infinite, so you must limit the training batches to some &lt;code&gt;n&lt;/code&gt; steps if you want to maintain the notion of &quot;epochs&quot; to start validation. Or you can eschew whole notion of epochs by validating every &lt;code&gt;nth&lt;/code&gt; step or both.
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;The multi processing workers of &lt;code&gt;DataLoader&lt;/code&gt; should be set to zero, with &lt;code&gt;num_workers=0&lt;/code&gt;. Rather use &lt;code&gt;ParallelMapIterator&lt;/code&gt; to parallelize your pre-processing.
&lt;/div&gt;&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;While using &lt;code&gt;IterableDataset&lt;/code&gt; in the typical multi-gpu &lt;code&gt;DistributedDataParallel&lt;/code&gt; (ddp) setup, you should pass &lt;code&gt;instance_rank&lt;/code&gt; and &lt;code&gt;num_instances&lt;/code&gt; to have different slices of data distributed to different training devices.
&lt;/div&gt;&lt;div class=&quot;flash flash-error&quot;&gt;
    &lt;svg class=&quot;octicon octicon-alert&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Warning: &lt;/strong&gt;When using finite iterators with &lt;code&gt;ddp&lt;/code&gt; for validation set, if you split the data using &lt;code&gt;instance_rank&lt;/code&gt; option, the validation can get stuck.This can happen either when your dataset is not divisible by number of &lt;code&gt;ddp&lt;/code&gt; processes or doing dynamic batching caused an uneven number of batches produced for each instance. So it&amp;#8217;s better to do the validation in one GPU setting &lt;code&gt;instance_rank=0&lt;/code&gt;. This is a quick hack, if you find a better option please let me know in the comments.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IterableDataset&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;IterableCheckpointedDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IterableDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Wraps a CheckpointableIterator into a PyTorch IterableDataset, which is &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    recognized by its type by PyTorch&amp;#39;s DataLoader class.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CheckpointableIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;should_reset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_source_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getstate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_should_reset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;should_reset&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__iter__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# this is called in the forked clone&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;worker_info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_worker_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;worker_info&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;worker_info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_workers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# not supported since we can&amp;#39;t get at the checkpoint for each worker&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_should_reset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# For training, since it&amp;#39;s infinite iterator, if we train for &lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# `n` batches with total instances less than dataset size&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# it&amp;#39;s better not to reset the iterator by itself will cycle back&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# with a new shuffle order when all the instances are iterated once.&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_source&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setstate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_source_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_source&lt;/span&gt;



&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_wiki_dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunks_glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PreTrainedTokenizerFast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;is_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;tokens_per_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                           &lt;span class=&quot;n&quot;&gt;num_workers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;buffer_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                           &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1337&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sentence_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunked_dataset_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;chunk_refs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunks_glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;read_chunk_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;buffer_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buffer_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_train&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Shuffle Only on Train&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tokenize_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;features_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParallelMapIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;source_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;num_processes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_workers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;num_items_per_process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize_fn&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batches_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BucketedReadaheadBatchIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;source_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;read_ahead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens_per_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;pt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MapIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batches_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IterableCheckpointedDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensors_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;should_reset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_train&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#Reset only for validation&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                      &lt;span class=&quot;c1&quot;&gt;# Very important to set this to 0.&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;num_workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;c1&quot;&gt;# Important as we have already batched. &lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;c1&quot;&gt;# Since batch has only one member which has all the &lt;/span&gt;
                      &lt;span class=&quot;c1&quot;&gt;#tensors already collated, we just return it.&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
                      &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;bert-base-cased&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_fast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_wiki_dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;wikitext-103-chunks/train.*.txt.gz&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                      &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                      &lt;span class=&quot;n&quot;&gt;is_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;val_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;create_wiki_dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;wikitext-103-chunks/train.*.txt.gz&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                      &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                      &lt;span class=&quot;n&quot;&gt;is_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#print(next(iter(train_loader)))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#print(next(iter(val_loader)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;/div&gt;

&lt;script type=&quot;application/vnd.jupyter.widget-state+json&quot;&gt;
{&quot;4ac9de7d40914f9ca3ac2e32b1c83300&quot;: {&quot;model_module&quot;: &quot;@jupyter-widgets/controls&quot;, &quot;model_name&quot;: &quot;HBoxModel&quot;, &quot;state&quot;: {&quot;_view_name&quot;: &quot;HBoxView&quot;, &quot;_dom_classes&quot;: [], &quot;_model_name&quot;: &quot;HBoxModel&quot;, &quot;_view_module&quot;: &quot;@jupyter-widgets/controls&quot;, &quot;_model_module_version&quot;: &quot;1.5.0&quot;, &quot;_view_count&quot;: null, &quot;_view_module_version&quot;: &quot;1.5.0&quot;, &quot;box_style&quot;: &quot;&quot;, &quot;layout&quot;: &quot;IPY_MODEL_beeaea6b1bfd4d00aa6503086fc58b5c&quot;, &quot;_model_module&quot;: &quot;@jupyter-widgets/controls&quot;, &quot;children&quot;: [&quot;IPY_MODEL_2fbceb9ebded411293cddc95f9ecba35&quot;, &quot;IPY_MODEL_4241770e5d5e4cd2b46ef61e553af9cf&quot;]}}, &quot;dcdb7dc95f0846a7a4c1e2fc9c7bd7ea&quot;: {&quot;model_module&quot;: &quot;@jupyter-widgets/controls&quot;, &quot;model_name&quot;: &quot;HBoxModel&quot;, &quot;state&quot;: {&quot;_view_name&quot;: &quot;HBoxView&quot;, &quot;_dom_classes&quot;: [], &quot;_model_name&quot;: &quot;HBoxModel&quot;, &quot;_view_module&quot;: &quot;@jupyter-widgets/controls&quot;, &quot;_model_module_version&quot;: &quot;1.5.0&quot;, &quot;_view_count&quot;: null, &quot;_view_module_version&quot;: &quot;1.5.0&quot;, &quot;box_style&quot;: &quot;&quot;, &quot;layout&quot;: &quot;IPY_MODEL_8c2b21fcc8324b719144b1cb0bfd0233&quot;, &quot;_model_module&quot;: &quot;@jupyter-widgets/controls&quot;, &quot;children&quot;: [&quot;IPY_MODEL_84848cf9d52541e9866a48172ee108dd&quot;, &quot;IPY_MODEL_d043b16a119b48a88757d48f87ab4a2f&quot;]}}}
&lt;/script&gt;</content><author><name></name></author><category term="deep learning" /><summary type="html"></summary></entry><entry><title type="html">Roam Research - Software for building a Second Brain</title><link href="https://saiprasanna.in/posts/roam-research-software-for-building-a-second-brain/" rel="alternate" type="text/html" title="Roam Research - Software for building a Second Brain" /><published>2020-03-25T00:00:00-05:00</published><updated>2020-03-25T00:00:00-05:00</updated><id>https://saiprasanna.in/posts/roam-research--software-for-building-a-second-brain</id><content type="html" xml:base="https://saiprasanna.in/posts/roam-research-software-for-building-a-second-brain/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://roamresearch.com/assets/images/Roam-Group-min.png&quot; alt=&quot;&quot; /&gt;
&lt;a href=&quot;roamresearch.com&quot;&gt;Roam Research&lt;/a&gt; is a revolutionary note-taking/knowledge management software. It is designed with the idea that data structure for a second brain should be associative (graph) rather than a rigid hierarchy.
It is meant for everyone who needs to manage their knowledge effectively. Their founder aims for the product to become more or less excel for knowledge management.
Professor Balaji Srinivas introduced it to me. I have been using this for about a month and fell in love with its features. 
Canadian philosopher who predicted the web tells that “Medium is the message”. The properties of a medium in which communication occurs can impact society a lot. I believe that roam is one such tool that shifts the medium of note-taking in a groundbreaking manner.
The features of Roam allow you to arrange for the serendipity of ideas, unexpected connections with your past, present and future selves.
It is built on simple building blocks that come together (emergent property) to make the whole greater than the sum of its parts. Each building block of Roam might look simple if looked separately, but together they become very powerful.
Note: It is still in beta with a pricing yet to be announced. But if you try it I think you will share this sentiment. &lt;img src=&quot;https://scaledynamix.com/wp-content/uploads/2018/08/takemymoney.jpg&quot; alt=&quot;&quot; /&gt;
Here is the &lt;a href=&quot;https://roamresearch.com/#/v8/help/page/Vu1MmjinS&quot;&gt;Roam white paper&lt;/a&gt; written by founders on a Public roam database about why they think Roam is revolutionary.&lt;/p&gt;

&lt;h1 id=&quot;pain-points-of-most-knowledge-management-software&quot;&gt;Pain points of most knowledge-management software&lt;/h1&gt;

&lt;p&gt;I have used popular note-taking software like evernote, One-note, Zoho notebook etc. There was always huge friction with these tools. Getting them to work for Note taking, journaling, and project management was such a pain.
The only tool that came close was org-mode in Emacs. I used it for the past one year. But even it had a lot of friction due to the reasons I will expand upon below. And emacs is most definitely not for popular use, it is only for the chosen few who are blessed enough to reject the cult of mouse.&lt;/p&gt;

&lt;h2 id=&quot;failure-of-files-inside-folders-way-of-organization&quot;&gt;Failure of Files inside Folders way of organization.&lt;/h2&gt;

&lt;p&gt;Most note-taking software or even physical note-taking follow a file-folder system or a single hierarchy of bullets inside bullets (Outlining tools) for organizing notes. I will refer to this as “files inside folder” model going forward now.
This system creates nested hierarchy of categories, sub-categories and so on. Inside which your notes are put.&lt;/p&gt;

&lt;h3 id=&quot;why-this-approach-fails&quot;&gt;&lt;strong&gt;Why this approach fails?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;You might have started taking notes/journaling etc for a few days and abandon it after some time. The following are the main reasons I think this happens.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Friction caused by a static hierarchy of the folder system&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Every time you want to write a note you have to decide where to put it in the hierarchy. You have to ask yourselves which notebook/folder/file should I write this, for it to be useful?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Poor Return in investment for good note-taking&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;You painstakingly take notes or journal your exercise regime or note down something. But it never surfaces automatically when you write something related.
Most notes are passive and useless unless you look for them.
Most notes are hidden uselessly in the hierarchy where you put it in.&lt;/p&gt;

&lt;h3 id=&quot;practical-scenario-where-folder-model-fails&quot;&gt;Practical Scenario where folder model fails&lt;/h3&gt;

&lt;p&gt;Say you had a discussion with your friend about note-taking while sipping a coffee in a cafe.
You talk about some personal stuff which say you want to put in your journal.
S/he brings about about a new book which you find interesting and want to read.
Also, you really like the coffee in the cafe and want to note it down in your list of the favourite coffee shops.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Now how do you take notes in this case?&lt;/strong&gt;
In a rigid hierarchy, for this note to be useful you have to file it under multiple places
“To read books”, “Daily Journal”, “Meets”, “Friend’s name”
But that is highly impractical because of the effort/redundancy involved. You would have to copy paste same information in multiple places or  manually create links in multiple pages. And if those pages don’t exist you would have to create them.&lt;/p&gt;

&lt;h2 id=&quot;simple-tags-dont-solve-this-problem&quot;&gt;Simple Tags don’t solve this problem&lt;/h2&gt;
&lt;p&gt;Most note-taking software provide tagging to solve this problem.
But this creates friction of adding tags to everything you write.
And more importantly the tags are flat. i.e. They have no hierarchy between them.
Tags solve searching for notes, but not disovery.  This makes it problematic if you want to discover notes when you stumble through a specific context automatically.&lt;/p&gt;

&lt;h2 id=&quot;we-think-in-a-associative-graphs-manner-not-as-a-rigid-hierarchy-trees&quot;&gt;We think in a associative (Graphs) manner not as a rigid hierarchy (Trees)&lt;/h2&gt;
&lt;p&gt;Every thought/idea in our brain has a bunch of associations. 
Associations like people who introduced us to the idea, what we want to do with it, associations with books we read about it, tasks we completed based on it, tasks we want to do, date in which we did it etc.
So this forms a “graph” (in computer science) where every idea is a node and is linked to many other ideas.
When you think of an idea naturally you get reminded of the stuff it is associated with.
But the problem is we forget stuff, which is the reason why we are doing note-taking in the first place. 
&lt;strong&gt;What if  a note-taking software allows you to mirror how the brain works?&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;building-blocks-of-roam-that-differentiate-it&quot;&gt;Building blocks of Roam that differentiate it&lt;/h1&gt;
&lt;p&gt;These are the fundamental set of features that make Roam what it is. Since showing is better than telling, I am including 1-minute videos of how each fundamental building blocks of Roam work.&lt;/p&gt;

&lt;h2 id=&quot;basic-layout&quot;&gt;Basic Layout&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/3SwQ4usbCX4&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;Roam’s page layout is like any other “outlining” tool. ie It has bullets which can be nested within each other infinitely and the bullets can be collapsed.
There is no folder system. All notes are be seen from “All Pages” view in left side-bar, but it is rarely needed because of way roam’s navigation is organized. 
Roam’s home page is the Daily notes page where you can see pages titled by dates. This is the basic dumping ground for all your quick note-taking and journaling, daily tasks, habit tracking for the day.&lt;/p&gt;

&lt;h2 id=&quot;friction-free-link-creation&quot;&gt;Friction Free Link Creation&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/lHkMq3aqDtw&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;Basic way roam allows linking between pages is typing the note title inside two square brackets “[[]]” which includes autocomplete/search to all notes page titles.
One Important thing here is if the note page doesn’t exist a new page gets create. This would seem weird when coming from other applications. But it serves a big purpose you will see next.&lt;/p&gt;

&lt;h2 id=&quot;bi-directional-linking&quot;&gt;Bi-directional Linking&lt;/h2&gt;
&lt;iframe width=&quot;854&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/v9s3pusI1JQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;This is the key feature of Roam. When a page is linked to, when you visit the page you can see all the places where it has been referred.&lt;/p&gt;

&lt;p&gt;Say you write “I was reading this cool article on [[Deep Learning]]”,
The Deep Learning page will have a back link to all the places it has been mentioned.
So every page becomes akin to a tag, but associations between them form a dynamic/organic hierarchy.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“Every page is a tag, and every tag is a page” - &lt;a href=&quot;https://www.nateliason.com/blog/roam&quot;&gt;Nat Elison’s blog on Roam&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;un-linked-references&quot;&gt;Un-linked References&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/nROryUttSr0&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;If you have already mentioned a topic in lots of notes, but didn’t create a page for it and link them. Roam has got your back with its super cool un-linked references. When you create a new page, you can easily bulk link every other page that has mentions of the current page.&lt;/p&gt;

&lt;h2 id=&quot;ability-to-refer-or-embed-any-blockbullet-anywhere&quot;&gt;Ability to refer or embed any block/bullet anywhere&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/ZFbrdv-70ME&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;You can link to or embed any block written anywhere in roam notes.
Roam prompts a search/autocomplete to any block you have written in all the pages. How awesome is that?
To create a block reference two open Parentheses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;((&lt;/code&gt; Or type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/Block Reference.&lt;/code&gt;
You can also embed the entire block using Block embed. 
Type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/Block Embed&lt;/code&gt;
When embedding or linking to a block you can see the  places it has been used by clicking on the number which appears at top right side of a block.&lt;/p&gt;

&lt;h2 id=&quot;all--back-links-and-block-embeds-are-editable&quot;&gt;All  back-links and block embeds are editable&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/qg9uS6LlCf0&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;The coolest part of roam is all blocks (bullets) displayed by back-links and block embeds are editable. 
You can edit embedded notes and back-links with no duplication.
So you easily remix (refactor?) notes by creating a new note with just embeds from multiple other notes in other places.&lt;/p&gt;

&lt;h2 id=&quot;navigating-with-full-text-search&quot;&gt;Navigating with Full-text Search&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/Al69VbgKVw0&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;Roam provides full text search of all the blocks and titles.
You can create a brand new page which is not linked to any other page directly from search.&lt;/p&gt;

&lt;h2 id=&quot;graph-view&quot;&gt;Graph View&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/OXqN4u7lKac&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;Since every note is basically a node in graph, roam easily allows a bird’s eye of your entire graph in the “Graph Overview” page.
A more helpful feature is ability to view what nodes current page has connections to and navigate visually.&lt;/p&gt;

&lt;h2 id=&quot;side-bar&quot;&gt;Side Bar&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/7dASSNABtIo&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;Roam sidebar allows you to open multiple notes at a time.
This is really useful when you want to aggregate knowledge across notes.&lt;/p&gt;

&lt;h2 id=&quot;filters-on-bi-directional-links&quot;&gt;Filters on Bi-directional Links&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/BnwWdTnXlxU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;When you have too many bi-directional links in a page, you can filter them to include or exclude other links.&lt;/p&gt;

&lt;h1 id=&quot;building-a-second-brain-with-roam&quot;&gt;Building a second brain with Roam&lt;/h1&gt;
&lt;p&gt;In this section, I will describe how Roam can be used for multiple use-cases at once thereby building your second brain.&lt;/p&gt;

&lt;h2 id=&quot;note-taking&quot;&gt;Note taking&lt;/h2&gt;
&lt;p&gt;If you read a lot and want to retain the knowledge. Reading stuff and writing it in your own words will be a good way to test gaps in understanding.
This &lt;a href=&quot;https://www.nateliason.com/blog/smart-notes&quot;&gt;article&lt;/a&gt; a effective way to take smart notes using roam.
I found &lt;a href=&quot;https://fortelabs.co/blog/how-to-take-smart-notes&quot;&gt;this summary&lt;/a&gt; of a book called “[[How to Take Smart Notes - Book]] really helpful.&lt;/p&gt;

&lt;h2 id=&quot;journal&quot;&gt;Journal&lt;/h2&gt;
&lt;p&gt;Writing a journal is a bread and (peanut) butter of roam.
Daily notes encourages you to write daily at anytime.
It feels really encouraging to journal in roam as unlike other apps because of the back-links.
Anything recorded will automatically get associated with all the topics.&lt;/p&gt;

&lt;h2 id=&quot;task-management&quot;&gt;Task management&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/asQ4RSjjCu4&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;Roam supports basic todos, you can use links to link tasks to the date it has to be done using date-picker. 
The key advantage here is your project management tasks can easily be linked to the meeting notes, research notes, and journal etc.
Getting things done (GTD) is a popular method to manage tasks.
It is very easy to implement that in roam with the aid of back-links.
You can read how to adopt GTD in roam &lt;a href=&quot;https://oliverschmid.space/posts/gtd-in-roam/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;bookmarks&quot;&gt;Bookmarks&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/7b2AVCZOMnw&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;You can easily put links into roam with creating tags/links. 
Tags are same as “[[]]” links, just that the font is greyed out.&lt;/p&gt;

&lt;h2 id=&quot;personal-crm&quot;&gt;Personal CRM&lt;/h2&gt;
&lt;p&gt;Personal crm is for maintaining a list of people, their contact, birthdays, how you met them or anything else you want to maintain about them.
In roam you can easily create pages for people, and refer it in your daily notes. So when you go to the person’s page, you can see all the places h/she has been mentioned.&lt;/p&gt;

&lt;h2 id=&quot;content-creation&quot;&gt;Content Creation&lt;/h2&gt;
&lt;p&gt;For writing new content, you can easily remix stuff which you wrote across different pages in a new page.
So you will never have the feeling of starting at a blank page when you have done your research and taken notes on it.&lt;/p&gt;

&lt;h1 id=&quot;other-useful-features&quot;&gt;Other useful features&lt;/h1&gt;

&lt;h2 id=&quot;query&quot;&gt;Query&lt;/h2&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/AlmhG6nTl9M&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;This is an advanced feature, where you can query on your graph to show blocks that satisfy boolean conditions. Like show me all the blocks with todos with high priority etc.&lt;/p&gt;

&lt;h2 id=&quot;shortcuts&quot;&gt;Shortcuts&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://nimbus-screenshots.s3.amazonaws.com/s/823247391734eda9aec6dd9353f33a2b.png&quot; alt=&quot;&quot; /&gt;
This is useful to keep the most important projects&lt;/p&gt;

&lt;h2 id=&quot;tables-diagrams-kanban-boards&quot;&gt;Tables, Diagrams, Kanban boards&lt;/h2&gt;
&lt;p&gt;Tables can be created using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/Table&lt;/code&gt; command followed by nested bullets.
&lt;img src=&quot;https://nimbus-screenshots.s3.amazonaws.com/s/e3e5189d83b0ab1d85e5debe2d0d7207.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;embedding-media&quot;&gt;Embedding Media&lt;/h2&gt;
&lt;p&gt;Embed tweet by just pasting a twitter link. 
Type backslash followed by image markdown  to insert a markdown for image embed. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/Image Markdown&lt;/code&gt;
Alternatively images can be uploaded by pasting directly or with backslash command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/Upload a image&lt;/code&gt; backslash command for it to be uploaded and the markdown inserted automatically.
For youtube videos, use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/Embed Youtube Video&lt;/code&gt; command.
Interesting point here is all the embeds are markdown or markdown like plain text syntax. No proprietary garbage.&lt;/p&gt;

&lt;h2 id=&quot;publishing-your-roam-notes&quot;&gt;Publishing your Roam Notes&lt;/h2&gt;
&lt;p&gt;You can share a note by its URL to public as read-only or even allow public edits.&lt;/p&gt;

&lt;h2 id=&quot;sharing-your-second-brain-to-form-a-hive-mind&quot;&gt;Sharing your second Brain to form a Hive mind&lt;/h2&gt;
&lt;p&gt;Currently you can share the entire roam database and collabrate with peers.
More fine-grained controls of sharing parts of the graph are in the works.&lt;/p&gt;

&lt;h2 id=&quot;works-offline-progressive-web-app&quot;&gt;Works offline (Progressive Web App)&lt;/h2&gt;
&lt;p&gt;The mobile apps are coming shortly, but the web app is designed so well that it can function offline.&lt;/p&gt;

&lt;h2 id=&quot;exports-to-plain-text&quot;&gt;Exports to plain text&lt;/h2&gt;
&lt;p&gt;This is important for anyone who cares about not getting locked out of your data.
Since the product is in development better to take regular backups if you plan to use it.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;The concept of bi-directional editable media in Roam can 
be transposed to many other products with lots of unstructured text 
trapped in a rigid hierarchy.
Roam is a well-designed innovative product that leapfrogs over existing products. This I think is because of unorthodox thinking of its founders (&lt;a href=&quot;https://twitter.com/Conaw&quot;&gt;Conor White-Sulivan&lt;/a&gt; and Joshua Brown) to build useful tools for augmenting our brain.
Turing award winner and Computer Science legend Alan Kay once said: “The best way to predict the future is to invent it.”. He also thought that there is a lot more that can be done to make computers truly augmenting the intellect. I think these founders are trying to fulfil that dream.
Roam seems like an application that can give compounding returns of value for the knowledge put in it. This is totally refreshing in an age where 
apps suck your attention.
Finally, I am more into engineering than content writing for productivity software. This software was so good that I couldn’t help writing this article to share it with others.&lt;/p&gt;</content><author><name></name></author><category term="Productivity" /><category term="Note Taking" /><summary type="html">Introduction</summary></entry><entry><title type="html">Neural Module Networks</title><link href="https://saiprasanna.in/posts/neural-module-networks/" rel="alternate" type="text/html" title="Neural Module Networks" /><published>2020-03-02T00:00:00-06:00</published><updated>2020-03-02T00:00:00-06:00</updated><id>https://saiprasanna.in/posts/neural-module-networks</id><content type="html" xml:base="https://saiprasanna.in/posts/neural-module-networks/">&lt;p&gt;Research Paper -  &lt;a href=&quot;https://arxiv.org/abs/1511.02799&quot;&gt;https://arxiv.org/abs/1511.02799&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Authors - Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein&lt;/p&gt;
&lt;h2 id=&quot;key-idea&quot;&gt;Key Idea&lt;/h2&gt;
&lt;p&gt;Parse questions of visual QA into a description of compositions of functions. These functions are neural networks called Neural Modules. Execute the neural networks and reweigh the resulting label using question representation.
&lt;img src=&quot;https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fartificial_sai%2FImqekKqTqJ?alt=media&amp;amp;token=f46ba375-0d38-4c81-b40f-f691c4099a74&quot; alt=&quot;Architecture diagram&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;task---visual-question-answering&quot;&gt;Task - Visual Question Answering&lt;/h2&gt;
&lt;p&gt;Given a question like “What color is the coffee mug?” and an image we want to predict the answer.
&lt;img src=&quot;https://visualqa.org/static/img/vqa_examples.jpg&quot; alt=&quot;4  visual qa examples. One example: Two images having a man and women. One with man wearing glasses and another image with woman wearing glasses.Question, &amp;quot;Who is wearing glasses?&amp;quot; and respective answer below the image&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;prior-approaches&quot;&gt;Prior approaches&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;End to End neural networks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Use a CNN to vectorize the image and RNN to vectorize the question and use a feed forward network to classify the answer.
This is a black box trying to answer in one shot.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Semantic Parsing approach&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Parse the question into logical expressions, image into logical representation of the world and use logic based reasoning to solve the problem.
This is more compositional.&lt;/p&gt;
&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Combine the representational capacity of neural nets and compositionality of symbolic approach.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Rather than thinking of question answering as a problem of learning a single function to map from questions and contexts to answers, it’s perhaps useful
to think of it as a highly-multitask learning setting, where each problem instance is associated with a novel task, and the  identity  of  that  task  is  expressed  only  noisily  in  language.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Simple example - “Is this a truck?” - Needs single task to be performed, namely truck or not classification.&lt;/p&gt;

&lt;p&gt;Compositional example - “What is the object to the left of the tea pot?” - Needs one to find the teapot, detect object to its left, then classify the object.&lt;/p&gt;
&lt;h2 id=&quot;architecture&quot;&gt;Architecture&lt;/h2&gt;
&lt;h3 id=&quot;neural-modules&quot;&gt;Neural Modules&lt;/h3&gt;
&lt;p&gt;Identify set of modules that can be composed to solve all/most tasks.
Modules can be thought of as a function parametrized by a neural network, with a type signature.
Data Types - Image, Unnormalized attention map, labels
&lt;img src=&quot;https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fartificial_sai%2FCukmmNqjRE?alt=media&amp;amp;token=f63a5c71-e85f-4936-a3db-d6c2e210da46&quot; alt=&quot;Attention Module&quot; /&gt;
&lt;img src=&quot;https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fartificial_sai%2Fn0rzgVl42h?alt=media&amp;amp;token=74d06d94-d7a2-4911-9f10-dac8a01a7970&quot; alt=&quot;Classification Module&quot; /&gt;
&lt;img src=&quot;https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fartificial_sai%2FnOFbj1IDtR?alt=media&amp;amp;token=044075ba-b992-4618-905e-e4a5e69fe4a4&quot; alt=&quot;Reattention module&quot; /&gt;
&lt;img src=&quot;https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fartificial_sai%2FGhc8_NHxUn?alt=media&amp;amp;token=b06a6670-84f7-4c65-89da-9475008fe5c3&quot; alt=&quot;Combination module&quot; /&gt;
&lt;img src=&quot;https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fartificial_sai%2FQt95yqX3Cf?alt=media&amp;amp;token=b2628c2d-ca01-48fd-b596-c4e01e491823&quot; alt=&quot;Measurement Module&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;strings---modules&quot;&gt;Strings -&amp;gt; Modules&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Parsing&lt;/strong&gt;
Use few rules on dependency parse of the question to convert it into a structured query.
e.g. “Is there a circle next to a square?” -&amp;gt;  is(circle, next-to(square))
&lt;strong&gt;Layout&lt;/strong&gt;
“All leaves become attend modules, all internal nodes become
re-attend or combine modules dependent on their arity, and root nodes become measure modules for yes/no questions and classify modules for all other question types.”
The queries could come from anywhere not just natural language question. As long as they can be converted to a layout in the end.&lt;/p&gt;
&lt;h3 id=&quot;answering&quot;&gt;Answering&lt;/h3&gt;
&lt;p&gt;An RNN is used to process the question and predict a label directly without looking into the image.
This is combined with the final label from the root node of the Neural Modules using geometric mean to get the final result.
This is done for 2 reasons
&lt;strong&gt;Syntactic Regularity/Prior&lt;/strong&gt;
When converting to structured query, certain syntactic elements are lost.
For e.g. What is in the sky? and What are in the sky?  both result in what(fly).
But answer varies from kite to kites.
&lt;strong&gt;Semantic Regularity/Prior&lt;/strong&gt;
Some answers are unreasonable just by inspecting the question.
For example, What colour is the bear? eliminates all non-colour answers.&lt;/p&gt;
&lt;h2 id=&quot;benchmarks&quot;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;They try this in vqa dataset - https://visualqa.org/ a huge dataset with natural images and questions with answers.
&lt;img src=&quot;https://d3i71xaburhd42.cloudfront.net/21c99706bb26e9012bfb4d8d48009a3d45af59b2/7-Table3-1.png&quot; alt=&quot;Benchmarks table for VQA&quot; /&gt;
Since VQA doesn’t have many deep compositional questions, they use shapes a synthetically generated dataset.
&lt;img src=&quot;https://d3i71xaburhd42.cloudfront.net/21c99706bb26e9012bfb4d8d48009a3d45af59b2/7-Table2-1.png&quot; alt=&quot;Synthetic Shapes dataset&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;
&lt;p&gt;What colour is his tie? &lt;img src=&quot;https://d3i71xaburhd42.cloudfront.net/21c99706bb26e9012bfb4d8d48009a3d45af59b2/5-Figure2-1.png&quot; alt=&quot;Statue of a man with yellow tie, question parsed to modules 1. find tie  2. describe colour &quot; /&gt;
&lt;img src=&quot;https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fartificial_sai%2FacB53oMkSP?alt=media&amp;amp;token=a75a6545-1c5f-44f6-9ed5-3f17d26061b0&quot; alt=&quot;Correct and incorrect predictions&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="Semantic Parsing" /><category term="Visual Q/A" /><category term="Symbolic AI" /><category term="CV" /><category term="NLP" /><category term="Research Paper Summary" /><summary type="html">Research Paper - https://arxiv.org/abs/1511.02799</summary></entry><entry><title type="html">ACL 2019 Conference Summary</title><link href="https://saiprasanna.in/posts/ACL-2019-Conference-Summary/" rel="alternate" type="text/html" title="ACL 2019 Conference Summary" /><published>2020-02-10T00:00:00-06:00</published><updated>2020-02-10T00:00:00-06:00</updated><id>https://saiprasanna.in/posts/ACL-2019-Conference-Summary</id><content type="html" xml:base="https://saiprasanna.in/posts/ACL-2019-Conference-Summary/">&lt;p&gt;My colleague Ananda and I attended &lt;a href=&quot;https://www.aclweb.org/portal/&quot;&gt;ACL 2019 conference&lt;/a&gt; at the enchanting city of Florence.
All the accepted papers can be accessed &lt;a href=&quot;https://www.aclweb.org/anthology/events/acl-2019/&quot;&gt;here&lt;/a&gt;.
Here’s the summary of interesting trends and also specific research work that caught my eye at the conference. 
A note of thanks to my employer at Zoho for sponsoring us to attend.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I wrote this summary an many months ago and forgot posting it. Better late than never I guess.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;grammatical-error-correction&quot;&gt;Grammatical Error Correction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Among the ACL workshops, Building Educational Applications (BEA) Workshop had a &lt;a href=&quot;https://www.cl.cam.ac.uk/research/nl/bea2019st/&quot;&gt;Grammar Error Correction competition&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The system description papers for this competition were presented as posters in the conference.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Three tracks were present in the competition.
&lt;strong&gt;Restricted track&lt;/strong&gt; - Only organizer provided human labelled parallel (error and corrected sentence pairs) data can be used. (No restriction on synthetic data)
&lt;strong&gt;Unrestricted track&lt;/strong&gt; - Any data including private data can be used.
&lt;strong&gt;Low Resource track&lt;/strong&gt; - No human labelled data can be used.&lt;/li&gt;
  &lt;li&gt;Interestingly, the winning team (Edinburgh + Microsoft)’s &lt;a href=&quot;https://www.aclweb.org/anthology/W19-4427/&quot;&gt;submission&lt;/a&gt; for Track 1 also beat Track 2 without using additional restricted data.&lt;/li&gt;
  &lt;li&gt;Synthetic data generated by corrupting good grammatical sentences from news, books and wikipedia are the techniques used overall by top performing teams.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;multi-lingual-models&quot;&gt;Multi-Lingual Models&lt;/h2&gt;

&lt;p&gt;MultiLingual models is a hot area of research now. Earlier results where using single model to perform tasks on multiple languages has shown promising results.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lots of papers on multi-lingual shared models were presented.&lt;/li&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/P/P19/P19-1301/&quot;&gt;Choosing Transfer Languages for Cross-Lingual Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rise-of-automated-metrics&quot;&gt;Rise of Automated Metrics&lt;/h2&gt;

&lt;p&gt;Until recently, we compare model outputs with human written sentences for translation, summarization etc. 
This can artificially penalize models that generate sentences with equivalent meaning but not same words.
There are couple of papers that train models to score quality of the output. Then use these model scores 
as reward for reinforcement learning. (FYI reinforcement learning is only used for fine tuning, none of 
the seq2seq models can be trained from scratch using it)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/P/P19/P19-1043/&quot;&gt;This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation&lt;/a&gt; 
This paper uses automated score instead of typical NGram match (ROUGE) score for summarization task.&lt;/li&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/P/P19/P19-1427/&quot;&gt;Beyond BLEU:Training Neural Machine Translation with Semantic Similarity&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/P/P19/P19-1264/&quot;&gt;Sentence Mover’s Similarity: Automatic Evaluation for Multi-Sentence Texts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;statistical-evaluation&quot;&gt;Statistical Evaluation&lt;/h2&gt;

&lt;p&gt;If we have two architectures and couple of datasets, how to say empirically one is better than the other?
Few questions are how to compare two models on the same dataset, across multiple datasets, across various hyperparameter configurations.
Problems in applying frequentist tests on the metrics such as accuracy, f1-score etc 
are that assumptions such as Independent and Identically distributed (IID) cannot be made for deep learning datasets.
So we cannot assume that the score the model gets in one dataset is “independent” of the score on another dataset. 
Statistical tests that don’t assume underlying distribution are needed.
Recent statistical methods/tests to do so are being developed and some were presented at the conference.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/P/P19/P19-1266/%20&quot;&gt;Deep Dominance - How to Properly Compare Deep Neural Models&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/P/P19/P19-1405/&quot;&gt;Bayes Test of Precision, Recall, and F1 Measure for Comparison of Two Natural Language Processing Models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bayesian-methods&quot;&gt;Bayesian Methods&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Attended a very detailed tutorial on it. The presenter has summarized the evolution of research in this area and the current papers. Here’s link to the detailed &lt;a href=&quot;https://drive.google.com/file/d/1SgNVpspG-m0O_k-_qAbxg-3HSZg3FOec/view?usp=sharing&quot;&gt;slides&lt;/a&gt; for fellow Bayesians.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;analyzing-neural-nets-and-interpretability&quot;&gt;Analyzing Neural Nets and Interpretability&lt;/h2&gt;

&lt;p&gt;There is an entire sub-fields of research into analyzing and interpreting neural networks.&lt;/p&gt;

&lt;h3 id=&quot;bertology&quot;&gt;BERTology&lt;/h3&gt;

&lt;p&gt;“BERT-ology” papers that explore what linguistic structures do pre-trained models like BERT learn.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/W/W19/W19-4828/&quot;&gt;What Does BERT Look at? An Analysis of BERT’s Attention&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;blackboxnlp-workshop&quot;&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/volumes/W19-48/&quot;&gt;BlackBoxNLP Workshop&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;An entire workshop devoted for analyzing what Neural Networks learn.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/W/W19/W19-4814/&quot;&gt;On the Realization of Compositionality in Neural Networks&lt;/a&gt;
Interesting paper studying what is required for neural models to compose two very trivial functions.&lt;/li&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/W/W19/W19-4826/&quot;&gt;GEval: Tool for Debugging NLP Datasets and Models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;formal-languages-workshop&quot;&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/volumes/W19-39/%20&quot;&gt;Formal Languages Workshop&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;An entire small workshop devoted to finding what Formal Languages (Finite state Automata, etc) neural networks can learn.
e.g. Can we reduce a RNN to Weighted Finite State Machine (which is far more interpretable, amenable to theory etc).
Although this area sounds exciting to me, I was unable to attend it as I was in an another workshop.
Slides from talk of Noah Smith’s talk on &lt;a href=&quot;https://homes.cs.washington.edu/~nasmith/slides/rrnn-dlfl-2019-08-02.pdf&quot;&gt;Rational Recurrences&lt;/a&gt; at this workshop.&lt;/p&gt;

&lt;h3 id=&quot;neuroscience-and-nlp&quot;&gt;Neuroscience and NLP&lt;/h3&gt;

&lt;p&gt;Neuroscience labs have started to use deep learning. An interesting conjunction of research in NLP and neuroscience research in correlating
ANN representations with brain signals was presented.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/P/P19/P19-1507/&quot;&gt;Relating Simple Sentence Representations in Deep Neural Networks and the Brain&lt;/a&gt;
The researchers try to find relationship between deep learning language representations and brain signals.
Paper of interest is where they predict neural brain patterns using pre-trained ANN models like BERT.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;language-emergence-in-multi-agent-systems&quot;&gt;Language Emergence in Multi-Agent systems&lt;/h3&gt;

&lt;p&gt;In this frontier, people try train models to solve some task by communicating symbols. Researchers analyze the properties of 
language used by the agents to solve the task and how it compares with properties of human language.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paper - &lt;a href=&quot;https://www.aclweb.org/anthology/papers/P/P19/P19-1509/&quot;&gt;Word-order Biases in Deep-agent Emergent Communication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conversational-ai&quot;&gt;Conversational AI&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Neural Models for selecting conversation from past history, detecting intent and slot fitting are all increasingly being deployed by companies.&lt;/li&gt;
  &lt;li&gt;PolyAI (a startup at Singapore shipping conversational AI) shared three &lt;a href=&quot;https://twitter.com/poly_ai/status/1154027323810861057/photo/1&quot;&gt;interesting papers&lt;/a&gt;. Their slides are also &lt;a href=&quot;https://www.matthen.com/assets/pdf/Neural%2520Models%2520of%2520Response%2520Selection%2520for%2520Bootstrapping%2520Dialogue%2520Systems.pdf&quot;&gt;interesting&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;On a related note, Baidu has is doing impressive research and engineering on meeting transcription. They have a stack that does speech to text, translating the text as its spoken (a problem that
needed separate research as the text would be incomplete), detecting english phrases being spoken (code switching) and then NLP over the transcribed text.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;translation&quot;&gt;Translation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Lots of new work on adapting translation models for low-resource languages.&lt;/li&gt;
  &lt;li&gt;Unsupervised translation, Multi-lingual translation models are few areas of research.&lt;/li&gt;
  &lt;li&gt;Unbabel a YC funded startup doing translation systems shared lots of interesting and important results.
&lt;a href=&quot;https://www.aclweb.org/anthology/W18-2103&quot;&gt;Slides from their talk&lt;/a&gt;. This company employs a hybrid system where human translators do “post-edits” on machine translations.
And some of their system work in real-time.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;contextual-search-using-neural-representations-at-scale&quot;&gt;Contextual Search using Neural Representations at scale&lt;/h2&gt;

&lt;p&gt;This &lt;a href=&quot;https://arxiv.org/abs/1906.05807&quot;&gt;paper&lt;/a&gt; has demonstrated a system which does dense vector search on entire wikipedia for open domain QA.&lt;/p&gt;

&lt;p&gt;Scaling search on neural vectors to do question answering on entire wikipedia on CPU - &lt;a href=&quot;https://github.com/uwnlp/denspi&quot;&gt;https://github.com/uwnlp/denspi&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Demo - &lt;a href=&quot;http://allgood.cs.washington.edu:15001/&quot;&gt;http://allgood.cs.washington.edu:15001/&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Computer Science" /><category term="Machine Learning" /><category term="Conference" /><category term="ACL" /><summary type="html">My colleague Ananda and I attended ACL 2019 conference at the enchanting city of Florence. All the accepted papers can be accessed here. Here’s the summary of interesting trends and also specific research work that caught my eye at the conference. A note of thanks to my employer at Zoho for sponsoring us to attend.</summary></entry><entry><title type="html">Semantic Legion</title><link href="https://saiprasanna.in/posts/semantic-legion-1/" rel="alternate" type="text/html" title="Semantic Legion" /><published>2019-12-08T00:00:00-06:00</published><updated>2019-12-08T00:00:00-06:00</updated><id>https://saiprasanna.in/posts/semantic-legion-1</id><content type="html" xml:base="https://saiprasanna.in/posts/semantic-legion-1/">&lt;p&gt;I am guilty of spamming people in the degree one of my network with too many links in topics that fancy the Legion of varied interests that haunt me. Following the suggestion of Ananda Seelan, I am consolidating my link blasts into a considated blog post format, thus begins the “Semantic Legion”. This exercise might help organize the “Legion” in my head and maybe lead to more focused blog posts.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“My name is Legion, for we are many.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h2&gt;

&lt;h3 id=&quot;the-lottery-ticket-hypothesis-finding-sparse-trainable-neural-networks&quot;&gt;&lt;a href=&quot;https://arxiv.org/abs/1803.03635&quot;&gt;The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The lottery ticket hypothesis suggests that big Deep Neural Nets train better than smaller nets because they get lucky. Essentially like someone who has purchased more number of lottery tickets.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Prune a large neural network by zeroing the bottom x% of weights by magnitude. This can be done one shot or iteratively while training.&lt;/li&gt;
  &lt;li&gt;Reset the obtained subnetwork weights to the exact weights you randomly intialized before training the large neural network.&lt;/li&gt;
  &lt;li&gt;The pruned subnetwork converges to similar test error rate as the full network or even better in the same number of epochs.&lt;/li&gt;
  &lt;li&gt;The authors notice that if you were try some other initialization for the subnetwork or even sample from similar distribution it doesn’t work.
Hence they hypothesise that the larger network essentially got lucky.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Though the subnetwork is smaller, computations will need sparse matrix multiplication optimizations to be faster.&lt;/p&gt;

&lt;h3 id=&quot;understanding-the-generalization-of-lottery-tickets-in-neural-networks&quot;&gt;&lt;a href=&quot;https://ai.facebook.com/blog/understanding-the-generalization-of-lottery-tickets-in-neural-networks&quot;&gt;Understanding the generalization of ‘lottery tickets’ in neural networks&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Facebook extends the study and checks it for various architectures, tasks and optimizer setting. The lottery ticket phenomena seems to occur in most places. The lottery ticket subnetworks generalize across datasets. This blog post is a summary of multiple papers by Facebook AI group in analyzing this phenomena.&lt;/p&gt;

&lt;h3 id=&quot;new-theory-cracks-open-the-black-box-of-deep-learning&quot;&gt;&lt;a href=&quot;https://www.quantamagazine.org/new-theory-cracks-open-the-black-box-of-deep-learning-20170921/&quot;&gt;New Theory Cracks Open the Black Box of Deep Learning&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Information bottleneck theory a hypothesis about how neural nets learn is creating some buzz. One of the claims is that the output of earlier layers have more mutual information with the inputs while final layer outputs have more mutual information with the outputs than the inputs. The information about input gets compressed in each layer.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;https://d2r55xnwy6nx47.cloudfront.net/uploads/2017/09/DeepLearning_5001.jpg&quot; alt=&quot;Information Bottleneck process&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;color:gray; font-size: 80%; text-align: center;&quot;&gt;&lt;em&gt;&lt;a href=&quot;https://www.quantamagazine.org/new-theory-cracks-open-the-black-box-of-deep-learning-20170921/&quot;&gt;Lucy Reading-Ikkanda/Quanta Magazine; adapted from arXiv:1703.00810 [cs.LG]&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;evolution-of-representations-in-the-transformer&quot;&gt;&lt;a href=&quot;https://lena-voita.github.io/posts/emnlp19_evolution.html&quot;&gt;Evolution of Representations in the Transformer&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;This is a great practical example of using information bottlenecks to analyze neural nets behaviour. This research (accompanied by inspirationally well written blog post) compares the evolution of representations in three different NLP encoder models. And in part explains some empirical findings such as why de-noising objective works better than casual language model objective or encoders from translation objective  for transfer learning.&lt;/p&gt;

&lt;h3 id=&quot;universal-adversarial-triggers-for-attacking-and-analyzing-nlp-wallace-et-al-emnlp-19&quot;&gt;&lt;a href=&quot;http://www.ericswallace.com/triggers&quot;&gt;Universal Adversarial Triggers for Attacking and Analyzing NLP (Wallace et al. EMNLP 19)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This paper finds magic spells that make your NLP models malfunction. They find phrases that cause a specific model prediction when concatenated to 𝘢𝘯𝘺 input from a dataset. These phrases are reported to work across architectures for the same dataset.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Triggers cause:

1. GPT-2 to spew racism
2. SQuAD models to answer &quot;to kill american people&quot; for 72% of questions asking &quot;Why...&quot;
3. Classification models to drop from 90% accuracy to 1%
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;allennlp-interpret&quot;&gt;&lt;a href=&quot;https://allennlp.org/interpret&quot;&gt;AllenNLP Interpret&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;This is a great set of features for interpretability added to AllenNLP library.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We present AllenNLP Interpret, a toolkit built on top of AllenNLP for interactive model interpretations. The toolkit makes it easy to apply gradient-based saliency maps and adversarial attacks to new models, as well as develop new interpretation methods. AllenNLP interpret contains three components: a suite of interpretation techniques applicable to most models, APIs for developing new interpretation methods (e.g., APIs to obtain input gradients), and reusable front-end components for visualizing the interpretation results.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The amazing thing here is with implementing a simple interface in your model predictor allows you to apply a suite of interpretability techniques for our models.&lt;/p&gt;

&lt;h3 id=&quot;aidungeon2-is-here&quot;&gt;&lt;a href=&quot;http://www.aidungeon.io/2019/12/aidungeon2-is-here.html&quot;&gt;AIDungeon2 is here&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;This is a real fun application of langauge model generation.  &lt;a href=&quot;https://twitter.com/nickwalton00&quot;&gt;Nick Walton&lt;/a&gt; has adapted GPT2 to generate user guided “Choose your own” text RPG type games. Now you can try out anything you fancy by just issuing commands like “Cast a spell to Reverse entropy”. A truly open world RPG with a AI dungeon master. The model weaves your actions to generalte plausible/surreal story continuations. &lt;a href=&quot;https://news.ycombinator.com/item?id=21717022&quot;&gt;Hacker News&lt;/a&gt; discussion about it. The nature of the model make them generate surreal dream like scenarios. There are glaring consistency issues in the generated story lines. This points to a symbolic gap that is yet to be filled.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSMELPoU7Br4TBHmaDn-eCYqQMFFrFUPlELxS1pYR1i3iPBOLTO&quot; alt=&quot;AIDungeon 2 generated story example.&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;color:gray; font-size: 80%; text-align: center;&quot;&gt;&lt;em&gt;&lt;a href=&quot;https://aiweirdness.com/post/189511103367/play-ai-dungeon-2-become-a-dragon-eat-the-moon&quot;&gt;Source: aiweirdness.com&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;controlling-text-generation-with-plug-and-play-language-models&quot;&gt;&lt;a href=&quot;https://eng.uber.com/pplm/&quot;&gt;Controlling Text Generation with Plug and Play Language Models&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;On the topic of controlling language models, uber research has found a way to control the generation of models like GPT2 without fine-tuning.&lt;/p&gt;

&lt;h2 id=&quot;quantum-computing-linear-algebra-tools-for-learning&quot;&gt;Quantum Computing, Linear Algebra, Tools for Learning&lt;/h2&gt;

&lt;h3 id=&quot;quantum-computing-for-the-very-curious&quot;&gt;&lt;a href=&quot;https://quantum.country/qcvc&quot;&gt;Quantum Computing for the Very Curious&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;I wanted to try out Micheal Nielsen’s (of neuralnetworksanddeeplearning.com fame) Quantum computing article. This long-form educational article attempts a unique teaching method by embedding flash cards (anki cards) and reminding readers via email to revisit the cards. I got around doing it at behest of the amzing Professor Balaji (a teacher of mine) who gave this as an exercise to test Linear Algebra understanding. Prior knowledge of the truly abstract nature of linear algebra (basis, linear transformations, linear combinations) really helped me to grok the essay.&lt;/p&gt;

&lt;p&gt;The learning approach taken by this article (embedding flash cards + reminders) article shows how computing medium can be extended to augment our understanding. This scratches the surface of Alan Kay’s vision of computers being tools that extend our mind.&lt;/p&gt;

&lt;h3 id=&quot;augmenting-long-term-memory&quot;&gt;&lt;a href=&quot;http://augmentingcognition.com/ltm.html&quot;&gt;Augmenting Long-term Memory&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If you’re curious about spaced repition flash card approach to learn new math theorems, machine learning concepts etc Micheal has written extensively about it in the above link.&lt;/p&gt;

&lt;h3 id=&quot;anki-flash-cards-with-spaced-repitition&quot;&gt;&lt;a href=&quot;https://apps.ankiweb.net/&quot;&gt;Anki Flash Cards with Spaced Repitition&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The free app Anki is example of good software aimed at expanding our capabilites rather than popular objective of draining attention. It has web, desktop and mobile versions for creating Anki (flash) cards with spaced repitition tracking. I am in the process of adopting it for my learning. Not yet successful in integrating it fully, will blog more about my experience in future.&lt;/p&gt;

&lt;h3 id=&quot;polar-app&quot;&gt;&lt;a href=&quot;https://getpolarized.io/&quot;&gt;Polar App&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Related learning tool I found is Polar.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“A powerful document manager for web pages, textbooks, PDFs, and anything you want to read. Supports tagging, annotation, highlighting and keeps track of your reading progress.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It doesn’t have a firefox extension yet. But it allows creating anki cards that can be synced to Anki app from web highlights. This helps in creating a learning expereince like the quantum computing blog for any document.&lt;/p&gt;

&lt;h2 id=&quot;philosophy&quot;&gt;Philosophy&lt;/h2&gt;

&lt;h3 id=&quot;would-aliens-understand-lambda-calculus&quot;&gt;&lt;a href=&quot;http://tomasp.net/blog/2018/alien-lambda-calculus/&quot;&gt;Would aliens understand lambda calculus?&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Platonism vs Aristotelianism is an age old debate in philosophy. Professor Balaji (a teacher of mine) had a strong notion that the current mathematics we have is strongly influenced by our spatio-visual sense. Stumbled upon the above post which makes similar claims. It claims that certain cognitive priors are necessary to converge upon ideas which some consider as universal.&lt;/p&gt;

&lt;p&gt;I don’t know enough to lean on any side of the debate heavily. But my intution lies with universality/platonism of physics, mathematics and computatability. I think even if Alien’s use some other metaphors to arrive at Lambda Calculus, the underlying notion of universal computability (if correct) will be the same.&lt;/p&gt;

&lt;h3 id=&quot;new-ai-strategy-mimics-how-brains-learn-to-smell&quot;&gt;&lt;a href=&quot;https://www.quantamagazine.org/new-ai-strategy-mimics-how-brains-learn-to-smell-20180918/&quot;&gt;New AI Strategy Mimics How Brains Learn to Smell&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I am now exploring search systems over neural net generated representation (vector spaces). This generally involves approximate methods such as Locality senstive Hashing. The method described in this post was interestingly derived from the sense of smell of fruit-flies. This lends some weight top the notion that our cognitive reliance on certain senses (vision) makes some ideas intutive, but exploring outside it can expand our horizons. (Purely my speculation to be taken with a grain of salt.)&lt;/p&gt;

&lt;h2 id=&quot;programming-languages&quot;&gt;Programming Languages&lt;/h2&gt;

&lt;h3 id=&quot;type-state-pattern&quot;&gt;&lt;a href=&quot;http://cliffle.com/blog/rust-typestate/&quot;&gt;Type State Pattern&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To eliminate errors make them impossible in runtime is a mantra I stand behind. Programming Patterns that are finally entering mainstream (after stewing in the academic functional world) such as Optional are moving errors to compile time. Among the patterns, type state caught my eye. Using rust’s borrow checker and other langauge features allows one to build compile time state machines. They can be as simple as allowing the compiler to disallow methods such as read on file references that are closed. Or it can be taken one step beyond to write a full blown state machines that track the current state in compile time. ie Say you have an API that needs a handshake to be performed before sending, you can ensure in compile time that the “send” method can be called only after “handshake” is called. How awesome is that.&lt;/p&gt;

&lt;h3 id=&quot;why-monads-matter&quot;&gt;&lt;a href=&quot;https://cdsmith.wordpress.com/2012/04/18/why-do-monads-matter/&quot;&gt;Why Monads matter?&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This article explains what the usally hyped functional programming concept of monad solves for a imperative programmer. I have not dived deeply into any functional language yet. Seeing how even weakly adopted fucntional programming concepts such as Optionals (algebraic data types) and Optional Chaining (which is a monad) makes me question what is the cost with which the programming world is ignoring Functional paradigmn.
Are the functional languages difficult to learn, or is it exposure bias towards imperative languages? Or do we need the functional abstractions to be put in better terms for people to grok them? Only time will tell.&lt;/p&gt;</content><author><name></name></author><category term="Computer Science" /><category term="Machine Learning" /><category term="Philosophy" /><category term="Semantic Legion" /><summary type="html">I am guilty of spamming people in the degree one of my network with too many links in topics that fancy the Legion of varied interests that haunt me. Following the suggestion of Ananda Seelan, I am consolidating my link blasts into a considated blog post format, thus begins the “Semantic Legion”. This exercise might help organize the “Legion” in my head and maybe lead to more focused blog posts.</summary></entry><entry><title type="html">SemEval 2019 - Semi-Supervised Domain Adaptation for Suggestion mining</title><link href="https://saiprasanna.in/posts/semeval-19-semi-supervised-domain-adaptation-for-suggestion-mining/" rel="alternate" type="text/html" title="SemEval 2019 - Semi-Supervised Domain Adaptation for Suggestion mining" /><published>2019-04-07T00:00:00-05:00</published><updated>2019-04-07T00:00:00-05:00</updated><id>https://saiprasanna.in/posts/semeval-19-semi-supervised-domain-adaptation-for-suggestion-mining</id><content type="html" xml:base="https://saiprasanna.in/posts/semeval-19-semi-supervised-domain-adaptation-for-suggestion-mining/">&lt;p&gt;SemEval Workshop regularly has been conducting tasks in NLP to evaluate the progress in the field.&lt;/p&gt;

&lt;p&gt;I and my colleague Ananda Seelan participated in this year SemEval’s Suggestion mining task (Task 9).
Here is our &lt;a href=&quot;https://arxiv.org/abs/1902.10623&quot;&gt;submission&lt;/a&gt; to be published in NAACL 2019 proceedings, and the code is on &lt;a href=&quot;https://github.com/sai-prasanna/suggestion-mining-semeval19&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This blog is a summary of the key techniques and ideas which influenced this work.&lt;/p&gt;

&lt;h2 id=&quot;suggestion-mining-task&quot;&gt;Suggestion Mining Task&lt;/h2&gt;

&lt;p&gt;The suggestion mining task in brief is a text classification task to find whether a sentence contains a suggestion.&lt;/p&gt;

&lt;p&gt;Example,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Suggestion&lt;/strong&gt;     - It would be nice if they had vegan options.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Non Suggestion&lt;/strong&gt; - This restaurant has good vegan options.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;About 8k sentences scrapped from technical forumns were provided as training data. 
The task was divided into two subtasks.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Subtask A - Evaluation on same domain   - technical forums posts.&lt;/li&gt;
  &lt;li&gt;Subtask B - Evaluation on out of domain - hotel reviews.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The catch for subtask B is human labelled data in hotel reviews domain is not allowed for training.
Our model was placed third place in the leaderboard for Subtask B.&lt;/p&gt;

&lt;h2 id=&quot;key-techniques&quot;&gt;Key Techniques&lt;/h2&gt;

&lt;p&gt;We used simple convolutional neural networks for text classification. And we applied transfer learning and semi-supervised learning for the tasks.&lt;/p&gt;

&lt;h3 id=&quot;transfer-learning&quot;&gt;Transfer Learning&lt;/h3&gt;

&lt;p&gt;The current trend in machine learning for NLP is to using pre-trained language models. We used google’s recently published BERT model as our representation layer.
Take a look at &lt;a href=&quot;http://jalammar.github.io/illustrated-bert/&quot;&gt;http://jalammar.github.io/illustrated-bert/&lt;/a&gt; for a good description of how pre-trained models work for NLP.&lt;/p&gt;

&lt;h3 id=&quot;semi-supervised-learning&quot;&gt;Semi-Supervised Learning&lt;/h3&gt;
&lt;p&gt;In ACL 2018 conference Melbourne, I attended two talks which impacted the work in this paper. One was Sebastien Ruder’s talk on Strong baselines for semi-supervised
learning in NLP. The conclusion of &lt;a href=&quot;https://aclweb.org/anthology/P18-1096&quot;&gt;Sebastian Ruder, Barbara Plank (2018)&lt;/a&gt; was that classic machine learning techniques for semi-supervised learning such as Tri-Training prove as strong baseline in NLP with neural nets.
Sebastien has a very accessible and thorough &lt;a href=&quot;http://ruder.io/semi-supervised/&quot;&gt;blog post&lt;/a&gt; explaining the techniques. They have also made their code available on &lt;a href=&quot;https://github.com/bplank/semi-supervised-baselines&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/285802189&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;We applied a variant of tri-training. We use three models of the same architecture trained initially on data &lt;a href=&quot;https://en.wikipedia.org/wiki/Bootstrapping_(statistics)&quot;&gt;bootstrap sampled&lt;/a&gt; from the tech reviews data. The three models
are used to iteratively label unlabelled data from hotel reviews domain. Agreement of labels between two models is used as way to select sentences to be added to next iteration
of training. Pseudo-code and detailed explanations can be found in the paper. Or you might as well look to the code, as its way simpler than a dry description of it might suggest.&lt;/p&gt;

&lt;h2 id=&quot;statistical-significance&quot;&gt;Statistical Significance&lt;/h2&gt;

&lt;p&gt;The other work &lt;a href=&quot;https://aclweb.org/anthology/P18-1128&quot;&gt;published&lt;/a&gt; and presented in ACL 2018 that influenced this paper is Rotem Dror’s “The Hitchhiker’s Guide to Statistical Significance in NLP”.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/285803636&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;We report confidence intervals for five random seeds for all our experiments. And we also do pair-wise significance testing via McNemar’s test to evaluate 
whether pair-wise model performance on the test set vary significantly.&lt;/p&gt;

&lt;h3 id=&quot;metrics&quot;&gt;Metrics&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/bf7927798419277eea7063f40d4329f8b8fa31ad/3-Table1-1.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;mcnemars-test&quot;&gt;McNemar’s Test&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/bf7927798419277eea7063f40d4329f8b8fa31ad/5-Table3-1.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="NLP" /><category term="Semi-Supervised Learning" /><category term="Research Paper Summary" /><summary type="html">SemEval Workshop regularly has been conducting tasks in NLP to evaluate the progress in the field.</summary></entry><entry><title type="html">God’s own Programming Language</title><link href="https://saiprasanna.in/posts/gods-own-programming-language/" rel="alternate" type="text/html" title="God’s own Programming Language" /><published>2019-04-04T00:00:00-05:00</published><updated>2019-04-04T00:00:00-05:00</updated><id>https://saiprasanna.in/posts/gods-own-programming-language</id><content type="html" xml:base="https://saiprasanna.in/posts/gods-own-programming-language/">&lt;p&gt;Found this interesting &lt;a href=&quot;https://twobithistory.org/2018/10/14/lisp.html&quot;&gt;blog post&lt;/a&gt; explores why many programmers hold a high regard for an ancient programming language which you might not have heard about or use daily.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot; class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;For God wrote in Lisp code
When he filled the leaves with green.
The fractal flowers and recursive roots:
The most lovely hack I’ve seen.
And when I ponder snowflakes,
never finding two the same,
I know God likes a language
with its own four-letter name.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p style=&quot;color:gray; font-size: 80%; text-align: center;&quot;&gt;&lt;em&gt;Poem from &lt;a href=&quot;https://twobithistory.org/2018/10/14/lisp.html&quot;&gt;twobithistory.org&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p style=&quot;color:gray; font-size: 80%; text-align: center;&quot;&gt;&lt;img src=&quot;https://imgs.xkcd.com/comics/lisp.jpg&quot; alt=&quot;XKCD LISP - We think God created the world in LISP, but he merely hacked it in Perl.&quot; /&gt;
&lt;em&gt;&lt;a href=&quot;https://xkcd.com/224/&quot;&gt;XKCD Comics&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Also a good read are the &lt;a href=&quot;http://www.paulgraham.com/lisp.html&quot;&gt;posts on LISP&lt;/a&gt; by Paul Graham of YCombinator/HackerNews fame.&lt;/p&gt;

&lt;h2 id=&quot;how-to-attain-nirvana-with-the-gods-own-language&quot;&gt;How to attain Nirvana with the God’s own language?&lt;/h2&gt;

&lt;p&gt;To attain programming nirvana - Start reading the SICP Book.&lt;/p&gt;

&lt;p&gt;SICP (Structure and Interpretation of Computer Programs) is a introduction to computer science book. It can change how you view even simple constructs we use for code (like loops, if, etc). A book that will teach timeless concepts in programming which you would never come across easily. I started reading it ages ago, haven’t completed it , the first few chapters themselves were sufficiently mind blowing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://web.mit.edu/alexmv/6.037/sicp.pdf&quot;&gt;Original book&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://xuanji.appspot.com/isicp/1-1-elements.html&quot;&gt;A modern interactive version&lt;/a&gt;&lt;/strong&gt; Now you can run the examples of SICP book God’s own language in the browser with godforsaken javascript. And laugh morosely on the irony of running LISP in a half baked language (javascript) which was inspired from it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://www.sicpdistilled.com/&quot;&gt;A Distilled version with illustrations&lt;/a&gt;&lt;/strong&gt; - Smaller, condensed version.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;To use an analogy, if SICP were about automobiles, it would be for the person who wants to know how cars work, how they are built, and how one might design fuel-efficient, safe, reliable vehicles for the 21st century. The people who hate SICP are the ones who just want to know how to drive their car on the highway, just like everyone else. &lt;strong&gt;- Peter Norvig on SICP&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;how-to-write-a-lisp-interpreter-in-python&quot;&gt;(How to Write a (Lisp) Interpreter (in Python))&lt;/h3&gt;

&lt;p&gt;Follow this &lt;a href=&quot;http://www.norvig.com/lispy.html&quot;&gt;guide&lt;/a&gt; to implement your own LISP Interpreter in an hundred lines of python.
You might think, “Is he crazy to ask a language beginner to implement the interpreter before learning it?”
Answer is while I am partly crazy LISP is not, it has the simplest structure of all programming languages. It’s just lists duh! (LiSt Processing).&lt;/p&gt;

&lt;h2 id=&quot;lisp-for-ai&quot;&gt;LISP for AI&lt;/h2&gt;
&lt;p&gt;You can practise LISP for Artificial Intelligence algorithms with Peter Norvig’s book on &lt;a href=&quot;https://github.com/norvig/paip-lisp&quot;&gt;“Paradigms of Artificial Intelligence Programming”&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;say-you-dont-want-nirvana-but-something-more-pragmatic&quot;&gt;Say you don’t want Nirvana, but something more pragmatic&lt;/h2&gt;

&lt;p&gt;You can learn Clojure to use God’s Language to do some real world wizardry. Clojure is a form of LISP which is modern, functional and runs on JVM. &lt;a href=&quot;https://braveclojure.com&quot;&gt;Brave Clojure&lt;/a&gt; is one of the best sources out there for Clojure. For front end development/nodejs there is clojure-script which compiles down to javascript.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Learning Clojure is the best way you can improve as a programmer because it introduces you to powerful concepts implemented in a simple, cohesive, and practical language. You learn Clojure here. Therefore, Brave Clojure is your very best friend when it comes to programming.” And lo, the syllogism was born!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p style=&quot;color:gray; font-size: 80%; text-align: center;&quot;&gt;&lt;img src=&quot;https://imgs.xkcd.com/comics/lisp_cycles.png&quot; alt=&quot;XKCD comic - LISP is passed down generation after generation as elegant weapons for a more Civilized age.&quot; /&gt;
&lt;em&gt;&lt;a href=&quot;https://xkcd.com/297/&quot;&gt;XKCD Comics&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-note-and-a-zen-koan&quot;&gt;A Note and a Zen Koan&lt;/h2&gt;

&lt;p&gt;Use any language that solves your problem and learn about others which have different paradigms conceptually like LISP, etc when you find the time. It a enjoyable exercise if you are curious about digging deeply into what makes computers tick.&lt;/p&gt;

&lt;p&gt;As &lt;a href=&quot;http://catb.org/jargon/html/koans.html&quot;&gt;Master Foo says&lt;/a&gt; says,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Master Foo once said to a visiting programmer: “There is more Unix-nature in one line of shell script than 
there is in ten thousand lines of C.”&lt;/p&gt;

  &lt;p&gt;The programmer, who was very proud of his mastery of C, said: “How can this be? C is the language in
which the very kernel of Unix is implemented!”&lt;/p&gt;

  &lt;p&gt;Master Foo replied: “That is so. Nevertheless, there is more Unix-nature in one line of shell script 
than there is in ten thousand lines of C.”&lt;/p&gt;

  &lt;p&gt;The programmer grew distressed. “But through the C language we experience the enlightenment of the Patriarch Ritchie! 
We become as one with the operating system and the machine, reaping matchless performance!”&lt;/p&gt;

  &lt;p&gt;Master Foo replied: “All that you say is true. But there is still more Unix-nature in one line of shell script
than there is in ten thousand lines of C.”&lt;/p&gt;

  &lt;p&gt;The programmer scoffed at Master Foo and rose to depart. But Master Foo nodded to his student Nubi, 
who wrote a line of shell script on a nearby whiteboard, and said: “Master programmer, consider this pipeline. 
Implemented in pure C, would it not span ten thousand lines?”&lt;/p&gt;

  &lt;p&gt;The programmer muttered through his beard, contemplating what Nubi had written. Finally he agreed that it was so.&lt;/p&gt;

  &lt;p&gt;“And how many hours would you require to implement and debug that C program?” asked Nubi.&lt;/p&gt;

  &lt;p&gt;“Many,” admitted the visiting programmer. “But only a fool would spend the time to do that when so many more worthy tasks await him.”&lt;/p&gt;

  &lt;p&gt;“And who better understands the Unix-nature?” Master Foo asked. “Is it he who writes the ten thousand 
lines, or he who, perceiving the emptiness of the task, gains merit by not coding?”&lt;/p&gt;

  &lt;p&gt;Upon hearing this, the programmer was enlightened.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For more funny hacker koans, visit &lt;a href=&quot;http://thecodelesscode.com/contents&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://catb.org/esr/writings/unix-koans/introduction.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I am currently learning emacs-lisp for I have become a convert/evangelizer of the &lt;a href=&quot;https://stallman.org/saint.html&quot;&gt;Church&lt;/a&gt; of &lt;a href=&quot;https://www.gnu.org/s/emacs/&quot;&gt;Emacs&lt;/a&gt; on a Starship called &lt;a href=&quot;http://spacemacs.org/&quot;&gt;Spacemacs&lt;/a&gt;. But that’s a post/sermon (;P) for another time.&lt;/p&gt;</content><author><name></name></author><category term="LISP" /><category term="Programming Languages" /><summary type="html">Found this interesting blog post explores why many programmers hold a high regard for an ancient programming language which you might not have heard about or use daily.</summary></entry><entry><title type="html">Learning Longer-term Dependencies in RNNs with Auxiliary Losses (ACL 2018)</title><link href="https://saiprasanna.in/posts/learning-long-term-dependencies-rnn/" rel="alternate" type="text/html" title="Learning Longer-term Dependencies in RNNs with Auxiliary Losses (ACL 2018)" /><published>2018-06-05T03:00:00-05:00</published><updated>2018-06-05T03:00:00-05:00</updated><id>https://saiprasanna.in/posts/learning-long-term-dependencies-rnn</id><content type="html" xml:base="https://saiprasanna.in/posts/learning-long-term-dependencies-rnn/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1803.00144.pdf&quot;&gt;Paper&lt;/a&gt; by Trieu H. Trinh, Andrew M. Dai,  Minh-Thang Luong,  Quoc V. Le&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TLDR;&lt;/strong&gt; RNNs can learn very long sequences when auxiliary loss for predicting input sequence (forward and backward) from different timesteps is added.&lt;/p&gt;

&lt;h3 id=&quot;problem-being-addressed&quot;&gt;Problem being addressed&lt;/h3&gt;

&lt;p&gt;Recurrent neural nets in theory can learn arbitrarily long sequences, but in practice suffer from problems like vanishing gradients etc. Techniques to reduce vanishing gradients problem like LSTM alone don’t work for very long sequences.&lt;/p&gt;

&lt;p&gt;RNN has a better tradeoff when it comes to memory requirements compared to CNN based networks or vanilla &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;Transformer&lt;/a&gt; nets.
When processing very large sequences this becomes important.&lt;/p&gt;

&lt;h3 id=&quot;proposed-method&quot;&gt;Proposed Method&lt;/h3&gt;

&lt;p&gt;Take the hidden state of main RNN used for a given task at sampled timesteps, use another RNN at sampled intervals, and try to predict the input sequence to certain time steps. Truncated BPTT (Back propagation through time) to few timesteps would give a new loss.&lt;/p&gt;

&lt;h3 id=&quot;evaluation-and-results&quot;&gt;Evaluation and results&lt;/h3&gt;

&lt;p&gt;Evaluation is done on MNIST, CIFAR-10, Stanford dog dataset is given as sequence of pixels to an RNN with classification being the target. Since the pixels are flattened to sequential input, spatial location information is now across whole range of the sequence, requiring long dependencies to be formed to get good results. 
The authors also test it on character based classification on dbpedia. 
This technique achieves very significant results on long sequences compared to existing LSTMs, Transformers etc.&lt;/p&gt;

&lt;h3 id=&quot;opinions&quot;&gt;Opinions&lt;/h3&gt;

&lt;p&gt;This paper makes a significant experiment to improve a crucial behavior of RNNs on long sequences. The ablation study is well done. This auxiliary loss reminded me of the &lt;a href=&quot;https://worldmodels.github.io/&quot;&gt;World models&lt;/a&gt;  paper where the task of predicting future states improves current tasks output.&lt;/p&gt;</content><author><name></name></author><category term="Research Paper Summary" /><category term="Deep learning" /><category term="RNN" /><summary type="html">Paper by Trieu H. Trinh, Andrew M. Dai, Minh-Thang Luong, Quoc V. Le TLDR; RNNs can learn very long sequences when auxiliary loss for predicting input sequence (forward and backward) from different timesteps is added. Problem being addressed</summary></entry><entry><title type="html">Neural Open Information Extraction (ACL 2018)</title><link href="https://saiprasanna.in/posts/neural-open-information-extraction/" rel="alternate" type="text/html" title="Neural Open Information Extraction (ACL 2018)" /><published>2018-06-04T03:00:00-05:00</published><updated>2018-06-04T03:00:00-05:00</updated><id>https://saiprasanna.in/posts/neural-open-information-extraction</id><content type="html" xml:base="https://saiprasanna.in/posts/neural-open-information-extraction/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1805.04270&quot;&gt;Paper&lt;/a&gt; by Lei Cui, Furu Wei, Ming Zhou&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TLDR;&lt;/strong&gt; Models Open information extraction as  Sequence to Sequence problem using neural nets.&lt;/p&gt;

&lt;h3 id=&quot;what-is-open-information-extraction&quot;&gt;What is Open information extraction?&lt;/h3&gt;

&lt;p&gt;Open Information Extraction aims to extract one or more (Entity 1, Relationship, Entity 2) tuples from sentences.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;Deep learning is a subfield of machine learning.&quot; 
                   |
                   v
(Deep learning, is a subfield of , machine learning) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Existing methods use handcrafted rules written on &lt;strong&gt;syntatic parsers&lt;/strong&gt; which have poor perfomance and suffer from &lt;strong&gt;cascading of errors&lt;/strong&gt;.&lt;br /&gt;
This paper applies neural networks to get better accuracy and alleviate errors.&lt;/p&gt;

&lt;h3 id=&quot;how-is-the-problem-modeled&quot;&gt;How is the problem modeled?&lt;/h3&gt;

&lt;p&gt;Sequence 2 Sequence task, where you take a source sentence as input and output the information tuple as sequence separated by special tokens (open arg1, arg2, arg3 and close arg1, arg2 arg3).  Currently the model is trained for single tuple extraction.&lt;/p&gt;

&lt;p&gt;“Deep learning is a subfield of machine learning.” -&amp;gt; “&lt;arg1&gt; Deep learning &lt;/arg1&gt;  &lt;arg2&gt; is a subfield of &lt;/arg2&gt; &lt;arg3&gt; machine learning &lt;/arg3&gt;”&lt;/p&gt;

&lt;p&gt;The paper uses a LSTM based &lt;strong&gt;Sequence to Sequence&lt;/strong&gt; model with &lt;strong&gt;attention&lt;/strong&gt;. 
The source and target vocabulary is same. If unknown word target is found, the model forms the target probability vector by placing attention on of source sequence as probability of the corresponding source words occurring.&lt;/p&gt;

&lt;h3 id=&quot;what-are-the-benchmarks&quot;&gt;What are the benchmarks?&lt;/h3&gt;

&lt;p&gt;Evaluating on a large benchmark dataset, this model gets &lt;strong&gt;0.473 AUC&lt;/strong&gt; (Area under curve) for Precision-Recall on &lt;strong&gt;top 5 predictions&lt;/strong&gt; of this model (I think generated from beam search) has better performance , significantly higher than existing systems.  Among existing systems &lt;strong&gt;OpenIE&lt;/strong&gt; has the best score of  &lt;strong&gt;0.373 AUC&lt;/strong&gt; .&lt;/p&gt;

&lt;p&gt;One observation of authors is only 11 % of the predictions of Neural model matches with Open IE (rule based) model, but the performance is higher. This could be due to neural model generalizing on some of the patterns hard to capture by rules.&lt;/p&gt;</content><author><name></name></author><category term="Research Paper Summary" /><category term="Deep learning" /><category term="NLP" /><summary type="html">Paper by Lei Cui, Furu Wei, Ming Zhou TLDR; Models Open information extraction as Sequence to Sequence problem using neural nets. What is Open information extraction?</summary></entry><entry><title type="html">Dependency Injection - What, Why and How?</title><link href="https://saiprasanna.in/posts/dependency-injection-what-why-and-how/" rel="alternate" type="text/html" title="Dependency Injection - What, Why and How?" /><published>2017-03-20T00:00:00-05:00</published><updated>2017-03-20T00:00:00-05:00</updated><id>https://saiprasanna.in/posts/dependency-injection-what-why-and-how</id><content type="html" xml:base="https://saiprasanna.in/posts/dependency-injection-what-why-and-how/">&lt;p&gt;We are going to explore dependency injection with emphasis on swift iOS development. But the concept
applies to most object oriented languages. We will also see some practical considerations on 
applying DI in iOS environment. This article is result of my deep dive into implementing DI, and learning about 
various practical, theoretical aspects of it.&lt;/p&gt;

&lt;h1 id=&quot;what-is-dependency-injection&quot;&gt;What is Dependency Injection?&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Dependency Injection” is a 25-dollar term for a 5-cent concept”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;is a often repeated maxim regarding DI.&lt;/p&gt;

&lt;p&gt;In its essence DI means wherever possible, &lt;strong&gt;replace object creation inside a piece of code 
by providing it from outside that piece of code&lt;/strong&gt;. Hence the term.&lt;/p&gt;

&lt;p&gt;Constructor, Property, Method are where we usually do object creation, and that can be replaced from outside. So we end up with 3 types of injection.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Constructor Injection&lt;/li&gt;
  &lt;li&gt;Property Injection&lt;/li&gt;
  &lt;li&gt;Method Injection&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We will explore they 3 types in “How ..?” section.&lt;/p&gt;

&lt;h1 id=&quot;why-dependency-injection&quot;&gt;Why Dependency Injection?&lt;/h1&gt;

&lt;p&gt;Let’s dwelve into this with help of a scenario.&lt;/p&gt;

&lt;h2 id=&quot;scenario---koala-koder&quot;&gt;Scenario - Koala Koder!&lt;/h2&gt;

&lt;p&gt;Say you have an app with a user login. A user model struct/class  encapsulates the logged in user data.&lt;/p&gt;

&lt;p&gt;Suppose you are a Koala Koder( a programmer who is as lazy as a koala bear). You perhaps made a solution which is quick and dirty. Store the user model inside NSUserDefaults, and fetch it via properties. And as we all know how apple loves its singleton classes, we follow them making UserModel a singleton.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sharedInstance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSUserDefaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;forKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;userName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;??&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;NSUserDefaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;forKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;userName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;greet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Vannakam :)&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We write our app with this usermodel in mind, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UserModel.sharedInstance&lt;/code&gt; is everywhere in our app.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ih0.redbubble.net/image.5150955.4141/flat,1000x1000,075,f.jpg&quot; alt=&quot;Koala lazing off&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;problems-problems-everywhere&quot;&gt;Problems, problems everywhere…&lt;/h2&gt;

&lt;h3 id=&quot;1-unit-tester-vader-strikes&quot;&gt;1. Unit Tester Vader strikes!&lt;/h3&gt;

&lt;p&gt;A senior developer suddenly turns to the dark side, and starts ranting about &lt;em&gt;unit testing&lt;/em&gt;.
He/She will not let apps which are not unit tested pass the code review.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://s2.quickmeme.com/img/03/0347c3efdc17cc1959d089f60b8b2fc267d9093caa8e8cb483bf476b58e63e45.jpg&quot; alt=&quot;Meme: Darth Vader says &amp;quot;I find your lack of unit testing disturbing&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-a-wild-new-use-case-appears&quot;&gt;2. A wild New Use case appears!&lt;/h3&gt;

&lt;p&gt;And if that isn’t enough a &lt;em&gt;new use case&lt;/em&gt;  should be supported. Our app should now support &lt;em&gt;multiple users&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.meme.am/instances/500x/64312241.jpg&quot; alt=&quot;Meme: Back to future - Dr Brown says &amp;quot;New Usecase in no time? I've an extra flux capacitor&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-lets-move-to-insert-any-serialization-library-here&quot;&gt;3. “Lets move to &amp;lt;insert any serialization library here&amp;gt;”&lt;/h3&gt;

&lt;p&gt;Now we also reached a point where userdefaults didn’t scale and  wish to migrate to new data serialization method. Now even our getters and setters inside the UserProfile is not safe.&lt;/p&gt;

&lt;h2 id=&quot;why-are-there-problems&quot;&gt;Why are there problems?&lt;/h2&gt;

&lt;p&gt;So we find ourselves in deep trouble. Lets analyze why so.&lt;/p&gt;

&lt;h3 id=&quot;1-singletons-are-hard-to-test&quot;&gt;1. Singletons are hard to test&lt;/h3&gt;

&lt;p&gt;Now if you want to unit test a viewcontroller that uses this singleton.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserProfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIViewController&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;viewDidLoad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;greetingLabel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sharedInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;greet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//...&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In unit testing you create a UserProfile object, call viewDidLoad or other methods manually. Now you have to verify 
whether &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UserModel.sharedInstance.greet()&lt;/code&gt; was called.&lt;/p&gt;

&lt;p&gt;Since UserModel.sharedInstance is immutable, either we can’t replace it with our mock class extending UserModel, which overrides greetUser, and sets a flag which can be checked. So our testing coverage comes down.&lt;/p&gt;

&lt;h3 id=&quot;2-instantiation-inside-our-code-constraints-creates-strong-coupling-creating-harmful-constraints&quot;&gt;2. Instantiation inside our code constraints creates strong coupling, creating harmful constraints&lt;/h3&gt;

&lt;p&gt;In our scenario, by using a singleton, we tied our codebase to a single UserModel but now our app needs multiple user models. So in general, using singletons will make it hard to adapt to new use cases. &lt;em&gt;What you thought as a singleton suddenly is not so single anymore&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;But consider that we didn’t use singleton, but instantiated UserModel, by calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UserModel()&lt;/code&gt; wherever we needed it.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserProfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIViewController&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;userModel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;viewDidLoad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;userNameLabel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;userModel&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//...&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can’t support our new usecase of multiple users, without userprofile class knowing about multi-usermodel, or some other global allowing UserModel() to return the correct usermodel, these solutions are ugly hacks, which add complexity by either giving too much knowledge to classes or using globals and forgoing object oriented encapsulation.&lt;/p&gt;

&lt;h3 id=&quot;3-concrete-type-usage-creates-strong-coupling&quot;&gt;3. Concrete Type usage creates strong coupling&lt;/h3&gt;

&lt;p&gt;Consider the UserProfile, it  uses NSUserDefaults, now suppose we move to coredata to save our data, we are again in trouble because of using singleton inside. &lt;strong&gt;Our UserProfile rather needed only just a way to serialize some data, it didn’t need to know about WHAT we use for serialization&lt;/strong&gt;. This is the key insight to keep in mind  when thinking about dependency injection.&lt;/p&gt;

&lt;h2 id=&quot;di-to-the-rescue&quot;&gt;DI to the rescue&lt;/h2&gt;

&lt;p&gt;DI helps to solve the variety of issues that we face above, with regard to  Unit Testablity, Singletons and strong coupling we face above.&lt;/p&gt;

&lt;h1 id=&quot;how-to-do-dependency-injection&quot;&gt;How to do Dependency Injection?&lt;/h1&gt;

&lt;h2 id=&quot;constructor-injection&quot;&gt;Constructor Injection&lt;/h2&gt;

&lt;p&gt;So we will be injecting a serializer into UserModel via constructor.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Move dependency to constructor, and if possible make it a interface/protocol type instead of concrete class/struct&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So we remove singleton access to userdefaults. And rather pass a serializer protocol which has methods we require for serialization to constructor.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;protocol&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forKey&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forKey&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;forKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;userName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;??&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;setObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;forKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;userName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Since we are Koala Koder, we just make the Serializing protocol methods to same ones in NSUserdefaults, so we can make NSUserDefaults conform easily by&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;extension&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSUserDefaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;.&lt;/p&gt;

&lt;p&gt;Now to use user defaults as our serializer, we do the following.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSUserDefaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For our fancy multiple user use case we can also do this. (Note: did this in a hurry, it may have edge cases, just providing it as a illustration)&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MultiUserSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// So we fetch the current currentUserId and use that to prefix stored data&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fetchCurrentUserId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;forKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;CURRENT_USER_ID&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;??&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forKey&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;forKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fetchCurrentUserId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forKey&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forKey&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fetchCurrentUserId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//Instantiate using userdefaults, assume we implemented contextFetcher somewhere else&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;multiUserSerializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MultiUserSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSUserDefaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;userModel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiUserSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So now userModel fetches data, and sets data to the current userID without even knowing about it. We could also use something other than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NSUserDefaults.standard&lt;/code&gt; to serialize the data in top level.&lt;/p&gt;

&lt;p&gt;The point is by removing replacing the concrete  dependency &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NSUserDefaults.standard&lt;/code&gt; out of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UserModel&lt;/code&gt; and swapping it to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Serializing&lt;/code&gt; protocol we can now satisfy the new usecase of multi user modelling easily. This is the core idea behind of &lt;strong&gt;loose coupling&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Also we can now unit test User Model by just passing a Mock implementation of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Serializing&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;dependency-injection-works-even-with-only-concrete-types&quot;&gt;Dependency injection works even with only concrete types.&lt;/h3&gt;

&lt;p&gt;Sometimes you don’t have the time, or are  sure that concrete type used will not have to be changed. You can still DI the concrete type without bothering with protocol creation, just for the sake of it.&lt;/p&gt;

&lt;h4 id=&quot;for-example&quot;&gt;For example:&lt;/h4&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserProfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIViewController&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;userModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// This works only if you don't use storyboards&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;userModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userModel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;userModel&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;viewDidLoad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;userNameLabel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;userModel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We  move UserModel creation out of the controller, without creating any protocol for UserModel properties.&lt;/p&gt;

&lt;p&gt;We still gain advantages of unit testability using ordinary mock objects, and also we are free to use our multi user serialized UserModel , hence making UserProfile support multi user model without changing any logic in user profile.&lt;/p&gt;

&lt;p&gt;(But if you have to do something to notify changes in data, that is seperate topic)&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;multiUserSerializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MultiUserSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSUserDefaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;multiUserModel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiUserSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;userProfile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserProfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;userModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiUserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;my-constructor-is-a-monster-now&quot;&gt;My constructor is a monster now :(&lt;/h3&gt;

&lt;p&gt;A common problem which you will come across is, your UIViewController (if you don’t use storyboards) or any class where you do DI becomes a to big.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserProfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIViewController&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;userModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;apiService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;APIService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;XService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;YService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ZService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is a good thing, it points out clearly that your class is violating &lt;strong&gt;Single Responsibility rule&lt;/strong&gt; . Single responsibility rule states that a  class should have singe responsibility.&lt;/p&gt;

&lt;p&gt;We can solve this by moving some of the current dependencies to a new class, and pass the new class as dependency to UserProfile.&lt;/p&gt;

&lt;p&gt;Guess what if we do this we properly we would be re-inventing design patterns l
MVVM(Nodel View ViewModel) or MVP. Whew! DI just solved Huge ViewController problem!!.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;DI can easily help refactoring code to better design, in a gradual manner.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;property-injection&quot;&gt;Property Injection&lt;/h2&gt;

&lt;p&gt;We seemed to have solved all our above problems, why bother with more types of injections?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you don’t control the creation of a object, your best bet is property injection. But prefer constructor injection if that’s not the case.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Sometimes you don’t create objects of classes, some messy framework does it. For example, if you use Storyboards, you can’t do stuff like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;let userProfileViewController = UserProfile(multiUserModel)&lt;/code&gt;. You would have to refactor to something like&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserProfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIViewController&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;userModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;viewDidLoad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;userNameLabel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;userModel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;multiUserSerializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MultiUserSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSUserDefaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;multiUserModel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiUserSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;storyboard&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIStoryboard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;main&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;bundle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;nil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;userProfile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;storyboard&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;instantiateViewController&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;withIdentifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;UserProfile&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as!&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserProfile&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;userProfile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userModel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiUserModel&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By using implicitly unwrapped Optional property, and setting it from outside, we achive the same effects of constructor injection. But is not perfect, as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;userModel&lt;/code&gt; property can be mutated from outside. Butthis is as good as it can get.&lt;/p&gt;

&lt;h2 id=&quot;method-injection&quot;&gt;Method Injection&lt;/h2&gt;

&lt;p&gt;Method injection is just replacing instantiating inside method by one of its parameters.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Before injection&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;someMethod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;something&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// After injection&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;someMethod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;XService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;something&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;runtime-injection---factory-pattern&quot;&gt;Runtime Injection - Factory pattern&lt;/h2&gt;

&lt;p&gt;Sometimes you want to create a object of a particular class in runtime. But you want to use only protocol type(or a super type) instead of actual implementation (or subclass). Let’s say you need a networking service, which you set based on a user action, but as you are going to need it in runtime, you may think that you can’t inject it.&lt;/p&gt;

&lt;p&gt;But what you can do is inject a factory Networking object or closure, that constructs it in runtime. This factory can fill the dependency of the concrete Networking class, so your class can be unaware of this.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kd&quot;&gt;protocol&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// Some methods ..&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ProxyNetworking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NormalNetworking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;// Injection Via Factory Class&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NetworkingFactory&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;withProxy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;withProxy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ProxyNetworking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NormalNetworking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Some&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;UIViewController&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// This has to be injected via property injection&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;networkingFactory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NetworkingFactory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; 

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;networking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;@IBOutlet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;weak&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;proxySwitch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UISwitch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;@IBAction&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;userTappedSubmit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIButton&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;networking&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;networkingFactory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;withProxy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proxySwitch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isOn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;// Injection using closure&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Some&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;UIViewController&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// This has to be injected via property injection&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;networkingFactory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;networking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;@IBOutlet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;weak&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;proxySwitch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UISwitch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;@IBAction&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;userTappedSubmit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIButton&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;networking&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;networkingFactory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proxySwitch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isOn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;dependency-injection---containers--frameworks&quot;&gt;Dependency injection - Containers &amp;amp; Frameworks&lt;/h1&gt;

&lt;p&gt;There are Dependency Injection frameworks that make the job of dependency injection easier. You may say, “whoa Sai! wait,Do we really need a dependency injection framework as a dependency? Can’t it be done “.&lt;/p&gt;

&lt;p&gt;When we examine what we are doing with DI, we are building a graph with our concrete types as nodes, and their dependencies linking them. If we do this completely, all dependencies will originate from a root object.&lt;/p&gt;

&lt;p&gt;Without a framework, we will be doing a lot of copy paste coding. If our app uses networking protocol type in multiple areas, we have to type out the same concrete implementation everywhere, and fill out every dependency of networking class everywhere.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;propertyInjectionVar&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;networking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

 &lt;span class=&quot;c1&quot;&gt;// To create A we have to create networking and also fill out any property injection vars it needs&lt;/span&gt;

 &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NetworkService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Networking&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

 &lt;span class=&quot;c1&quot;&gt;// Now networking will inturn have its dependencies , which inturn have more ..&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;// So to create A, You have to create NetworkService, X, Y, Z &lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;networking&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NetworkService&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To make this process easier we can build something to store list of dependency type, and their concrete implementation. We will have a table of mappings.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dependency Type&lt;/th&gt;
      &lt;th&gt;Implementation type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Networking&lt;/td&gt;
      &lt;td&gt;NetworkService&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;X&lt;/td&gt;
      &lt;td&gt;XService&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;YService&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Z&lt;/td&gt;
      &lt;td&gt;ZSubClass&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can register a protocol Dependency Type to concrete implementation, like Networking, X, Y to NetworkService, XService, YService respectively. Or map concrete type to its concrete implementation which can be exactly same type, like A, or subclass like mapping Z to ZSubClass. Now what the container does is when A has to be created, it auto resolves each dependency of A from the table.&lt;/p&gt;

&lt;p&gt;You can either implement a container, or use a DI Framework which does that for you.&lt;/p&gt;

&lt;p&gt;Containers also allow you to autofill property injection, handle lifecycle of dependencies like marking them as singleton, so that your whole container has only one object of that type created and other fancy features to make your life easy.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h3 id=&quot;a-key-point-to-remember-is-that-your-classes-should-not-depend-on-di-framework-container-ie-its-not-good-idea-to-pass-the-container-to-your-class-as-a-dependency&quot;&gt;A key point to remember is that your classes should not depend on DI framework container ie its not good idea to pass the container to your class as a dependency.&lt;/h3&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;dip-framework---swift&quot;&gt;&lt;a href=&quot;https://github.com/AliSoftware/Dip&quot;&gt;Dip Framework - Swift&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Among the DI frameworks exiting now for swift, I recommend Dip. Dip has some nifty features to make your DI pain free.&lt;/p&gt;

&lt;h3 id=&quot;features-of-dip&quot;&gt;Features of Dip&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Scopes&lt;/strong&gt;. Dip supports 5 different scopes (or life cycle strategies): &lt;em&gt;Unique&lt;/em&gt;, &lt;em&gt;Shared&lt;/em&gt;, &lt;em&gt;Singleton&lt;/em&gt;, &lt;em&gt;EagerSingleton&lt;/em&gt;, &lt;em&gt;WeakSingleton&lt;/em&gt;;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Auto-wiring&lt;/strong&gt; &amp;amp; &lt;strong&gt;Auto-injection&lt;/strong&gt;. Dip can infer your components’ dependencies injected in constructor and automatically resolve them as well as dependencies injected with properties.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Resolving optionals&lt;/strong&gt;. Dip is able to resolve constructor or property dependencies defined as optionals.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Type forwarding&lt;/strong&gt;. You can register the same factory to resolve different types implemeted by a single class.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Circular dependencies&lt;/strong&gt;. Dip will be able to resolve circular dependencies if you will follow some simple rules;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Storyboards integration&lt;/strong&gt;. You can easily use Dip along with storyboards and Xibs without ever referencing container in your view controller’s code;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Named definitions&lt;/strong&gt;. You can register different factories for the same protocol or type by registering them with &lt;a href=&quot;&quot;&gt;tags&lt;/a&gt;;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Runtime arguments&lt;/strong&gt;. You can register factories that accept up to 6 runtime arguments (and extend it if you need);&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Easy configuration&lt;/strong&gt; &amp;amp; &lt;strong&gt;Code generation&lt;/strong&gt;. No complex containers hierarchy, no unneeded functionality. Tired of writing all registrations by hand? There is a &lt;a href=&quot;https://github.com/ilyapuchka/dipgen&quot;&gt;cool code generator&lt;/a&gt; that will create them for you. The only thing you need is to annotate your code with some comments.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Weakly typed components&lt;/strong&gt;. Dip can resolve “weak” types when they are unknown at compile time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Thread safety&lt;/strong&gt;. Registering and resolving components is thread safe;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Helpful error messages and configuration validation&lt;/strong&gt;. You can validate your container configuration. If something can not be resolved at runtime Dip throws an error that completely describes the issue;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;annotations-in-dip&quot;&gt;Annotations in Dip&lt;/h3&gt;

&lt;p&gt;Java has good frameworks like &lt;a href=&quot;https://square.github.io/dagger/&quot;&gt;Dagger&lt;/a&gt;, and &lt;a href=&quot;https://github.com/google/guice&quot;&gt;Guice&lt;/a&gt; that use annotations to make the job even simpler compared to swift. Dip allows you to leave annotations of dependencies in comments and also generate code for DI from it. How cool is that?&lt;/p&gt;

&lt;h2 id=&quot;poor-mans-di-in-swift&quot;&gt;Poor man’s DI in Swift&lt;/h2&gt;

&lt;p&gt;Though I recommend the framework approach, supposing you don’t want to use framework initially and still want the to do DI, Fear not. You can use Swift’s default parameters to do constructor/method injection, and just use variable properties for property injection. You can maintain a Seperate DI singleton and fill dependencies using that.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UserModel&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;PoormanDIContainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Poor man DI&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;forKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;userName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;??&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;serializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;setObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;forKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;userName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;PoorManDIContainer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;PoorManDIContainer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getSerializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializing&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// If Serializer has some dependencies, it will again use default constructor to obtain it from PoorManDIContainer&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Serializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But if you use the above method, beware of circular dependencies.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;So in conclusion DI is great. It allows you to progressively make your code better remove  singletons, make your code modular, testable and also allow you to evolve good design patterns. Try it out in your existing code base, it will be one of the easiest way to refactor legacy OOP code, without modifying internal logic initially.If you have any doubts, suggestions, constructive criticisms, comment below.&lt;/p&gt;</content><author><name></name></author><category term="iOS" /><category term="Swift" /><summary type="html">We are going to explore dependency injection with emphasis on swift iOS development. But the concept applies to most object oriented languages. We will also see some practical considerations on applying DI in iOS environment. This article is result of my deep dive into implementing DI, and learning about various practical, theoretical aspects of it.</summary></entry></feed>